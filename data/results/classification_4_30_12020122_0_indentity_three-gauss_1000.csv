Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 16, 8, 4, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-3963.00120992735;0.23933333333333334;88.03333333333333
10;-4077.4340647885506;0.31133333333333335;87.43333333333332
15;-4044.326635111346;0.4053333333333333;85.26666666666667
20;-4114.066630839283;0.32866666666666666;87.16666666666667
25;-4113.444346813789;0.464;84.1
30;-4144.968480876321;0.384;86.2
35;-4132.192688102787;0.3446666666666667;86.9
40;-4127.6398026123225;0.37133333333333335;86.43333333333332
45;-4014.786065767712;0.3313333333333333;86.66666666666667
50;-4069.653098548974;0.2966666666666667;87.66666666666667
55;-4081.5929475719104;0.31466666666666665;87.33333333333333
60;-4098.826767552261;0.38266666666666665;85.93333333333332
65;-4075.5245223836664;0.312;87.43333333333332
70;-4051.889764027737;0.3393333333333333;86.53333333333333
75;-4097.698964164462;0.43666666666666665;84.89999999999999
80;-4054.125553222833;0.35133333333333333;86.36666666666667
85;-4101.694214358149;0.3273333333333333;87.16666666666667
90;-4069.7416904354995;0.3486666666666667;86.56666666666666
95;-4098.763189233451;0.3526666666666667;86.63333333333333
100;-4146.381877504198;0.368;86.46666666666667
105;-4034.9957420209766;0.2813333333333333;87.83333333333333
110;-4030.610666718267;0.3433333333333333;86.53333333333333
115;-4047.927882597929;0.324;87.06666666666666
120;-4090.6038602691897;0.31933333333333336;87.3
125;-4065.460847001735;0.42;85.06666666666666
130;-4054.050512519686;0.2946666666666667;87.63333333333333
135;-4176.030856314859;0.37666666666666665;86.2
140;-4095.830075309712;0.41333333333333333;85.3
145;-4016.0639505618046;0.39666666666666667;85.26666666666667
150;-3984.538798110139;0.27466666666666667;87.73333333333333
155;-4263.537293752208;0.4493333333333333;84.0
160;-4171.885524714878;0.36466666666666664;86.46666666666667
165;-4106.6212849752155;0.3893333333333333;85.96666666666667
170;-3960.1952526412297;0.3426666666666667;86.16666666666667
175;-4192.17024167129;0.37333333333333335;86.26666666666667
180;-4184.6227527373185;0.39066666666666666;86.06666666666666
185;-4111.697418609444;0.36;86.6
190;-3969.73878706757;0.4026666666666667;84.93333333333334
195;-4166.952187700688;0.4146666666666667;85.3
200;-4029.4442985793744;0.382;85.63333333333333
205;-4071.535538587102;0.31133333333333335;87.43333333333332
210;-4076.9243678281646;0.30533333333333335;87.43333333333332
215;-4085.500624268205;0.366;86.33333333333333
220;-3959.413513624145;0.2966666666666667;87.1
225;-4145.817975810299;0.394;85.8
230;-4067.635146677063;0.36466666666666664;86.23333333333333
235;-4126.355651421107;0.416;85.16666666666667
240;-3986.6568042529134;0.288;87.5
245;-4091.644090159596;0.428;84.96666666666667
250;-4175.378362734434;0.3506666666666667;87.03333333333333
255;-4089.1362589078;0.37066666666666664;86.26666666666667
260;-4057.631942425768;0.328;87.0
265;-3953.232501370792;0.422;84.53333333333333
270;-3980.47579199956;0.41333333333333333;84.93333333333334
275;-4072.4256870712143;0.29733333333333334;87.63333333333333
280;-4049.3798439768993;0.32133333333333336;87.1
285;-4013.665547166168;0.484;83.53333333333333
290;-4056.5989973216174;0.3233333333333333;87.03333333333333
295;-4068.7837860344957;0.4033333333333333;85.53333333333333
300;-4074.0162674721414;0.38466666666666666;85.8
