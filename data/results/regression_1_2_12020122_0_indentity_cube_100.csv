Train dataset: data/regression/data.cube.train.100.csv
Test dataset: data/regression/data.cube.test.100.csv
Layers: [1, 2, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.3840487189975715;0.16356951590934105
10;0.3515738020929956;0.2120018998030187
15;0.3937264462995771;0.15732602480158622
20;0.3469651046463508;0.31055554618262105
25;0.4271157838780875;0.14318767941294963
30;0.3813871112746064;0.1655757255071159
35;0.4205801278471414;0.145358181848093
40;0.45287066783900964;0.13631950709357404
45;0.4384137012474181;0.13988709763348084
50;0.37378920153973394;0.17225274329404053
55;0.44783306119348804;0.13749075185431248
60;0.418263381309197;0.14618167714363184
65;0.5773597695448217;0.11990030703519795
70;0.3932611874334443;0.157594523966806
75;0.4153614625168729;0.1472574339378288
80;0.5131851440158671;0.1262280595271739
85;0.45729351347677494;0.13534711652601217
90;0.36009179833639954;0.1904106477239727
95;0.5119039643341378;0.12638873441330353
100;0.4969147326220416;0.12840545475995774
105;0.6704742429142377;0.1143212019379934
110;0.440292868238615;0.13938565071557651
115;0.36861891979095956;0.17788585253928096
120;0.4523387754765114;0.13643986756429527
125;0.34655147092501615;0.24321432559753045
130;0.43747635291981274;0.14014190711340746
135;0.45860972303691966;0.13506716717613243
140;0.36071333266063205;0.18930104912219076
145;0.4104874031093826;0.1491859421209039
150;0.38739259825319433;0.16124244597153597
155;0.3882382061132322;0.16068463227702884
160;0.46855119883381324;0.1330797889448254
165;0.34706308221732224;0.3122554482238619
170;0.4851128148269875;0.13019559434921482
175;0.4049476848745224;0.15158883646524132
180;0.5957456514371353;0.11854638604585847
185;0.519199166549364;0.12549614342483045
190;0.43679213388855065;0.14032992411136835
195;0.39214209367742386;0.15825201191245009
200;0.3959390814185368;0.15608622811888445
205;0.42622299426345434;0.14347176308483103
210;0.5001419187636321;0.12794866702814292
215;0.45650171652868166;0.13551756296445197
220;0.4855219162543352;0.13013016634511637
225;0.358305242289207;0.19384392097595562
230;0.449183141173569;0.13716985097463058
235;0.3459507299743122;0.2883414582579858
240;0.3465628607609569;0.24306889361873005
245;0.4171901366893521;0.14657362181476122
250;0.5501708833852259;0.12222703245412847
255;0.3904443329677252;0.15928234849104322
260;0.5473359986230746;0.12249584290533704
265;0.3622129779521595;0.18677885302038355
270;0.38211183889102346;0.16501476143466084
275;0.3685633068664917;0.1779527201597959
280;0.4005929874899607;0.15366132834443375
285;0.3864142707915058;0.16190270288534897
290;0.4257597371490463;0.14362065204368188
295;0.39910235250403;0.15441277406084547
300;0.48092729632828246;0.13088006179297276
