Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 32, 16, 8, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4024.269181084191;0.104;90.8
10;-4203.696322427397;0.082;92.7
15;-4674.608033368822;0.2673333333333333;88.53333333333333
20;-4306.55831740505;0.112;92.86666666666666
25;-4916.738396855511;0.12133333333333333;89.0
30;-4583.936023091262;0.148;90.9
35;-4418.66887998367;0.12066666666666667;92.66666666666666
40;-4135.088307685341;0.06333333333333334;92.36666666666666
45;-4241.0084844253115;0.10133333333333333;92.7
50;-4274.532841578294;0.06666666666666667;93.03333333333333
55;-3974.845182277505;0.076;90.76666666666667
60;-4923.74908646234;0.11266666666666666;89.26666666666667
65;-4367.251942872788;0.19133333333333333;91.36666666666666
70;-4281.122426111263;0.08733333333333333;93.13333333333334
75;-4357.3978016386545;0.09866666666666667;93.06666666666666
80;-4624.386655562631;0.29133333333333333;87.76666666666667
85;-4249.416930677597;0.12733333333333333;92.30000000000001
90;-4384.521220416059;0.10266666666666667;93.06666666666666
95;-4244.750439732891;0.09466666666666666;92.63333333333334
100;-4196.110268742332;0.11666666666666667;91.9
105;-4355.463245666055;0.07066666666666667;93.56666666666666
110;-4302.4786529229195;0.10066666666666667;93.0
115;-4359.4365894801995;0.10133333333333333;93.13333333333334
120;-4271.928063243809;0.09466666666666666;92.80000000000001
125;-4269.0762564203405;0.10066666666666667;92.80000000000001
130;-4306.3654936495805;0.07466666666666667;93.30000000000001
135;-4419.259884044326;0.08733333333333333;93.30000000000001
140;-4951.293610313605;0.114;88.83333333333333
145;-4838.356477569683;0.09333333333333334;90.93333333333334
150;-4340.735168138459;0.09066666666666667;93.33333333333333
155;-4346.019765510577;0.09933333333333333;92.13333333333334
160;-4314.316358875952;0.08333333333333333;93.30000000000001
165;-4469.155015060305;0.08066666666666666;93.0
170;-4591.691975763122;0.07733333333333334;91.53333333333333
175;-4404.166994975424;0.08266666666666667;93.36666666666666
180;-4323.680620730201;0.09333333333333334;92.9
185;-4425.47319465165;0.08533333333333333;93.13333333333334
190;-4058.3803646997503;0.058666666666666666;91.83333333333333
195;-4912.027074762589;0.11066666666666666;88.26666666666667
200;-4117.43547143017;0.092;90.96666666666667
205;-4345.614300419135;0.09666666666666666;92.9
210;-4470.650737177584;0.25866666666666666;89.53333333333333
215;-4986.347058347747;0.17733333333333334;87.63333333333333
220;-4041.35709725633;0.08333333333333333;90.60000000000001
225;-4459.138259625633;0.09;92.86666666666666
230;-4305.52746109994;0.09266666666666666;93.0
235;-4494.307401913056;0.10666666666666667;92.86666666666666
240;-4357.961703332554;0.074;93.43333333333334
245;-4472.568634778632;0.08866666666666667;93.33333333333333
250;-4302.5328576564325;0.084;93.26666666666667
255;-4473.123162887236;0.10933333333333334;92.36666666666666
260;-4435.38780701642;0.07933333333333334;93.10000000000001
265;-4075.8289148151125;0.08066666666666666;91.53333333333333
270;-4540.684681341763;0.10333333333333333;92.33333333333333
275;-4202.292299384817;0.16266666666666665;91.3
280;-4408.692778099132;0.07466666666666667;93.23333333333333
285;-4496.058507715483;0.08866666666666667;92.96666666666667
290;-4207.945885896323;0.13666666666666666;90.96666666666667
295;-4296.190301612449;0.07466666666666667;92.9
300;-4580.796534228674;0.09133333333333334;92.7
