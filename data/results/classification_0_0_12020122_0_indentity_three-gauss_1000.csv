Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4069.5853426320828;0.33866666666666667;86.83333333333333
10;-4076.5032627543037;0.35133333333333333;86.53333333333333
15;-4051.8897640277364;0.34;86.63333333333333
20;-4077.0400620814466;0.3406666666666667;86.76666666666667
25;-4125.560361220643;0.37;86.43333333333332
30;-4098.527623128804;0.35533333333333333;86.63333333333333
35;-4069.9251406056737;0.3426666666666667;86.63333333333333
40;-4062.626768959726;0.35;86.53333333333333
45;-4048.7773775319056;0.334;86.86666666666667
50;-4109.617977217765;0.36;86.6
55;-4059.00468550351;0.338;86.76666666666667
60;-4095.204684096044;0.36866666666666664;86.26666666666667
65;-4101.313762834423;0.3486666666666667;86.76666666666667
70;-4087.437269039846;0.348;86.66666666666667
75;-4117.0591454837495;0.37066666666666664;86.36666666666667
80;-4078.4534587093235;0.32466666666666666;87.03333333333333
85;-4075.823666807122;0.342;86.73333333333333
90;-4089.8700595884948;0.3453333333333333;86.73333333333333
95;-4096.448181737125;0.354;86.63333333333333
100;-4114.300108144888;0.36;86.56666666666666
105;-4076.1770159640914;0.338;86.8
110;-3996.995628879717;0.38866666666666666;85.39999999999999
115;-4043.035199133874;0.344;86.6
120;-4050.8568189235857;0.334;86.86666666666667
125;-4051.38006706735;0.332;86.93333333333332
130;-4056.23209698127;0.336;86.8
135;-4155.0529922278865;0.368;86.53333333333333
140;-4108.374479576683;0.378;86.13333333333333
145;-4047.717330060998;0.3453333333333333;86.56666666666666
150;-4072.2151345342836;0.32133333333333336;87.13333333333333
155;-4111.683867426065;0.36933333333333335;86.33333333333333
160;-4130.242492147767;0.372;86.3
165;-4076.3198125841304;0.358;86.36666666666667
170;-4047.7308812443766;0.336;86.83333333333333
175;-4174.814461040534;0.378;86.16666666666667
180;-4147.075024634758;0.368;86.53333333333333
185;-4079.7990994203083;0.35133333333333333;86.56666666666666
190;-4035.960931208236;0.324;86.96666666666667
195;-4072.330828787565;0.35733333333333334;86.36666666666667
200;-4042.185704199897;0.334;86.8
205;-4070.958085709824;0.3473333333333333;86.6
210;-4073.0510782848824;0.3406666666666667;86.66666666666667
215;-4074.2674735592063;0.33866666666666667;86.8
220;-4031.958396228293;0.332;86.8
225;-4131.105538265122;0.37466666666666665;86.26666666666667
230;-4104.596048317049;0.35733333333333334;86.63333333333333
235;-4079.6156492501345;0.358;86.4
240;-4064.2100645743985;0.3373333333333333;86.8
245;-4112.5469135434205;0.372;86.3
250;-4094.395842712202;0.3353333333333333;86.96666666666667
255;-4048.2270270213844;0.35133333333333333;86.36666666666667
260;-4057.251490902042;0.3486666666666667;86.5
265;-4019.4817478782143;0.32666666666666666;86.8
270;-4086.5606717391124;0.354;86.53333333333333
275;-4043.048750317252;0.338;86.76666666666667
280;-4073.5743264286466;0.338;86.83333333333333
285;-4154.489090533987;0.396;85.76666666666667
290;-4099.234321442744;0.3473333333333333;86.76666666666667
295;-4077.5362078584544;0.3566666666666667;86.4
300;-4047.1805307338554;0.35533333333333333;86.23333333333333
