Train dataset: data/regression/data.activation.train.100.csv
Test dataset: data/regression/data.activation.test.100.csv
Layers: [1, 4, 2, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.26157263610595544;inf
10;0.103677675029623;inf
15;0.004041942359797938;inf
20;0.0022816920311162425;0.03078509655177683
25;0.003898685146449269;0.051561464973972376
30;0.0021146097553842416;0.03672500252503967
35;0.00267007399703723;0.043918024185068315
40;0.0024973808779186536;0.04255214277482324
45;0.0018316035283129294;0.037764251508016405
50;0.0021285397065082595;0.04041632242804356
55;0.0017718675301712137;0.03796545390034317
60;0.0011502567047076114;0.030828631270955864
65;0.0016091639286046533;0.0384378088331894
70;0.0011267099711232045;0.03328719949527013
75;0.0018446825606019265;0.041123909386827424
80;0.0008352963537231431;0.02885175066762265
85;0.0011549952147535813;0.03590240106898603
90;0.0009899141793923679;0.0340410631227843
95;0.0007970144995398757;0.030034719128179246
100;0.0009962100603933689;0.03465032217205418
105;0.0007838847291175523;0.031132219867743748
110;0.0008587270802552582;0.032623321707104726
115;0.0014636908216097437;0.03896020002929495
120;0.0011992225808969052;0.03666531723714256
125;0.0011093300222099096;0.03571020099194353
130;0.0009328179519760922;0.033416399525179115
135;0.0009827249961168127;0.033995823717022346
140;0.0009588731566291019;0.03340056681769898
145;0.0010914716788887316;0.0350991526099627
150;0.0010314065521755177;0.03433588863825731
155;0.0009352292654842829;0.033029585017500765
160;0.0009846283583898063;0.03368997321572307
165;0.0009576389328598095;0.03323455690986624
170;0.0009981481033787887;0.03375003814294547
175;0.0009926654410534435;0.033703876304217124
180;0.0010084719526988297;0.033970482820757195
185;0.000996612618606139;0.033932802835039064
190;0.000882196168289544;0.03210929091610601
195;0.0009223811028637458;0.032569519265484036
200;0.001076390831084175;0.034951742564279825
205;0.0009378698124997892;0.03334314265962946
210;0.0008777690583192085;0.03255057087406823
215;0.0008887614454259944;0.032946957340838114
220;0.0008476387203269599;0.03217173283601058
225;0.0008199967806272536;0.03192063954872936
230;0.0008722225183502115;0.032832241515929825
235;0.0008769477795417725;0.032965758935895685
240;0.000787598256076979;0.03165921859560631
245;0.000784419978319273;0.031852013091762825
250;0.0007876249484254149;0.03191302257833704
255;0.0007640462771987419;0.03176755440597239
260;0.0007360571438718955;0.031394479817104186
265;0.0007066671906092341;0.03058690231034271
270;0.0006697369034693047;0.03025254227057526
275;0.0007846523896121693;0.032562323333570314
280;0.0007173691793603847;0.031223672940623552
285;0.0006721084411149678;0.030733433354967057
290;0.0006664999335362056;0.030664298016854035
295;0.0006477438417205765;0.030375612885251417
300;0.0006412250717728609;0.030297626542875152
