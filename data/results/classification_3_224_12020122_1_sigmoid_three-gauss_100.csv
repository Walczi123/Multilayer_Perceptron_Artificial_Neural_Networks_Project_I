Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 128, 64, 32, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-383.214546526868;0.06666666666666667;90.0
10;-434.1561738303761;0.06;93.33333333333333
15;-440.1589319007695;0.09333333333333334;92.66666666666666
20;-442.4739393970955;0.08;92.66666666666666
25;-455.31748808752207;0.05333333333333334;93.0
30;-450.3862398723733;0.12;92.0
35;-427.5645004983674;0.05333333333333334;93.33333333333333
40;-432.991894490524;0.07333333333333333;93.0
45;-422.05788820498185;0.10666666666666667;92.66666666666666
50;-468.9719669608317;0.06666666666666667;92.66666666666666
55;-452.95036465672376;0.05333333333333334;93.0
60;-444.0436838283891;0.06666666666666667;92.33333333333333
65;-427.66873236731215;0.09333333333333334;93.0
70;-468.7885167906579;0.04;93.0
75;-436.00004911740984;0.08666666666666667;93.33333333333333
80;-463.29545568065066;0.04;93.33333333333333
85;-457.0571315056111;0.06666666666666667;93.0
90;-465.662579111449;0.06666666666666667;93.0
95;-454.50655790463907;0.04;93.33333333333333
100;-442.879404488537;0.07333333333333333;92.66666666666666
105;-451.6683022645485;0.07333333333333333;92.66666666666666
110;-450.11210901663327;0.04;93.33333333333333
115;-459.47637087088174;0.06;93.66666666666667
120;-458.2599755965573;0.07333333333333333;93.33333333333333
125;-445.0245129980675;0.06;93.33333333333333
130;-445.7697760630998;0.08;93.0
135;-450.92303919951627;0.05333333333333334;93.0
140;-452.70124736869934;0.10666666666666667;92.0
145;-461.90916141953073;0.05333333333333334;92.33333333333333
150;-453.34227856478697;0.07333333333333333;93.33333333333333
155;-459.7119369755278;0.05333333333333334;93.0
160;-456.1805342048774;0.06;93.33333333333333
165;-463.1776726283276;0.05333333333333334;92.66666666666666
170;-449.70664392519177;0.06666666666666667;92.66666666666666
175;-459.82972002785084;0.04;93.66666666666667
180;-458.0900766097618;0.07333333333333333;92.66666666666666
185;-460.9283322498523;0.04;93.33333333333333
190;-459.7119369755278;0.05333333333333334;93.0
195;-470.528160208747;0.05333333333333334;93.0
200;-455.89285216575894;0.07333333333333333;93.33333333333333
205;-456.06275115255437;0.07333333333333333;92.66666666666666
210;-457.39692947920184;0.06666666666666667;93.0
215;-453.8134107740791;0.06;93.33333333333333
220;-447.3916364288658;0.06;93.33333333333333
225;-462.02694447185377;0.04;93.0
230;-453.2901626303145;0.05333333333333334;93.0
235;-455.3696040219944;0.04666666666666667;93.66666666666667
240;-450.92303919951627;0.05333333333333334;93.0
245;-446.0574581022183;0.06666666666666667;93.0
250;-458.0900766097618;0.07333333333333333;92.66666666666666
255;-460.3394169882372;0.06666666666666667;92.66666666666666
260;-452.13943447384077;0.04;93.33333333333333
265;-457.2791464268788;0.06;93.0
270;-460.3394169882372;0.06666666666666667;92.66666666666666
275;-459.0709057794403;0.04;92.66666666666666
280;-446.5807062459828;0.04666666666666667;93.66666666666667
285;-462.02694447185377;0.04;93.0
290;-455.89285216575894;0.07333333333333333;93.33333333333333
295;-449.7587598596641;0.06;93.33333333333333
300;-453.2901626303145;0.03333333333333333;93.66666666666667
