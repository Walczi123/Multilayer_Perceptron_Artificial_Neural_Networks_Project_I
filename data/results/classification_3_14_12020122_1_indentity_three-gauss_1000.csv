Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 8, 4, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-3411.4301705865073;0.186;81.73333333333333
10;-4037.901753577959;0.24;88.53333333333333
15;-4857.886557875766;0.18466666666666667;86.76666666666667
20;-4477.3758335443345;0.184;90.4
25;-4534.333770101614;0.194;90.13333333333333
30;-4276.250578616841;0.19866666666666666;90.60000000000001
35;-3927.4370465436887;0.08733333333333333;90.03333333333333
40;-4220.9624407617175;0.2673333333333333;89.0
45;-3514.5829547914527;0.12866666666666668;85.13333333333334
50;-4203.723424794153;0.08933333333333333;92.53333333333333
55;-3994.774461277907;0.14333333333333334;89.8
60;-4586.839945849203;0.138;91.56666666666666
65;-4241.69954275683;0.15;91.33333333333333
70;-4040.9276369863046;0.16333333333333333;89.9
75;-4172.448408019645;0.152;90.66666666666666
80;-4231.403460479202;0.122;91.13333333333333
85;-4083.794349613995;0.25133333333333335;88.3
90;-4352.578070078706;0.19466666666666665;90.7
95;-4419.935302393426;0.16866666666666666;90.96666666666667
100;-4026.170368292913;0.23666666666666666;88.13333333333333
105;-4294.504862927873;0.072;92.53333333333333
110;-3607.004948440755;0.572;79.03333333333333
115;-4087.5946872531717;0.13133333333333333;90.83333333333333
120;-3946.38131877633;0.17133333333333334;88.93333333333334
125;-3907.155436775449;0.21666666666666667;87.76666666666667
130;-4224.662724130031;0.088;92.46666666666667
135;-4306.540588623589;0.204;90.60000000000001
140;-4835.658929750591;0.16533333333333333;86.23333333333333
145;-3928.852531970606;0.09133333333333334;89.73333333333333
150;-4248.089018748073;0.078;92.43333333333334
155;-4253.87078028633;0.23866666666666667;89.23333333333333
160;-4408.785547583739;0.124;92.23333333333333
165;-4050.6796351505345;0.24133333333333334;88.23333333333333
170;-4042.082542740861;0.124;90.53333333333333
175;-4517.852497972553;0.22333333333333333;90.5
180;-4040.8067467458086;0.092;89.83333333333333
185;-4496.35974093798;0.12;91.8
190;-4493.969692738507;0.126;91.73333333333333
195;-4504.736907225426;0.186;90.73333333333333
200;-3917.8101162180365;0.10533333333333333;89.66666666666666
205;-4328.190763871488;0.12266666666666666;92.4
210;-4445.227378678042;0.15666666666666668;91.3
215;-4232.153919531449;0.12933333333333333;91.73333333333333
220;-3954.7209907225915;0.10266666666666667;89.7
225;-3990.8021358528945;0.29333333333333333;86.76666666666667
230;-4368.0514106713335;0.178;90.83333333333333
235;-4339.985727475345;0.16;91.63333333333334
240;-3608.5445353378946;0.12666666666666668;85.8
245;-4089.502140859015;0.16466666666666666;90.03333333333333
250;-4115.644730466741;0.188;89.63333333333333
255;-4006.6226112261443;0.11333333333333333;89.03333333333333
260;-4254.09697280568;0.16933333333333334;91.13333333333333
265;-3903.3478143500183;0.25;87.4
270;-4240.927177325041;0.16733333333333333;91.0
275;-4051.792816945047;0.43533333333333335;84.56666666666666
280;-4233.7372151461195;0.116;91.83333333333333
285;-3877.982786161295;0.34;85.03333333333333
290;-3820.498494272077;0.18533333333333332;87.66666666666667
295;-4330.6735815555685;0.162;91.3
300;-4571.706403230166;0.12866666666666668;91.7
