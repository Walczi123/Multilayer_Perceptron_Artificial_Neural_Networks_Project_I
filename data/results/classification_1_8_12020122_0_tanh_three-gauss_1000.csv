Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4048.464681925072;0.31466666666666665;86.9
10;-4040.907819405804;0.2753333333333333;87.8
15;-4046.296648646866;0.2653333333333333;87.66666666666667
20;-4114.49710949844;0.3486666666666667;86.5
25;-4249.232410097515;0.386;85.6
30;-4079.99610077386;0.3393333333333333;86.6
35;-4111.912148744456;0.2673333333333333;88.13333333333333
40;-4029.7559757970757;0.20533333333333334;89.13333333333333
45;-4046.779243240496;0.2906666666666667;87.36666666666667
50;-4081.6471523054233;0.2906666666666667;87.6
55;-4107.776190729772;0.324;87.03333333333333
60;-4083.3461421733778;0.30733333333333335;86.9
65;-4129.304405327265;0.31333333333333335;87.3
70;-4117.337453937572;0.31066666666666665;87.4
75;-4118.9071983688655;0.30533333333333335;87.5
80;-4139.734981049543;0.19333333333333333;89.66666666666666
85;-4085.0722344080887;0.31;87.23333333333333
90;-4177.512008859627;0.32066666666666666;87.4
95;-4086.811877826178;0.308;87.33333333333333
100;-4097.106941714673;0.2733333333333333;87.96666666666667
105;-4046.1267496600713;0.26666666666666666;88.1
110;-3947.218280916061;0.394;84.89999999999999
115;-4037.3743278361126;0.31133333333333335;86.93333333333332
120;-4045.6785422194534;0.32133333333333336;86.76666666666667
125;-4118.893647185488;0.314;87.13333333333333
130;-4097.568700338669;0.206;89.33333333333333
135;-4186.5500239236635;0.31066666666666665;87.5
140;-4188.498131079641;0.31933333333333336;87.06666666666666
145;-4161.569624856748;0.31066666666666665;87.36666666666667
150;-4076.0332009549206;0.12466666666666666;90.96666666666667
155;-4079.2008105733967;0.2946666666666667;87.46666666666667
160;-4120.326861393865;0.18466666666666667;89.7
165;-4139.74435463484;0.25533333333333336;88.5
170;-3931.2758969131824;0.38533333333333336;84.86666666666667
175;-4212.787471815038;0.2813333333333333;88.13333333333333
180;-4209.37385209671;0.2846666666666667;88.26666666666667
185;-4171.212195164819;0.24866666666666667;88.7
190;-4153.804298599592;0.24933333333333332;88.76666666666667
195;-4148.121520922287;0.368;86.06666666666666
200;-4056.7730739064946;0.2613333333333333;87.96666666666667
205;-4111.9621758798885;0.31066666666666665;87.36666666666667
210;-4135.834589139505;0.24133333333333334;88.46666666666667
215;-4134.706785751706;0.29933333333333334;87.36666666666667
220;-4003.946917765818;0.29;87.3
225;-4172.51927112471;0.26266666666666666;88.36666666666667
230;-4130.480147051454;0.3373333333333333;86.73333333333333
235;-4242.590709630074;0.342;86.6
240;-4116.005364409965;0.2793333333333333;88.03333333333333
245;-4182.690285563759;0.338;86.8
250;-4183.084288270864;0.308;87.56666666666668
255;-4037.3263894997217;0.23733333333333334;88.2
260;-4085.62258491861;0.2926666666666667;87.53333333333333
265;-4033.283200969645;0.27066666666666667;87.96666666666667
270;-4078.641086477579;0.256;88.23333333333333
275;-4106.8245527258905;0.268;88.16666666666667
280;-4095.143194576275;0.304;87.4
285;-4094.552190515619;0.34933333333333333;86.3
290;-4115.258012545893;0.30866666666666664;87.5
295;-4142.4241736724725;0.2806666666666667;87.93333333333334
300;-4039.3651773412666;0.26066666666666666;87.7
