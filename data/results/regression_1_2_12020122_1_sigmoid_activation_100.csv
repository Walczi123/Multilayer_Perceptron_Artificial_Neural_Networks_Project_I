Train dataset: data/regression/data.activation.train.100.csv
Test dataset: data/regression/data.activation.test.100.csv
Layers: [1, 2, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.0028724483737450957;0.10716824870340043
10;0.0010091916267314426;0.041125368861766584
15;0.0018553106893362168;0.046248468641168695
20;0.0018074512403771757;0.037526790779829115
25;0.0023827029070963885;0.043930814615280686
30;0.001948937742536162;0.03878009085473893
35;0.0023299785591694715;0.04078378842240208
40;0.002151075913779702;0.040477947755902806
45;0.002364045620732525;0.041457082156507855
50;0.0021287823152660616;0.038761729902360015
55;0.002236246830672481;0.03983723924631088
60;0.00217248171848783;0.039584003980682715
65;0.0020110346696677432;0.040491299265671826
70;0.0019609211856646933;0.03894696747605206
75;0.0024963963309322258;0.043764238766101256
80;0.0023756896434300023;0.04129002011158355
85;0.0024660515425032397;0.04269668035082005
90;0.0026244151731731175;0.044067764890815764
95;0.0022257332260606742;0.03883493837850165
100;0.002439743745905195;0.04268932052421502
105;0.00208781043682906;0.039770268949008335
110;0.002101722756493335;0.039367357535529696
115;0.0027544036125960267;0.04488809665045049
120;0.002097659490538894;0.04218495546829237
125;0.002557622387269887;0.04346965467204231
130;0.002127143895776294;0.04033424382581417
135;0.0024963022477667604;0.04171000474591887
140;0.0026138839155017838;0.04262934087405086
145;0.0024117833148949376;0.04330559932111069
150;0.0022867249593803264;0.04267090663525763
155;0.0020417584350722897;0.04117257914686551
160;0.0023697483014539864;0.0435338608627757
165;0.002576913708655912;0.04395275931479776
170;0.0024196624873043886;0.04385609258861547
175;0.0027102954857116247;0.04463356184028037
180;0.0026823691971813515;0.045161150473051116
185;0.0023765527330200766;0.044515198439366944
190;0.002496024465189881;0.04312836926009236
195;0.002625274117654752;0.044176536971685804
200;0.0030450889252177735;0.04771901186390051
205;0.0026786366879114408;0.04562176294705544
210;0.0023129038551848334;0.043843469850427474
215;0.002458829509540106;0.04509090253486908
220;0.0025385925914315553;0.04449052303616658
225;0.002242609910820081;0.04352226713733055
230;0.002752659277384287;0.04591020521951459
235;0.002799839469871103;0.04632524376837685
240;0.002601845309165883;0.04522611582227103
245;0.002335289358838743;0.04459536839267173
250;0.002720952236693009;0.045799563325430774
255;0.0021802861262647448;0.044247555180025294
260;0.002460127696945587;0.04537951620383547
265;0.0027754824613574767;0.04546636435100386
270;0.002050236259834319;0.0434431700614167
275;0.002598249196753115;0.04640524979982287
280;0.0025045086399547913;0.04511104705935932
285;0.0024688349225415996;0.044994670609947704
290;0.002232563957795894;0.043986892358288114
295;0.0024084385311086737;0.04535814093715168
300;0.002504379897033893;0.04556152667400707
