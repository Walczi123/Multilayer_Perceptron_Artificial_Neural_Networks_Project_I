Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 256, 128, 64, 32, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4237.162297248786;0.12933333333333333;90.53333333333333
10;-4376.28476194961;0.07333333333333333;93.43333333333334
15;-5361.967240034942;1.4513333333333334;59.63333333333334
20;-4219.715835932464;0.128;91.83333333333333
25;-4825.8287316742635;0.23533333333333334;84.7
30;-4157.896495875968;0.098;91.76666666666667
35;-4506.367122787357;0.102;92.33333333333333
40;-3409.3267340162442;0.07866666666666666;84.43333333333334
45;-4530.20097129588;0.154;89.63333333333333
50;-4445.266961818269;0.22733333333333333;89.1
55;-3435.9309261856374;1.372;62.0
60;-5730.910211670999;1.3053333333333332;58.699999999999996
65;-4463.233564090182;0.274;88.16666666666667
70;-4284.234812607093;0.136;91.53333333333333
75;-4670.8670964503735;0.13933333333333334;90.7
80;-2021.6679809732163;0.5426666666666666;55.733333333333334
85;-4348.035628583447;0.11466666666666667;92.33333333333333
90;-4222.928276699156;0.19466666666666665;90.76666666666667
95;-5918.601880215767;0.252;60.43333333333333
100;-4754.619097806672;0.178;89.93333333333334
105;-5563.371769784614;0.25933333333333336;71.43333333333334
110;-3945.4953478903;0.10933333333333334;88.53333333333333
115;-4633.939563574268;0.164;91.3
120;-1305.1966468443543;0.09266666666666666;63.366666666666674
125;-4511.452630006881;0.122;91.73333333333333
130;-5072.838279462407;0.20933333333333334;83.93333333333334
135;-4556.80114192952;0.134;90.23333333333333
140;-4162.7850017419405;0.13466666666666666;90.13333333333333
145;-4627.782546499498;0.208;86.63333333333333
150;-3609.3481287137465;0.38866666666666666;81.86666666666666
155;-3577.747935558934;0.19866666666666666;84.7
160;-4282.954839013959;0.08466666666666667;92.2
165;-4300.250148514078;0.184;89.86666666666666
170;-3980.521693557686;0.16733333333333333;88.13333333333333
175;-4022.757818984493;0.136;88.33333333333333
180;-4306.726127592805;0.15533333333333332;91.3
185;-4191.702268670947;0.11333333333333333;91.4
190;-2441.205445132159;0.132;73.16666666666667
195;-4755.844866666293;0.17133333333333334;89.2
200;-1672.6000836040478;0.09;66.33333333333333
205;-4049.6487788454247;0.3586666666666667;84.2
210;-4686.265396339854;0.14666666666666667;91.13333333333333
215;-4936.6353775019425;0.16933333333333334;88.2
220;-4136.524629081891;0.15933333333333333;89.60000000000001
225;-4042.8934729237444;0.124;89.4
230;-5606.877476830127;0.7913333333333333;65.66666666666666
235;-5781.128430268241;0.8493333333333334;61.03333333333333
240;-2313.8383608949653;0.164;72.3
245;-5081.604252469744;0.22533333333333333;76.4
250;-5867.107813602695;0.228;61.16666666666667
255;-3706.4398245374787;0.17;85.56666666666666
260;-4854.633411538162;0.4653333333333333;79.16666666666666
265;-2729.698622516598;0.672;58.56666666666667
270;-3417.1264994471894;0.46266666666666667;74.06666666666666
275;-5044.882990490933;0.906;60.333333333333336
280;-4727.908376886188;0.5613333333333334;75.36666666666667
285;-4505.191329042391;0.496;81.2
290;-3855.872993109218;0.192;86.63333333333333
295;-4682.042883216908;0.49866666666666665;79.80000000000001
300;-5835.930866341561;1.39;48.333333333333336
