Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 16, 8, 4, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-2599.7652726752362;0.366;68.33333333333333
10;-4081.1259929607004;0.25333333333333335;88.53333333333333
15;-4916.022324956277;0.19866666666666666;85.66666666666667
20;-4529.010607978403;0.18066666666666667;89.83333333333333
25;-4604.121704165943;0.19866666666666666;89.13333333333333
30;-4270.888851742536;0.19133333333333333;90.73333333333333
35;-3972.7542785014875;0.08933333333333333;90.4
40;-4296.977236616749;0.24866666666666667;89.56666666666668
45;-3484.267931216989;0.12133333333333333;84.86666666666667
50;-4204.928357684141;0.07466666666666667;92.63333333333334
55;-3954.2936192516077;0.17666666666666667;88.83333333333333
60;-4563.288583392583;0.174;91.16666666666666
65;-4142.876558711172;0.15933333333333333;90.93333333333334
70;-4076.135344024824;0.16533333333333333;90.23333333333333
75;-4151.012962906759;0.142;90.86666666666666
80;-4150.418851657929;0.098;91.3
85;-4100.6133309176075;0.252;88.36666666666667
90;-4418.5219057655495;0.18266666666666667;90.73333333333333
95;-4447.518390995785;0.16866666666666666;90.83333333333333
100;-4091.6503565567186;0.32066666666666666;87.03333333333333
105;-4392.254248319245;0.08333333333333333;92.60000000000001
110;-3614.785914680331;0.5886666666666667;78.9
115;-4082.0630613920703;0.128;90.86666666666666
120;-3921.15180242139;0.18333333333333332;88.53333333333333
125;-4015.0664630205747;0.238;88.0
130;-4294.99891990584;0.10066666666666667;92.5
135;-4341.591947858691;0.19733333333333333;90.86666666666666
140;-4844.028811251782;0.17;85.76666666666667
145;-3814.896005305911;0.10266666666666667;88.7
150;-4147.061525472156;0.12133333333333333;89.83333333333333
155;-4396.663266779762;0.25466666666666665;89.3
160;-4448.3105740080755;0.14533333333333334;91.83333333333333
165;-4042.1221258810874;0.30866666666666664;87.0
170;-3990.434217123415;0.134;89.93333333333334
175;-4490.681140858758;0.13266666666666665;92.46666666666667
180;-4043.656464770236;0.09333333333333334;90.36666666666666
185;-4423.708537665846;0.096;92.33333333333333
190;-4528.250775340861;0.15;91.13333333333333
195;-4566.00380797236;0.30933333333333335;87.86666666666667
200;-3868.5018116646324;0.12333333333333334;89.03333333333333
205;-4273.522821242819;0.10866666666666666;92.33333333333333
210;-4177.021111090609;0.10466666666666667;91.3
215;-4281.199555613451;0.124;92.0
220;-4010.2269659009007;0.10266666666666667;90.03333333333333
225;-4033.0570084502947;0.334;86.2
230;-4428.814880855004;0.182;90.7
235;-4343.515041446954;0.19266666666666668;90.93333333333334
240;-3671.4103716819195;0.13;86.66666666666667
245;-4107.354067266778;0.17133333333333334;90.06666666666666
250;-4215.29010707962;0.21133333333333335;89.73333333333333
255;-3914.5705730845866;0.09133333333333334;89.5
260;-4225.587259767155;0.14133333333333334;91.66666666666666
265;-4007.7618249775046;0.3486666666666667;85.96666666666667
270;-4208.360724573061;0.17533333333333334;90.66666666666666
275;-4162.974666288461;0.44266666666666665;84.96666666666667
280;-4305.853707890154;0.10866666666666666;92.13333333333334
285;-3822.368401515959;0.4033333333333333;83.39999999999999
290;-3783.8502882389253;0.21;86.93333333333332
295;-4271.15569781202;0.11733333333333333;92.10000000000001
300;-4566.016340766606;0.14;91.53333333333333
