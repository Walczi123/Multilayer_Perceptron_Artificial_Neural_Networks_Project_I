Train dataset: data/regression/data.activation.train.100.csv
Test dataset: data/regression/data.activation.test.100.csv
Layers: [1, 8, 4, 2, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.5230587948964477;0.07059027078780321
10;0.218957666194076;0.10456151727088107
15;0.3774278387662373;0.07091022205046099
20;0.24349669551335393;0.07824373299649923
25;0.47764170881144224;0.07050671971849846
30;0.5165037438137418;0.07057242590393922
35;0.35608461580419604;0.0712018245834426
40;0.2856935801607403;0.07356653603667386
45;0.37123881425160954;0.07098327364657295
50;0.3677313373092354;0.0710285949486596
55;0.33363560711222995;0.07165755549453656
60;0.3167648259920559;0.07214336352404249
65;0.2582446802017067;0.07595020199925132
70;0.3081340797287018;0.07245657872590285
75;0.3747092245960724;0.07094126116355128
80;0.2764314251853367;0.07420125759399616
85;0.3252271700160672;0.07188116081801676
90;0.30814126487083005;0.07245629624369088
95;0.2763631544044746;0.07420644870295011
100;0.39355800029890436;0.07075643160852194
105;0.25345298373265773;0.07657686337858279
110;0.22018492759355296;0.08851351541491849
115;0.42079724924254347;0.07059245559579216
120;0.2740477201398436;0.07438752670286723
125;0.30055680238533733;0.0727772827555092
130;0.6525375397380254;0.0711749362929114
135;0.388974499084687;0.07079519898502837
140;0.5182380942574496;0.07057698311839303
145;0.3959980468410646;0.07073725604851816
150;0.5063168168015846;0.07054818462600408
155;0.36044078367987414;0.07113270365355194
160;0.21840070051930474;0.09157396468980399
165;0.3300341983706127;0.07174920685750327
170;0.2643438055122966;0.07526890515672452
175;0.36484888640754254;0.07106810391710058
180;0.2392156934806641;0.07917972392869614
185;0.22741077555442202;0.0831371917536601
190;0.28957381749753525;0.07333656265287376
195;0.4464294461885269;0.07051957143219675
200;0.2442514596502035;0.0780951235074127
205;0.47635787691949955;0.07050592653606147
210;0.23819732256609874;0.07942939211284798
215;0.2647656659371856;0.07522586103251551
220;0.4339814848308571;0.07054669471747911
225;0.2216044969916784;0.0869728653089453
230;0.24576025479975375;0.07781072588674552
235;0.3122184545450194;0.0723020384722665
240;0.28912424402518205;0.07336225044355052
245;0.28101554884648106;0.07387068424299092
250;0.33489749788028345;0.07162681459960644
255;0.2685989221077984;0.0748557621855415
260;0.23937640561997936;0.07914137300655717
265;0.44286823578400947;0.07052587325798194
270;0.22780150317479167;0.08295135554325563
275;0.2785056688096211;0.07404738695436022
280;0.28094118959879466;0.07387577701412629
285;0.37653541600998175;0.07092023448965781
290;0.3157122312175917;0.07217891792756723
295;0.26094177904048615;0.07563458355663058
300;0.2322301572904279;0.08117906893194321
