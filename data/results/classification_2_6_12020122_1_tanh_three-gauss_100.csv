Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 4, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-433.4494755164378;0.08666666666666667;93.33333333333333
10;-429.0550266284321;0.08666666666666667;93.33333333333333
15;-442.64383838389085;0.08;93.33333333333333
20;-441.95069125333094;0.07333333333333333;93.66666666666667
25;-436.1699481042053;0.06666666666666667;93.33333333333333
30;-436.5754131956468;0.06;93.33333333333333
35;-434.09050671252544;0.05333333333333334;93.33333333333333
40;-434.9535528298808;0.08;93.0
45;-431.370034124758;0.07333333333333333;93.33333333333333
50;-441.4931102274171;0.08666666666666667;93.0
55;-441.4931102274171;0.08666666666666667;93.0
60;-435.18911893452685;0.06666666666666667;93.0
65;-429.29059273307814;0.07333333333333333;93.33333333333333
70;-439.8712498616511;0.06;93.66666666666667
75;-433.8549406078793;0.08;93.33333333333333
80;-448.8300466244581;0.13333333333333333;91.66666666666666
85;-446.93405540295197;0.09333333333333334;92.0
90;-449.23551171589963;0.12666666666666668;91.66666666666666
95;-442.7616214362139;0.08666666666666667;93.33333333333333
100;-434.9535528298808;0.08;93.0
105;-441.83290820100785;0.08666666666666667;93.0
110;-440.6821800445341;0.07333333333333333;93.33333333333333
115;-442.5917224494185;0.08666666666666667;92.66666666666666
120;-443.5068845012462;0.10666666666666667;93.0
125;-431.7754992161995;0.06666666666666667;93.33333333333333
130;-434.9535528298808;0.08;93.0
135;-440.6821800445341;0.07333333333333333;93.33333333333333
140;-446.5150391281322;0.1;92.66666666666666
145;-440.6821800445341;0.07333333333333333;93.33333333333333
150;-438.2493894958851;0.08;93.33333333333333
155;-440.6821800445341;0.07333333333333333;93.33333333333333
160;-436.5754131956468;0.06;93.33333333333333
165;-450.4519069902241;0.11333333333333333;92.0
170;-438.6027386528542;0.06;93.33333333333333
175;-451.44628734328074;0.08;92.66666666666666
180;-448.9478296767811;0.09333333333333334;92.66666666666666
185;-449.06561272910415;0.1;92.66666666666666
190;-439.46578477020955;0.08666666666666667;93.0
195;-462.60230855009075;0.10666666666666667;92.33333333333333
200;-441.4274431095664;0.09333333333333334;93.0
205;-442.23837329244935;0.10666666666666667;92.66666666666666
210;-438.2493894958851;0.08;93.33333333333333
215;-441.8464593843862;0.06666666666666667;93.0
220;-434.9535528298808;0.08;93.0
225;-436.1699481042052;0.08666666666666667;92.66666666666666
230;-463.00777364153225;0.1;92.33333333333333
235;-455.31748808752207;0.08;92.66666666666666
240;-447.3259693110151;0.11333333333333333;92.33333333333333
245;-440.1589319007695;0.09333333333333334;92.66666666666666
250;-462.19684345864925;0.08666666666666667;92.66666666666666
255;-461.6735953148847;0.10666666666666667;92.0
260;-453.2901626303145;0.08;92.66666666666666
265;-453.4079456826376;0.08666666666666667;92.66666666666666
270;-458.02440949191123;0.10666666666666667;92.33333333333333
275;-449.9943259643102;0.08;92.33333333333333
280;-435.42468503917297;0.06666666666666667;93.0
285;-464.6296340072982;0.08;92.66666666666666
290;-456.46821624399587;0.09333333333333334;92.33333333333333
295;-437.3863433785298;0.07333333333333333;93.0
300;-459.71193697552786;0.1;92.0
