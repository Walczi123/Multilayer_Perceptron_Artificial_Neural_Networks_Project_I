Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 64, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4342.60614579225;0.09733333333333333;93.06666666666666
10;-4257.6575667421275;0.116;92.30000000000001
15;-4341.874433910596;0.09066666666666667;92.83333333333333
20;-4378.754028450312;0.09533333333333334;93.26666666666667
25;-4419.925928808129;0.10666666666666667;92.7
30;-4418.016386403246;0.09533333333333334;93.23333333333333
35;-4383.451799359855;0.07266666666666667;93.66666666666667
40;-4375.969977543735;0.08066666666666666;93.2
45;-4397.1448429842585;0.086;93.43333333333334
50;-4450.924725927857;0.07466666666666667;93.63333333333334
55;-4420.344945082949;0.08733333333333333;93.5
60;-4502.32393425728;0.076;93.53333333333333
65;-4396.8686233294775;0.09;92.93333333333334
70;-4364.093706839608;0.08133333333333333;93.5
75;-4427.40775062425;0.09333333333333334;93.43333333333334
80;-4424.363120045311;0.07733333333333334;93.16666666666666
85;-4422.306603422307;0.088;93.36666666666666
90;-4497.460441959022;0.08533333333333333;92.96666666666667
95;-4442.645525112232;0.07466666666666667;93.53333333333333
100;-4427.461955357763;0.074;93.5
105;-4380.02462845815;0.07066666666666667;93.60000000000001
110;-4446.700176026647;0.07333333333333333;93.73333333333333
115;-4449.903243208044;0.08333333333333333;93.43333333333334
120;-4368.737273015638;0.07333333333333333;93.7
125;-4372.438574773085;0.07866666666666666;93.56666666666666
130;-4415.585684653637;0.07;93.60000000000001
135;-4417.678677228695;0.07666666666666666;93.33333333333333
140;-4456.286452802164;0.07666666666666666;93.26666666666667
145;-4454.521795816358;0.07733333333333334;93.60000000000001
150;-4423.2374054565535;0.07066666666666667;93.5
155;-4504.090680042124;0.08133333333333333;92.86666666666666
160;-4431.5030550888005;0.07733333333333334;93.5
165;-4346.987043496877;0.082;93.53333333333333
170;-4396.503811788171;0.078;93.23333333333333
175;-4438.420975211021;0.074;93.53333333333333
180;-4355.4225921159195;0.08333333333333333;93.33333333333333
185;-4359.5700125149415;0.072;93.66666666666667
190;-4423.314534958741;0.07933333333333334;93.5
195;-4460.982134912666;0.07666666666666666;93.7
200;-4413.114329353894;0.07133333333333333;93.86666666666666
205;-4482.025666117488;0.072;93.5
210;-4429.344395395892;0.07733333333333334;93.60000000000001
215;-4428.744017749939;0.08266666666666667;93.30000000000001
220;-4319.770855234865;0.07266666666666667;93.53333333333333
225;-4406.273538733861;0.072;93.36666666666666
230;-4417.665126045317;0.07133333333333333;93.56666666666666
235;-4440.500416602701;0.07866666666666666;93.43333333333334
240;-4442.881091216877;0.07933333333333334;93.43333333333334
245;-4462.812459016321;0.084;93.16666666666666
250;-4427.944549951393;0.07733333333333334;93.43333333333334
255;-4440.57963490393;0.072;93.46666666666667
260;-4432.116983918131;0.07466666666666667;93.53333333333333
265;-4393.887571069348;0.07666666666666666;93.33333333333333
270;-4384.144946490414;0.08;93.5
275;-4405.802406524569;0.07266666666666667;93.46666666666667
280;-4444.201718360147;0.07666666666666666;93.36666666666666
285;-4478.872626071523;0.08666666666666667;93.06666666666666
290;-4368.474604544235;0.08866666666666667;93.46666666666667
295;-4399.407734546112;0.07666666666666666;93.56666666666666
300;-4486.839131280314;0.07933333333333334;93.63333333333334
