Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-3971.3147978959864;0.296;87.2
10;-4009.8183416005095;0.29333333333333333;87.46666666666667
15;-3994.0187542176695;0.302;87.2
20;-4050.258530076674;0.272;88.16666666666667
25;-4174.019170840071;0.32866666666666666;87.53333333333333
30;-4021.9551919769983;0.2926666666666667;87.56666666666668
35;-4009.7161985306057;0.252;88.3
40;-4005.3603143936944;0.264;88.06666666666668
45;-3977.396774267609;0.28933333333333333;87.36666666666667
50;-4029.1243181862847;0.26066666666666666;88.26666666666667
55;-4014.527574894391;0.27666666666666667;87.86666666666667
60;-4010.0632812904523;0.34933333333333333;86.4
65;-4044.06085945177;0.24933333333333332;88.56666666666668
70;-4117.9805739327;0.262;88.83333333333333
75;-4090.5152683826645;0.2633333333333333;88.6
80;-4012.998484013232;0.258;88.16666666666667
85;-4024.7548828659947;0.2786666666666667;87.86666666666667
90;-4070.93724974019;0.24933333333333332;88.73333333333333
95;-4026.6915276376353;0.2633333333333333;88.2
100;-4013.4810786068615;0.2806666666666667;87.73333333333333
105;-4035.206294557907;0.254;88.43333333333334
110;-3874.9475291676526;0.37066666666666664;85.1
115;-3994.2293067546007;0.2793333333333333;87.7
120;-3977.226875280814;0.2886666666666667;87.36666666666667
125;-4090.5152683826645;0.2633333333333333;88.6
130;-4021.499699750125;0.25666666666666665;88.33333333333333
135;-4109.989055156193;0.27066666666666667;88.46666666666667
140;-4155.906664759946;0.3;87.96666666666667
145;-4047.588084624338;0.314;87.36666666666667
150;-4014.738127431321;0.256;88.26666666666667
155;-3991.4702694157386;0.272;87.8
160;-4050.272081260052;0.264;88.23333333333333
165;-4040.357468895282;0.282;87.9
170;-3404.069134969331;0.918;71.66666666666667
175;-4137.218794601584;0.272;88.7
180;-4198.032291920686;0.31933333333333336;87.7
185;-4094.21657014011;0.26266666666666666;88.63333333333333
190;-4102.221640099996;0.24666666666666667;88.96666666666667
195;-4018.7479471975194;0.342;86.63333333333333
200;-3949.956482285289;0.31133333333333335;86.73333333333333
205;-4005.176864223521;0.2673333333333333;88.0
210;-4081.6200499386673;0.2926666666666667;87.96666666666667
215;-4061.036188558799;0.25933333333333336;88.46666666666667
220;-3940.422321444245;0.31266666666666665;86.7
225;-4103.580831994358;0.2633333333333333;88.66666666666667
230;-4102.597914025639;0.3006666666666667;87.93333333333334
235;-4136.002399327259;0.2733333333333333;88.66666666666667
240;-4067.6007595240508;0.274;88.2
245;-4101.931869261836;0.2833333333333333;88.2
250;-4086.329283232548;0.278;88.26666666666667
255;-4005.1633130401424;0.27466666666666667;87.83333333333333
260;-4041.0912695759775;0.26;88.26666666666667
265;-4023.918939115396;0.2613333333333333;88.23333333333333
270;-4026.820773074296;0.28733333333333333;87.7
275;-3998.0619427477473;0.272;87.86666666666667
280;-4042.2941136669233;0.26666666666666666;88.23333333333333
285;-4113.0357745341735;0.282;88.33333333333333
290;-4043.680407928043;0.268;88.16666666666667
295;-4079.0580139533577;0.26866666666666666;88.4
300;-4009.9611382205485;0.30533333333333335;87.23333333333333
