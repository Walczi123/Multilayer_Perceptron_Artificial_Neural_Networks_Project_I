Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 16, 8, 4, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4467.316335760485;0.20866666666666667;90.33333333333333
10;-4049.6435828582107;0.11933333333333333;90.56666666666666
15;-4437.455786023763;0.176;90.7
20;-4327.434038422119;0.08;93.5
25;-4299.841576234463;0.11533333333333333;91.9
30;-4387.270884169625;0.07333333333333333;93.36666666666666
35;-4347.838627229895;0.08;93.4
40;-4346.75147739223;0.09133333333333334;92.96666666666667
45;-4361.361771867503;0.06933333333333333;93.73333333333333
50;-4468.765189951284;0.08866666666666667;92.56666666666666
55;-4003.3298817483137;0.09266666666666666;90.83333333333333
60;-4588.772413022762;0.11866666666666667;92.23333333333333
65;-4467.453936393311;0.09933333333333333;93.2
70;-4272.202194099549;0.132;91.66666666666666
75;-4115.847998217416;0.106;91.3
80;-4409.245217408694;0.13066666666666665;91.83333333333333
85;-4392.879639532914;0.092;92.80000000000001
90;-4448.1771509733335;0.07866666666666666;93.06666666666666
95;-4414.828959204267;0.084;92.93333333333334
100;-4321.6011793385205;0.108;92.43333333333334
105;-4425.45755466923;0.11133333333333334;92.9
110;-4302.720485424688;0.08866666666666667;91.86666666666666
115;-4417.141877901553;0.09533333333333334;93.0
120;-4157.842291142455;0.12533333333333332;91.26666666666667
125;-4529.754852654303;0.13933333333333334;91.33333333333333
130;-4428.562656378806;0.11666666666666667;92.36666666666666
135;-4299.132789121484;0.11333333333333333;92.30000000000001
140;-4519.029310106651;0.104;92.30000000000001
145;-4635.275830699956;0.16666666666666666;90.93333333333334
150;-4524.105443740878;0.142;91.5
155;-4886.509876368531;0.09066666666666667;89.36666666666667
160;-4365.88546619217;0.09733333333333333;92.76666666666667
165;-4380.389439999455;0.12466666666666666;92.30000000000001
170;-4461.720113191443;0.134;91.53333333333333
175;-4325.082554973739;0.07933333333333334;92.7
180;-4410.926478495187;0.116;92.9
185;-4454.741721938585;0.09466666666666666;92.80000000000001
190;-4340.458948483678;0.11133333333333334;92.73333333333333
195;-4827.1462516293595;0.09733333333333333;90.53333333333333
200;-4358.0680240005395;0.10666666666666667;92.4
205;-4641.496426093534;0.10466666666666667;92.5
210;-4679.173399632755;0.08666666666666667;92.53333333333333
215;-4731.322048625291;0.12133333333333333;91.46666666666667
220;-4499.889054909589;0.10266666666666667;92.96666666666667
225;-4307.933149281833;0.09133333333333334;93.23333333333333
230;-4455.097159894595;0.07066666666666667;93.5
235;-4588.484730983643;0.094;92.80000000000001
240;-4374.151115824417;0.08733333333333333;93.03333333333333
245;-4409.345271679556;0.092;93.30000000000001
250;-4372.127967965291;0.08866666666666667;92.83333333333333
255;-4511.379678102776;0.13933333333333334;91.56666666666666
260;-4493.262994424568;0.09666666666666666;92.86666666666666
265;-4479.135294542926;0.07266666666666667;92.96666666666667
270;-4550.682689605845;0.162;90.66666666666666
275;-4235.977181939299;0.09466666666666666;91.93333333333334
280;-4146.944760808965;0.14266666666666666;91.13333333333333
285;-4156.256906728741;0.13266666666666665;91.46666666666667
290;-4193.822363612762;0.098;92.26666666666667
295;-4356.87455349489;0.15933333333333333;90.93333333333334
300;-4323.0239495516935;0.146;91.66666666666666
