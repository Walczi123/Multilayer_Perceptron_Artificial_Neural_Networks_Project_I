Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-433.109677542847;0.05333333333333334;93.0
10;-433.109677542847;0.05333333333333334;93.0
15;-433.802824673407;0.06;92.66666666666666
20;-437.0986613394113;0.06;93.0
25;-433.109677542847;0.05333333333333334;93.0
30;-433.109677542847;0.05333333333333334;93.0
35;-433.109677542847;0.05333333333333334;93.0
40;-431.8411663340502;0.05333333333333334;92.66666666666666
45;-431.0302361511672;0.04;93.0
50;-439.4136688357372;0.07333333333333333;93.0
55;-439.4136688357372;0.07333333333333333;93.0
60;-433.109677542847;0.05333333333333334;93.0
65;-433.109677542847;0.05333333333333334;93.0
70;-439.4136688357372;0.07333333333333333;93.0
75;-433.92060772573;0.06666666666666667;92.66666666666666
80;-433.92060772573;0.06666666666666667;92.66666666666666
85;-431.8411663340502;0.05333333333333334;92.66666666666666
90;-440.1068159662972;0.08;92.66666666666666
95;-433.92060772573;0.06666666666666667;92.66666666666666
100;-431.8411663340502;0.05333333333333334;92.66666666666666
105;-433.92060772573;0.06666666666666667;92.66666666666666
110;-439.4136688357372;0.07333333333333333;93.0
115;-436.1178321697329;0.07333333333333333;92.66666666666666
120;-433.92060772573;0.06666666666666667;92.66666666666666
125;-433.109677542847;0.05333333333333334;93.0
130;-433.92060772573;0.06666666666666667;92.66666666666666
135;-433.92060772573;0.06666666666666667;92.66666666666666
140;-433.109677542847;0.05333333333333334;93.0
145;-439.4136688357372;0.07333333333333333;93.0
150;-433.92060772573;0.06666666666666667;92.66666666666666
155;-433.92060772573;0.06666666666666667;92.66666666666666
160;-433.92060772573;0.06666666666666667;92.66666666666666
165;-440.1068159662972;0.08;92.66666666666666
170;-436.1178321697329;0.07333333333333333;92.66666666666666
175;-439.4136688357372;0.07333333333333333;93.0
180;-433.92060772573;0.06666666666666667;92.66666666666666
185;-433.92060772573;0.06666666666666667;92.66666666666666
190;-436.1178321697329;0.07333333333333333;92.66666666666666
195;-439.4136688357372;0.07333333333333333;93.0
200;-433.802824673407;0.06;92.66666666666666
205;-440.1068159662972;0.08;92.66666666666666
210;-433.92060772573;0.06666666666666667;92.66666666666666
215;-436.1178321697329;0.07333333333333333;92.66666666666666
220;-431.8411663340502;0.05333333333333334;92.66666666666666
225;-439.4136688357372;0.07333333333333333;93.0
230;-439.4136688357372;0.07333333333333333;93.0
235;-433.92060772573;0.06666666666666667;92.66666666666666
240;-431.8411663340502;0.05333333333333334;92.66666666666666
245;-433.109677542847;0.05333333333333334;93.0
250;-439.4136688357372;0.07333333333333333;93.0
255;-439.4136688357372;0.07333333333333333;93.0
260;-431.8411663340502;0.05333333333333334;92.66666666666666
265;-440.1068159662972;0.08;92.66666666666666
270;-436.1178321697329;0.07333333333333333;92.66666666666666
275;-434.849320960936;0.07333333333333333;92.33333333333333
280;-431.8411663340502;0.05333333333333334;92.66666666666666
285;-431.8411663340502;0.05333333333333334;92.66666666666666
290;-433.92060772573;0.06666666666666667;92.66666666666666
295;-433.109677542847;0.05333333333333334;93.0
300;-433.92060772573;0.06666666666666667;92.66666666666666
