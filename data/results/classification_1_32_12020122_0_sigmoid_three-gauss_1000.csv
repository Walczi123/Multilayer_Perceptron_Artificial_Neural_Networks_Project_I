Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4242.8408973280075;0.09933333333333333;92.36666666666666
10;-4217.061030462547;0.12066666666666667;91.96666666666667
15;-4558.79927622093;0.09866666666666667;92.5
20;-4271.350610366532;0.11733333333333333;92.30000000000001
25;-4754.848397514194;0.102;91.43333333333334
30;-4355.878084342792;0.118;92.56666666666666
35;-4395.3666348150755;0.094;93.03333333333333
40;-4366.906948911983;0.09133333333333334;93.10000000000001
45;-4217.690599274298;0.09;92.63333333333334
50;-4452.428803241301;0.09333333333333334;93.03333333333333
55;-4266.761248924015;0.09533333333333334;92.73333333333333
60;-4694.490392421966;0.09666666666666666;92.03333333333333
65;-4331.056121878335;0.09733333333333333;92.83333333333333
70;-4259.38574777588;0.08466666666666667;92.86666666666666
75;-4284.692393633007;0.09133333333333334;92.93333333333334
80;-4553.883667988201;0.11;92.63333333333334
85;-4373.901998536392;0.1;93.0
90;-4495.471681252908;0.08933333333333333;93.30000000000001
95;-4379.18659590851;0.09133333333333334;93.23333333333333
100;-4482.680248496954;0.09333333333333334;93.13333333333334
105;-4331.096775428471;0.088;92.96666666666667
110;-4280.6127291508765;0.08466666666666667;92.96666666666667
115;-4371.1314988131935;0.084;93.30000000000001
120;-4229.997348637581;0.092;92.63333333333334
125;-4252.322942234579;0.08733333333333333;92.80000000000001
130;-4371.536963904635;0.08733333333333333;93.0
135;-4404.010647172008;0.09066666666666667;93.10000000000001
140;-4776.535048714147;0.1;91.36666666666666
145;-4565.717196343151;0.09133333333333334;92.9
150;-4313.858777850038;0.08733333333333333;93.03333333333333
155;-4550.859873378895;0.08866666666666667;92.83333333333333
160;-4355.096345325707;0.09;93.03333333333333
165;-4375.616628386766;0.09466666666666666;92.93333333333334
170;-4433.530380546008;0.09333333333333334;93.03333333333333
175;-4405.684623472246;0.09733333333333333;93.0
180;-4308.730528281337;0.10133333333333333;93.0
185;-4389.898587272784;0.09466666666666666;93.03333333333333
190;-4341.833780360461;0.08533333333333333;93.13333333333334
195;-4602.127747472615;0.09133333333333334;92.46666666666667
200;-4247.040433661502;0.07733333333333334;92.80000000000001
205;-4548.963882157388;0.08533333333333333;93.16666666666666
210;-4385.214367546619;0.10533333333333333;93.06666666666666
215;-4524.284716312971;0.08466666666666667;93.36666666666666
220;-4238.722668094782;0.078;92.7
225;-4527.827581467958;0.09;92.93333333333334
230;-4485.504952953666;0.092;93.2
235;-4621.628636612902;0.09266666666666666;92.46666666666667
240;-4400.569925086924;0.09466666666666666;93.10000000000001
245;-4557.161775872743;0.094;92.76666666666667
250;-4307.853930980604;0.10333333333333333;92.9
255;-4624.62532885545;0.09333333333333334;92.46666666666667
260;-4475.683110073504;0.08933333333333333;93.16666666666666
265;-4395.038299225823;0.09066666666666667;93.23333333333333
270;-4279.697567099049;0.08466666666666667;92.86666666666666
275;-4282.443053254532;0.08933333333333333;92.93333333333334
280;-4346.790042143325;0.09466666666666666;93.10000000000001
285;-4470.5798740725195;0.10133333333333333;93.0
290;-4261.306752565101;0.10466666666666667;92.63333333333334
295;-4435.897503976807;0.09066666666666667;93.16666666666666
300;-4640.515596923857;0.08666666666666667;92.63333333333334
