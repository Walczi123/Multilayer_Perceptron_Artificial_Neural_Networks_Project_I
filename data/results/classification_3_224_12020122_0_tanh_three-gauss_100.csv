Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 128, 64, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-407.82804525343533;0.14;91.0
10;-412.51017618055965;0.15333333333333332;90.66666666666666
15;-413.2033233111196;0.16;90.33333333333333
20;-406.2583008221418;0.2;89.0
25;-419.7949966431283;0.16;91.0
30;-422.39768617857266;0.14;91.66666666666666
35;-410.99254768373834;0.25333333333333335;89.0
40;-420.8414929306574;0.12666666666666668;91.33333333333333
45;-421.18129090424816;0.15333333333333332;91.33333333333333
50;-417.19230710768386;0.18666666666666668;87.33333333333333
55;-410.3265029199351;0.08;91.66666666666666
60;-408.11572729255386;0.14666666666666667;90.33333333333333
65;-383.5001397669455;0.4066666666666667;84.33333333333334
70;-414.44473215315975;0.36;85.66666666666667
75;-420.55381089153894;0.11333333333333333;91.66666666666666
80;-420.6059268260113;0.13333333333333333;91.0
85;-417.42787321233;0.12;91.33333333333333
90;-418.5264854343314;0.12666666666666668;90.0
95;-419.33741561721445;0.11333333333333333;91.33333333333333
100;-417.3757572778576;0.1;92.0
105;-413.72657145488415;0.14;91.0
110;-400.7381373453778;0.38666666666666666;84.0
115;-399.3132783331639;0.25333333333333335;86.66666666666667
120;-408.5211923839953;0.16;90.66666666666666
125;-412.562292115032;0.17333333333333334;90.0
130;-438.3400701814515;0.26;89.0
135;-418.7620515389775;0.12;92.33333333333333
140;-442.31550279463744;0.37333333333333335;84.33333333333334
145;-412.10471108911815;0.16;89.66666666666666
150;-423.0908333091326;0.14666666666666667;91.33333333333333
155;-423.14294924360496;0.22;88.0
160;-415.1128657160041;0.15333333333333332;89.33333333333333
165;-422.51546923089575;0.16666666666666666;88.33333333333333
170;-412.52372736393795;0.08;92.33333333333333
175;-422.9073831389589;0.24;87.66666666666667
180;-414.01425349400256;0.17333333333333334;89.0
185;-405.5130377571095;0.17333333333333334;89.0
190;-426.6222360797831;0.13333333333333333;91.66666666666666
195;-419.80854782650664;0.08666666666666667;91.66666666666666
200;-409.80325477617055;0.08;92.0
205;-419.6772135908052;0.2;87.66666666666667
210;-417.0880752387392;0.1;92.33333333333333
215;-394.1350016290318;0.14666666666666667;89.66666666666666
220;-418.47436949985905;0.11333333333333333;91.66666666666666
225;-415.5183308074455;0.18666666666666668;89.33333333333333
230;-418.2252522118347;0.21333333333333335;89.0
235;-419.80854782650664;0.08666666666666667;91.66666666666666
240;-422.5811363487464;0.11333333333333333;91.33333333333333
245;-417.4414243957083;0.04666666666666667;93.0
250;-411.4501287096522;0.3;86.0
255;-414.18415248079793;0.18666666666666668;87.66666666666667
260;-407.65814626663996;0.13333333333333333;91.0
265;-419.0361823947176;0.22;89.0
270;-428.6495615369905;0.11333333333333333;91.33333333333333
275;-416.4856087937456;0.25333333333333335;85.66666666666667
280;-419.6907647741836;0.10666666666666667;91.33333333333333
285;-399.86362884368515;0.1;89.66666666666666
290;-395.5327582744891;0.4;84.0
295;-403.3293644964849;0.12;90.0
300;-408.80887442311376;0.15333333333333332;90.0
