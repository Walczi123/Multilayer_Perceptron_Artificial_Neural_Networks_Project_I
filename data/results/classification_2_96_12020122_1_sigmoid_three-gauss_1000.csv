Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 64, 32, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4289.075380136675;0.088;92.9
10;-4203.94335091638;0.12;91.96666666666667
15;-4451.461525255;0.09333333333333334;93.06666666666666
20;-4357.891858616621;0.11666666666666667;93.0
25;-4576.610549078558;0.102;92.33333333333333
30;-4429.000419824219;0.13066666666666665;92.60000000000001
35;-4395.862780592083;0.07733333333333334;93.56666666666666
40;-4343.36496004066;0.078;93.2
45;-4336.99530162992;0.09;93.16666666666666
50;-4411.034887962214;0.07066666666666667;93.30000000000001
55;-4380.650019671818;0.09933333333333333;93.26666666666667
60;-4619.83687726034;0.07533333333333334;92.83333333333333
65;-4358.7569935330175;0.09266666666666666;93.0
70;-4331.488689336533;0.076;93.53333333333333
75;-4391.622590708454;0.10933333333333334;93.10000000000001
80;-4406.0265102448775;0.076;93.2
85;-4399.797559655134;0.09733333333333333;93.13333333333334
90;-4494.830650056821;0.07533333333333334;93.26666666666667
95;-4427.82676689907;0.07466666666666667;93.66666666666667
100;-4488.87791912186;0.07866666666666666;93.56666666666666
105;-4386.249401449811;0.08;93.53333333333333
110;-4382.9921295349;0.08533333333333333;93.4
115;-4424.451711931837;0.092;93.4
120;-4325.6943950040295;0.08733333333333333;93.23333333333333
125;-4320.776697972259;0.08866666666666667;93.26666666666667
130;-4389.794355403839;0.07266666666666667;93.56666666666666
135;-4388.931309286483;0.06866666666666667;93.60000000000001
140;-4552.506747312376;0.074;93.23333333333333
145;-4469.981585225608;0.08066666666666666;93.43333333333334
150;-4412.3169503543895;0.06666666666666667;93.8
155;-4587.363193992967;0.08466666666666667;92.46666666666667
160;-4408.799098767118;0.08733333333333333;93.23333333333333
165;-4392.841074781819;0.07933333333333334;93.76666666666667
170;-4445.941361778237;0.088;93.10000000000001
175;-4385.504138384778;0.07933333333333334;93.36666666666666
180;-4422.881967500543;0.09333333333333334;93.33333333333333
185;-4306.732393989928;0.08;93.06666666666666
190;-4417.4295599406705;0.07133333333333333;93.46666666666667
195;-4458.889142337608;0.07266666666666667;93.8
200;-4339.310309126245;0.07333333333333333;93.56666666666666
205;-4470.738310674978;0.07466666666666667;93.5
210;-4421.300760684912;0.08133333333333333;93.5
215;-4493.967603939465;0.08066666666666666;93.5
220;-4387.950480116805;0.07;93.7
225;-4388.904206919728;0.08866666666666667;93.10000000000001
230;-4414.59130430058;0.076;93.4
235;-4697.44643111438;0.098;92.03333333333333
240;-4419.86235048932;0.074;93.4
245;-4468.64531809992;0.07666666666666666;93.26666666666667
250;-4380.36442643174;0.07466666666666667;93.56666666666666
255;-4541.692612878199;0.082;92.9
260;-4449.001632339594;0.074;93.56666666666666
265;-4349.170716757501;0.088;93.2
270;-4392.541930358364;0.07333333333333333;93.56666666666666
275;-4345.143168209843;0.084;93.06666666666666
280;-4415.859815509377;0.08;93.4
285;-4479.565773202083;0.082;93.06666666666666
290;-4349.836761521305;0.096;93.23333333333333
295;-4424.623699717673;0.07266666666666667;93.76666666666667
300;-4464.108072591875;0.07133333333333333;93.73333333333333
