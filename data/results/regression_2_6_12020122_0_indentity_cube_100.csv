Train dataset: data/regression/data.cube.train.100.csv
Test dataset: data/regression/data.cube.test.100.csv
Layers: [1, 4, 2, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.35862930971591267;0.19319193966071965
10;0.34598395232046253;0.28934504870872674
15;0.39014209076377426;0.15947010711954712
20;0.3465114807056918;0.3020002753413357
25;0.42356392276795257;0.1443405594614666
30;0.37809983570345235;0.1682730189037638
35;0.42213174642273826;0.14482316559085995
40;0.43917934648725176;0.13968129519741285
45;0.44143381261603865;0.13908713543707865
50;0.3719716852220547;0.17411157373589017
55;0.43774793679168544;0.14006775291602722
60;0.42261894262271016;0.14465780491244706
65;0.5501282220484377;0.12223103740658449
70;0.39720372201068344;0.15540381604057169
75;0.40666328583999606;0.15081851526671208
80;0.5044508981878919;0.127358733541775
85;0.43703181993621015;0.1402638648305845
90;0.3653775331147012;0.18205785894558735
95;0.5076247321874457;0.12693812040285155
100;0.47950446170451644;0.13111919254713003
105;0.6552847550268036;0.11504706990319732
110;0.4425992795174787;0.1387867024664306
115;0.3682972607632596;0.1782747111441591
120;0.4528040484842073;0.1363345408238307
125;0.3510707782029318;0.2139251943948676
130;0.4294060370550787;0.14247561882065915
135;0.45297506574705343;0.136295971763601
140;0.35787359972845356;0.1947344109798023
145;0.39667207338245414;0.15568846165490965
150;0.3922402364593069;0.15819367908334245
155;0.387402684557975;0.16123572312730441
160;0.46561947413648475;0.13364365182100865
165;0.34574039476024226;0.2597349002614638
170;0.4824463108102724;0.13062842887130488
175;0.40733306428728494;0.15052435958622412
180;0.5364562810602032;0.12358060049073444
185;0.5083230240996329;0.12684710521878906
190;0.4267650046765728;0.14329885185315466
195;0.39199756342881387;0.15833815518525893
200;0.3983054804040417;0.15482396860324024
205;0.4061174772694168;0.15106092461793863
210;0.5045666993157865;0.12734318370649628
215;0.4302857172956906;0.14220829858721426
220;0.4922712977363836;0.1290865030431111
225;0.3578684887836579;0.19474511127937524
230;0.4473700030914734;0.13760204120575065
235;0.34671515079963633;0.24121996984795005
240;0.3498972355741564;0.21898051243127722
245;0.4060635165997922;0.15108502354271558
250;0.5387094170879615;0.1233487316776533
255;0.39168350930954265;0.15852632834434877
260;0.5199882518429484;0.12540274828577616
265;0.37006176017361053;0.1762018775915407
270;0.386023034096973;0.1621713637920516
275;0.37074584230746344;0.1754359194552028
280;0.39938824728504907;0.1542668824279142
285;0.38541123987753645;0.16259693446567774
290;0.4210530235595252;0.14519375267732082
295;0.4005886561951016;0.15366347919593684
300;0.4860804785045125;0.13004124755547528
