Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 128, 64, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4060.8183512356136;0.19066666666666668;89.43333333333334
10;-4102.053829912242;0.23533333333333334;88.26666666666667
15;-4089.7126933959453;0.21533333333333332;87.66666666666667
20;-4237.341569820877;0.18133333333333335;90.86666666666666
25;-4316.437472206899;0.26266666666666666;89.13333333333333
30;-4192.366224635709;0.15133333333333332;91.4
35;-4218.175282666967;0.142;90.7
40;-4104.297974303502;0.106;91.43333333333334
45;-4114.575309410537;0.144;90.9
50;-4133.906299564027;0.13933333333333334;90.66666666666666
55;-4413.335273865254;0.31666666666666665;87.63333333333333
60;-4086.566938136235;0.276;86.0
65;-4069.783414395543;0.09666666666666666;91.4
70;-4218.157553885508;0.182;89.93333333333334
75;-4165.204241107211;0.128;91.5
80;-4293.904485281921;0.21933333333333332;88.63333333333333
85;-4089.5021408590146;0.14733333333333334;90.63333333333333
90;-4226.03128960969;0.14733333333333334;91.33333333333333
95;-4195.3743792625955;0.16066666666666668;91.0
100;-4122.202016645737;0.09733333333333333;91.53333333333333
105;-4125.026721102449;0.114;91.53333333333333
110;-4042.8507305745675;0.15133333333333332;90.13333333333333
115;-4133.004688695579;0.112;90.86666666666666
120;-4083.750588875687;0.106;91.33333333333333
125;-4132.8055985429855;0.14933333333333335;90.9
130;-4115.571778562635;0.11133333333333334;91.5
135;-4420.452284140068;0.2846666666666667;87.83333333333333
140;-4249.102146271722;0.19333333333333333;89.76666666666667
145;-4159.878990184958;0.142;90.36666666666666
150;-4125.524955678498;0.09266666666666666;91.73333333333333
155;-4190.3795527286375;0.16;90.86666666666666
160;-4167.548439769334;0.09933333333333333;90.8
165;-4091.323091377374;0.106;91.10000000000001
170;-4045.999593022452;0.25266666666666665;88.06666666666668
175;-4173.415686005945;0.13133333333333333;91.26666666666667
180;-4167.204464197662;0.126;90.83333333333333
185;-4108.925900497113;0.12;91.16666666666666
190;-4133.9584154985005;0.14333333333333334;90.83333333333333
195;-4152.757802312062;0.248;88.23333333333333
200;-4241.837143389655;0.24466666666666667;87.9
205;-4082.2986274967166;0.10666666666666667;91.26666666666667
210;-4100.341288860909;0.19733333333333333;88.3
215;-4124.152212600757;0.10666666666666667;91.43333333333334
220;-4078.3388348659496;0.08866666666666667;91.4
225;-4184.401808225959;0.148;91.36666666666666
230;-4096.4628033304125;0.10133333333333333;91.46666666666667
235;-4469.162299846561;0.324;85.9
240;-4130.585449330307;0.09866666666666667;91.83333333333333
245;-4274.433805696565;0.17;91.33333333333333
250;-4111.37224222914;0.10333333333333333;91.60000000000001
255;-4160.000950835363;0.14733333333333334;89.83333333333333
260;-4128.49245675525;0.10866666666666666;91.66666666666666
265;-4065.638082795562;0.104;91.16666666666666
270;-4136.366192479433;0.116;91.60000000000001
275;-4127.629410637894;0.108;91.60000000000001
280;-4102.062185108405;0.084;91.73333333333333
285;-4116.054373156264;0.10333333333333333;91.43333333333334
290;-4142.185500379653;0.136;91.16666666666666
295;-4104.454322106919;0.13666666666666666;90.8
300;-4302.567244809445;0.2633333333333333;88.23333333333333
