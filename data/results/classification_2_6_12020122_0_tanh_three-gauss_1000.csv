Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 4, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4002.927523845045;0.26666666666666666;88.0
10;-3910.454380629627;0.382;85.03333333333333
15;-3665.2605873726293;0.536;80.26666666666667
20;-4125.383177447592;0.266;88.43333333333334
25;-4141.115008913541;0.2966666666666667;87.86666666666667
30;-3860.283029958867;0.4126666666666667;84.06666666666666
35;-4090.063953753873;0.16133333333333333;90.26666666666667
40;-3768.3779660354303;0.44133333333333336;82.86666666666666
45;-3900.25417502478;0.366;85.26666666666667
50;-3989.0145540984145;0.226;88.5
55;-3962.4154018539075;0.39;85.13333333333334
60;-4016.2015511946292;0.28;87.26666666666667
65;-4114.963045720518;0.20733333333333334;89.63333333333333
70;-4067.448589318716;0.20133333333333334;89.4
75;-4094.467776227175;0.22266666666666668;89.13333333333333
80;-4091.4523368140344;0.15733333333333333;90.03333333333333
85;-4033.03408368162;0.2786666666666667;87.7
90;-4077.139097963177;0.21533333333333332;89.16666666666667
95;-3992.4802897512145;0.22666666666666666;88.53333333333333
100;-4093.853847397844;0.21133333333333335;89.33333333333333
105;-4060.2315247730394;0.16466666666666666;90.16666666666666
110;-3902.883966926981;0.3506666666666667;85.66666666666667
115;-4076.907709456613;0.144;90.46666666666667
120;-4066.4385689832397;0.25066666666666665;88.53333333333333
125;-4115.262190143974;0.23133333333333334;89.03333333333333
130;-3463.0148138435916;0.7286666666666667;75.26666666666667
135;-4115.710397584591;0.17466666666666666;90.13333333333333
140;-4092.4967443025225;0.15733333333333333;90.33333333333333
145;-4101.3721451660185;0.24066666666666667;88.56666666666668
150;-3806.9628168402232;0.39666666666666667;84.03333333333333
155;-4076.391746099104;0.24;88.53333333333333
160;-4062.0232841256;0.17066666666666666;89.8
165;-4096.979785077053;0.20533333333333334;89.36666666666667
170;-3973.002325379604;0.28933333333333333;87.16666666666667
175;-4114.378308056985;0.14133333333333334;90.66666666666666
180;-4124.5243089283185;0.18733333333333332;89.86666666666666
185;-4091.946393792001;0.176;90.03333333333333
190;-4117.355182719032;0.22266666666666668;89.4
195;-4075.5901895015168;0.30666666666666664;87.13333333333333
200;-4060.9924278204903;0.12866666666666668;90.76666666666667
205;-3941.5594984173404;0.31666666666666665;86.36666666666667
210;-4096.819259675554;0.266;88.1
215;-4122.825319060365;0.172;90.16666666666666
220;-3944.9116286158987;0.25866666666666666;87.53333333333333
225;-4119.631625464264;0.21133333333333335;89.53333333333333
230;-3601.480607365909;0.6593333333333333;77.63333333333333
235;-4056.095566758354;0.214;88.5
240;-4135.498968763995;0.168;90.4
245;-4132.90983041193;0.15733333333333333;90.5
250;-4120.508222764998;0.204;89.66666666666666
255;-4099.2697790056645;0.18;89.73333333333333
260;-4074.208072838479;0.23533333333333334;88.76666666666667
265;-4089.921157133835;0.142;90.8
270;-4111.252370377776;0.14533333333333334;90.73333333333333
275;-4115.459191497525;0.21533333333333332;89.46666666666667
280;-4116.913241675537;0.17866666666666667;90.10000000000001
285;-4153.48014060842;0.19666666666666666;89.83333333333333
290;-4103.090952614474;0.14866666666666667;90.66666666666666
295;-4119.74003493129;0.15066666666666667;90.63333333333333
300;-3641.5038683662942;0.6293333333333333;78.26666666666667
