Train dataset: data/regression/data.cube.train.1000.csv
Test dataset: data/regression/data.cube.test.1000.csv
Layers: [1, 256, 128, 64, 32, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.41780238542292025;0.26107132647641795
10;0.4598868154859888;0.25403756881970757
15;0.4589167278505777;0.267089473989129
20;0.45911724328878084;0.25177048848174177
25;0.5374485407220742;0.2351278381579965
30;0.41244258916577176;0.30771514277935
35;0.44475908954627846;0.2774304680588922
40;0.4719985275506862;0.2678949623907768
45;0.47325919393843535;0.2397104409123769
50;0.4957597719217122;0.2778505905002549
55;0.47941406940466835;0.2151105749395934
60;0.4210894040794203;0.31232124044431747
65;0.4324358673290805;0.27582062905446797
70;0.42143567497844986;0.3155566049692123
75;0.4682702541173098;0.24461426618329452
80;0.4813636421889744;0.2609986861365957
85;0.44377119061936554;0.2552733877175067
90;0.37817736531317314;0.38640634955805037
95;0.4400092103889082;0.2576610295765159
100;0.4423947759576268;0.289725180288998
105;0.40515784082872836;0.34993210851651224
110;0.4346304191736884;0.2523902583741146
115;0.40872980943977244;0.28780088488698014
120;0.39903336723127075;0.33304441354956443
125;0.44204308457841796;0.25169158849399054
130;0.4872457411715059;0.2710098932110285
135;0.506416287055194;0.26525303937711986
140;0.5587511951083587;0.27620287660219833
145;0.41809349204752194;0.301635171082784
150;0.4990518785818469;0.2650910809966405
155;0.49755654635458657;0.24687233782817364
160;0.45019522302167014;0.2866784885350099
165;0.43573947110501815;0.25612588014243437
170;0.3887210181610382;0.3245995140406484
175;0.4008459865276769;0.3685248579574704
180;0.5012693371012799;0.2565134620944156
185;0.5067931804211319;0.26860956989194945
190;0.4638294156792712;0.2645645322442305
195;0.5000359886103126;0.21775540358030987
200;0.48056490324647166;0.24050512563970483
205;0.574973630917984;0.23907573634316076
210;0.44643326073864165;0.2688860194047429
215;0.48368527124051036;0.2682732018484802
220;0.4549155498983145;0.2924380845758096
225;0.5581753024945293;0.2578443848392889
230;0.39911802791845913;0.3460564084970655
235;0.4765006126211032;0.28975802489489805
240;0.6110697794136537;0.23648624362482276
245;0.4441528162501773;0.2735581197228201
250;0.5199186340393143;0.2210325548427286
255;0.4221941793581838;0.26278296733814127
260;0.44952922397792977;0.23009090503049442
265;0.5562436982241512;0.2796783358521464
270;0.4943081715084711;0.2524281355809979
275;0.4813169285958858;0.26709969261101696
280;0.4324336115961685;0.2533069887973022
285;0.49530603944866197;0.2711898248230242
290;0.520681342783757;0.26469536748776495
295;0.43042390857498786;0.31041078257071536
300;0.5154705655363457;0.24844078523953506
