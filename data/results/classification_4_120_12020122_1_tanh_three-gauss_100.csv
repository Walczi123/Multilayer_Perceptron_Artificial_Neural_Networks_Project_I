Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 64, 32, 16, 8, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-415.3619830040285;0.04666666666666667;93.0
10;-440.74784716238474;0.06666666666666667;93.33333333333333
15;-440.1068159662972;0.05333333333333334;93.0
20;-436.4055142088514;0.06;94.0
25;-441.7151251486849;0.10666666666666667;92.66666666666666
30;-437.4384593130021;0.11333333333333333;92.66666666666666
35;-454.5336602713957;0.22666666666666666;89.33333333333333
40;-439.17810273109114;0.08;92.33333333333333
45;-430.1536388504335;0.08666666666666667;93.0
50;-459.13657289729093;0.08;93.0
55;-453.76129483960676;0.06666666666666667;92.66666666666666
60;-423.9809817932446;0.05333333333333334;93.0
65;-425.65495809348295;0.04;94.0
70;-459.47637087088174;0.06;93.66666666666667
75;-417.2058582910622;0.07333333333333333;93.0
80;-472.4377026136315;0.06666666666666667;92.33333333333333
85;-465.2049980855351;0.05333333333333334;92.66666666666666
90;-443.8602336582154;0.06666666666666667;93.66666666666667
95;-413.23042567787627;0.06;91.33333333333333
100;-436.1699481042053;0.06666666666666667;93.33333333333333
105;-459.0709057794403;0.08666666666666667;93.0
110;-451.49840327775314;0.05333333333333334;94.0
115;-475.56364029284043;0.06666666666666667;92.0
120;-446.5150391281321;0.1;92.66666666666666
125;-444.9067299457445;0.07333333333333333;92.66666666666666
130;-399.65307630675477;0.26666666666666666;87.66666666666667
135;-458.6133247535264;0.05333333333333334;93.33333333333333
140;-439.5700166391543;0.14666666666666667;91.66666666666666
145;-469.7828971437147;0.08;92.33333333333333
150;-445.2465279193353;0.1;92.33333333333333
155;-455.081921982876;0.06;93.66666666666667
160;-453.8655267085515;0.07333333333333333;93.33333333333333
165;-465.08721503321203;0.06666666666666667;92.0
170;-449.58886087286874;0.06;92.66666666666666
175;-466.19937843859185;0.09333333333333334;92.0
180;-463.70092077209216;0.06;93.0
185;-459.4242549364094;0.06666666666666667;93.0
190;-452.71479855207764;0.06;93.66666666666667
195;-474.85694197890206;0.06;91.66666666666666
200;-458.20785966208484;0.08;92.66666666666666
205;-457.39692947920184;0.06666666666666667;93.0
210;-463.46535466744604;0.08666666666666667;91.66666666666666
215;-444.0957997628615;0.06;93.0
220;-429.5261588377242;0.07333333333333333;92.0
225;-449.53674493839634;0.06666666666666667;93.33333333333333
230;-458.37775864888033;0.06;92.66666666666666
235;-459.4242549364094;0.06666666666666667;93.0
240;-458.6133247535264;0.05333333333333334;93.33333333333333
245;-445.0245129980675;0.08;92.66666666666666
250;-460.8105491975293;0.1;91.66666666666666
255;-459.5941539232048;0.04666666666666667;93.0
260;-454.96413893055296;0.07333333333333333;93.0
265;-458.2599755965573;0.05333333333333334;94.0
270;-456.1805342048774;0.06;93.33333333333333
275;-455.25182096967137;0.06;93.0
280;-450.5696900425471;0.05333333333333334;93.66666666666667
285;-459.82972002785084;0.04;93.66666666666667
290;-454.270991799993;0.04666666666666667;94.0
295;-408.7046425541691;0.06666666666666667;92.33333333333333
300;-458.20785966208484;0.06;93.33333333333333
