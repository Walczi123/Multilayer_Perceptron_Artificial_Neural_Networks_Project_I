Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 8, 4, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-3988.9186774256345;0.07933333333333334;90.9
10;-4233.005503264467;0.09933333333333333;92.10000000000001
15;-4666.965686151202;0.174;90.73333333333333
20;-4327.719631662197;0.11466666666666667;92.86666666666666
25;-4834.14339005281;0.106;90.16666666666666
30;-4338.59214842797;0.07;93.16666666666666
35;-4300.804676622682;0.10133333333333333;92.7
40;-4157.166872793355;0.07266666666666667;91.93333333333334
45;-4401.149466763242;0.10266666666666667;92.7
50;-4269.014766900572;0.07133333333333333;92.23333333333333
55;-4163.086234964438;0.09266666666666666;92.06666666666666
60;-4885.177786840925;0.08733333333333333;89.9
65;-4224.6648129290725;0.072;92.5
70;-4255.56666296611;0.07933333333333334;93.13333333333334
75;-4083.899651892849;0.06866666666666667;91.63333333333334
80;-4360.394493881203;0.07933333333333334;93.2
85;-4274.127376486853;0.06866666666666667;93.03333333333333
90;-4329.407159145813;0.10933333333333334;92.96666666666667
95;-4356.745308058229;0.09066666666666667;93.0
100;-4245.366457361264;0.084;92.80000000000001
105;-4305.176200742012;0.06733333333333333;93.03333333333333
110;-4086.8129482360864;0.07933333333333334;91.73333333333333
115;-4164.83214477965;0.07933333333333334;91.3
120;-4086.957833655166;0.07;91.8
125;-4379.0417104894295;0.09733333333333333;93.16666666666666
130;-4186.122704473455;0.068;92.53333333333333
135;-4316.739775839305;0.09066666666666667;92.63333333333334
140;-4739.900393864373;0.088;92.10000000000001
145;-4797.120998893055;0.10133333333333333;91.26666666666667
150;-4293.19569816894;0.07;93.30000000000001
155;-4483.334830876421;0.06733333333333333;92.03333333333333
160;-4362.682399010772;0.08933333333333333;93.13333333333334
165;-4258.105774182745;0.07266666666666667;92.9
170;-4335.989458892525;0.10066666666666667;92.63333333333334
175;-4456.603326007079;0.09533333333333334;92.86666666666666
180;-4367.178990968682;0.10266666666666667;93.06666666666666
185;-4259.125168103518;0.084;92.76666666666667
190;-4170.321028291574;0.07133333333333333;92.5
195;-4752.782507305893;0.08266666666666667;91.8
200;-4277.581649755316;0.092;92.33333333333333
205;-4368.907172002433;0.08;93.36666666666666
210;-4598.963245042313;0.106;92.06666666666666
215;-4718.045932476667;0.082;90.03333333333333
220;-4117.809656556772;0.08133333333333333;91.9
225;-4220.99998712368;0.086;92.7
230;-4302.963336315591;0.09066666666666667;93.03333333333333
235;-4097.6698250194395;0.07666666666666666;91.73333333333333
240;-4292.4889998550025;0.07;93.2
245;-4381.173267815582;0.10133333333333333;93.10000000000001
250;-4135.663671763577;0.06533333333333333;92.26666666666667
255;-4457.099471784088;0.126;92.30000000000001
260;-4322.531981372767;0.08333333333333333;92.9
265;-4088.9215807935634;0.066;91.8
270;-3750.1279113432574;0.07266666666666667;88.83333333333333
275;-4270.790886270714;0.07533333333333334;93.23333333333333
280;-4136.488153129839;0.07133333333333333;92.16666666666666
285;-4404.466139398881;0.10666666666666667;92.96666666666667
290;-4454.012098855972;0.076;93.43333333333334
295;-4204.352993605904;0.064;92.73333333333333
300;-4649.01681266075;0.094;92.26666666666667
