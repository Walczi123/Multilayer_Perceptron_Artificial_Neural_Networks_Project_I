Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 128, 64, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-383.214546526868;0.06666666666666667;90.0
10;-437.4520104963804;0.06666666666666667;93.0
15;-440.1589319007695;0.09333333333333334;92.66666666666666
20;-442.5917224494185;0.06666666666666667;93.33333333333333
25;-464.10638586353366;0.05333333333333334;93.0
30;-450.3862398723733;0.12;92.0
35;-433.0054456739023;0.04666666666666667;93.66666666666667
40;-437.09866133941125;0.08666666666666667;93.0
45;-431.94539820299485;0.11333333333333333;93.0
50;-465.72824622929966;0.08;92.33333333333333
55;-457.3448135447295;0.05333333333333334;93.0
60;-443.2327536455061;0.05333333333333334;92.66666666666666
65;-432.87411143820094;0.08;93.0
70;-460.81054919752927;0.05333333333333334;92.66666666666666
75;-438.3150566137358;0.07333333333333333;93.33333333333333
80;-463.0077736415322;0.05333333333333334;93.33333333333333
85;-462.5501926156183;0.06666666666666667;92.66666666666666
90;-462.36674244544463;0.06666666666666667;92.66666666666666
95;-454.50655790463907;0.04;93.33333333333333
100;-441.7807922665355;0.07333333333333333;93.0
105;-449.30117883375027;0.07333333333333333;92.66666666666666
110;-450.92303919951627;0.05333333333333334;93.0
115;-450.92303919951627;0.05333333333333334;93.0
120;-458.2599755965573;0.07333333333333333;93.33333333333333
125;-445.0245129980675;0.06;93.33333333333333
130;-446.1752411545413;0.07333333333333333;93.0
135;-453.8134107740791;0.06;93.33333333333333
140;-446.8683882851013;0.08;92.66666666666666
145;-459.1886888317633;0.07333333333333333;92.33333333333333
150;-453.22449551246393;0.08666666666666667;92.66666666666666
155;-458.6133247535264;0.05333333333333334;93.33333333333333
160;-452.88469753887307;0.06;93.0
165;-460.86266513200167;0.04666666666666667;93.33333333333333
170;-450.92303919951627;0.05333333333333334;93.0
175;-459.82972002785084;0.04;93.66666666666667
180;-458.0900766097618;0.07333333333333333;92.66666666666666
185;-459.7119369755278;0.05333333333333334;93.0
190;-457.68461151832037;0.05333333333333334;93.0
195;-460.9283322498523;0.04;93.33333333333333
200;-458.0900766097618;0.07333333333333333;92.66666666666666
205;-456.06275115255437;0.07333333333333333;92.66666666666666
210;-453.0024805911961;0.06666666666666667;93.0
215;-455.3696040219944;0.06666666666666667;93.0
220;-451.7860853168716;0.06;93.33333333333333
225;-459.7119369755278;0.05333333333333334;93.0
230;-457.39692947920196;0.06666666666666667;93.0
235;-450.9751551339886;0.04666666666666667;93.66666666666667
240;-453.4079456826376;0.04;93.66666666666667
245;-446.4629231936598;0.06;93.0
250;-459.3064718840863;0.06;93.0
255;-460.3394169882372;0.06666666666666667;92.66666666666666
260;-452.13943447384077;0.04;93.33333333333333
265;-459.3064718840863;0.06;93.0
270;-460.3394169882372;0.06666666666666667;92.66666666666666
275;-455.89285216575894;0.02666666666666667;94.33333333333334
280;-451.3806202254301;0.04;93.66666666666667
285;-462.02694447185377;0.04;93.0
290;-453.12026364351914;0.05333333333333334;93.66666666666667
295;-453.7477436562284;0.06666666666666667;93.33333333333333
300;-455.77506911343585;0.04;93.66666666666667
