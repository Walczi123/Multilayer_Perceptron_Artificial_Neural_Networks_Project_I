Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 32, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4275.407350079988;0.094;92.76666666666667
10;-4283.723026847666;0.11733333333333333;92.33333333333333
15;-4819.410116538001;0.148;90.23333333333333
20;-4332.832241248477;0.136;92.26666666666667
25;-4671.390344594138;0.118;91.43333333333334
30;-4433.213507341092;0.11466666666666667;92.76666666666667
35;-4332.954201898883;0.09;92.93333333333334
40;-4327.449678404538;0.08666666666666667;92.80000000000001
45;-4252.413622920145;0.10466666666666667;92.53333333333333
50;-4360.197492527651;0.08333333333333333;92.96666666666667
55;-4253.761352430171;0.09866666666666667;92.5
60;-4650.584468293002;0.10333333333333333;92.33333333333333
65;-4365.831261458656;0.11733333333333333;92.63333333333334
70;-4280.023813889261;0.09133333333333334;92.86666666666666
75;-4295.952646708762;0.104;92.66666666666666
80;-4552.590143211688;0.13066666666666665;92.10000000000001
85;-4375.614539587725;0.11266666666666666;92.7
90;-4459.7772020226785;0.10933333333333334;92.83333333333333
95;-4353.68294869783;0.09733333333333333;92.96666666666667
100;-4444.59363226821;0.104;93.0
105;-4298.086292833955;0.08866666666666667;92.76666666666667
110;-4287.544200456476;0.09133333333333334;92.83333333333333
115;-4334.471830395703;0.086;93.03333333333333
120;-4295.9912114598565;0.112;92.53333333333333
125;-4324.333114310625;0.10933333333333334;92.66666666666666
130;-4281.688416604204;0.076;92.63333333333334
135;-4357.227902651859;0.092;93.06666666666666
140;-4607.058995687764;0.10666666666666667;91.96666666666667
145;-4643.417430882757;0.09933333333333333;92.56666666666666
150;-4279.489103361159;0.08266666666666667;92.73333333333333
155;-4476.741068745371;0.10266666666666667;93.13333333333334
160;-4528.117352306118;0.10066666666666667;92.93333333333334
165;-4423.026852919623;0.09733333333333333;93.13333333333334
170;-4338.682829113536;0.09533333333333334;92.86666666666666
175;-4382.994218333942;0.08733333333333333;93.16666666666666
180;-4368.4339509941;0.11933333333333333;92.56666666666666
185;-4423.092520037474;0.094;93.13333333333334
190;-4275.223899909814;0.09733333333333333;92.56666666666666
195;-4653.551969369752;0.104;92.26666666666667
200;-4268.373735704485;0.08;92.63333333333334
205;-4532.693162565256;0.096;93.06666666666666
210;-4493.951963957047;0.10466666666666667;92.96666666666667
215;-4501.00330711401;0.09533333333333334;93.23333333333333
220;-4155.425140576224;0.08266666666666667;92.16666666666666
225;-4447.966598436403;0.10933333333333334;92.9
230;-4441.898173248159;0.114;92.86666666666666
235;-4543.561501732948;0.09733333333333333;93.06666666666666
240;-4318.121892502343;0.09066666666666667;92.93333333333334
245;-4523.981394291433;0.104;92.63333333333334
250;-4339.713685418646;0.10666666666666667;92.80000000000001
255;-4462.042182383573;0.10266666666666667;92.9
260;-4341.061414928672;0.09533333333333334;93.06666666666666
265;-4312.955078182547;0.102;92.76666666666667
270;-4358.000268083649;0.098;92.86666666666666
275;-4305.44615399967;0.122;92.46666666666667
280;-4278.2185033533215;0.09733333333333333;92.7
285;-4411.356957154346;0.136;92.43333333333334
290;-4273.980402268732;0.10666666666666667;92.5
295;-4386.917535012655;0.09733333333333333;92.93333333333334
300;-4673.279051029389;0.11533333333333333;92.10000000000001
