Train dataset: data/regression/data.cube.train.100.csv
Test dataset: data/regression/data.cube.test.100.csv
Layers: [1, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.37829777311207224;0.16810302982769093
10;0.6817053326698568;0.5841547904180879
15;0.7471596193000161;0.11137013121776422
20;0.7409692365547529;0.11157198775923013
25;1.3747215072979873;0.10321716097398677
30;0.4369253459028059;0.14029318370703822
35;0.4197314079570753;0.14565636202568774
40;0.44644668931074777;0.13782584829628663
45;0.35608315642090144;0.19873159812386185
50;0.7716456791809222;0.11062201661835419
55;0.5245586142407387;0.12487328164587207
60;0.45832640158162263;0.13512707480236924
65;0.7982349879968521;0.10989106427620182
70;0.38275028002351924;0.16452989100492676
75;0.4453378188750584;0.13809803828195968
80;0.5575020678826457;0.12155642757370701
85;0.7978146568849704;0.10990202124763804
90;0.3457041274336398;0.27846708000660214
95;0.5637851516377653;0.12100827987559412
100;0.9498844433279728;0.10687139933272427
105;0.7300799013212554;0.11194061901636886
110;0.5388254624855188;0.12333689496731916
115;0.4821533124833591;0.13067667524159002
120;0.5596612773338422;0.12136537858162787
125;0.6326874852999187;0.7254840734619054
130;0.4325685835475793;0.1415299005153038
135;0.4136084739884029;0.14793269317809635
140;0.37534949355767083;0.1707473091301427
145;0.43688635665771963;3.0177961233849575
150;0.6763766949814738;0.1140538815252074
155;1.037043507878828;0.10572132396472594
160;0.40850716445203566;0.15001730502623886
165;0.7538059381609505;0.46467405629051967
170;0.590418199533574;0.11892276374203622
175;0.5863907748306343;0.11921567883248632
180;1.0959161330959934;0.10510068483729058
185;0.9205799341208731;0.1073364624571368
190;0.41422266964504667;0.14769384052152562
195;0.8682749966805402;0.10829152581742378
200;0.37528676533505234;0.6595245472326324
205;0.7477263324586627;0.11135192080059676
210;0.35883132484990166;0.19279241058001748
215;0.9348200078689604;0.10710480449520499
220;0.37588711270989517;0.1702464010390863
225;0.5802906766124891;0.11967376678246792
230;0.5779674610427538;0.11985298333197321
235;0.7396801446391179;0.48303836778767734
240;0.48046561367979734;5.767506685650871
245;0.40613251550620494;0.15105421281840445
250;0.5700543537956008;0.12048416350203292
255;0.44545564081592487;0.13806893828222322
260;0.7572748059341285;0.11105166108351708
265;0.3795253905163081;0.7222868738962184
270;0.3456725065885903;0.2632834358166673
275;0.9036603395299584;0.10762663063494635
280;0.4506146221119861;0.1368352882594135
285;0.3561853739591838;0.42487598869553694
290;0.7631402678638469;0.11087316919315503
295;0.4225464803545022;0.14468232130264164
300;0.42027386767968317;0.1454653215704566
