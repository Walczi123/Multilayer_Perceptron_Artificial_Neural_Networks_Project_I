Train dataset: data/regression/data.activation.train.1000.csv
Test dataset: data/regression/data.activation.test.1000.csv
Layers: [1, 16, 8, 4, 2, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.00012422150435644204;inf
10;0.00013889926252660985;inf
15;7.864839449999041e-05;inf
20;3.913668514970768e-05;0.021013201825547057
25;4.5103115960908585e-05;0.020389217242608008
30;2.512428452876046e-05;0.011577067299949383
35;2.0869476408543047e-05;0.011650609694532604
40;2.243174657236463e-05;0.01244307879902745
45;2.7186551665627656e-05;0.014025871226993307
50;3.3468814594980444e-05;0.015278253851798389
55;3.71373568870893e-05;0.015657774515909297
60;4.5768053448671595e-05;0.016724448939476944
65;5.130156773323335e-05;0.017238843712987593
70;6.1030086187390046e-05;0.018187353858575592
75;7.166656863851105e-05;0.019059298579825645
80;7.779996811641357e-05;0.01947263814082157
85;8.58019786844228e-05;0.020003370917761387
90;8.845359544748266e-05;0.02008591920262398
95;9.424019666836878e-05;0.0204209930815153
100;9.85481036422191e-05;0.020649928559262013
105;0.0001083070764305678;0.0212477817962669
110;0.00011332028403508857;0.021503482777739773
115;0.00011606429335190362;0.02160547014572733
120;0.0001217243112490286;0.02190755897873433
125;0.00012439724593603957;0.022006831473714534
130;0.00012542869225749592;0.0220260699086633
135;0.0001286139933690995;0.022173050937638154
140;0.00013233474820822477;0.022350889245060346
145;0.00013407134519314844;0.02240458066632377
150;0.00013713731899500778;0.02255369646987215
155;0.00014023336098646047;0.022698705448378896
160;0.0001415618678322485;0.022748654434204398
165;0.00014162868296315606;0.02273582733521392
170;0.00014377564878253105;0.022822844260863746
175;0.00014409961710575516;0.02282805664363713
180;0.00014554340906327917;0.02289487001084564
185;0.00014685532476033282;0.022939302572730674
190;0.00014760604546922953;0.02296315573045261
195;0.00014957577143695245;0.023048671873029187
200;0.00014764056608591395;0.02294631604904728
205;0.00014936357174503192;0.023025660828729665
210;0.0001494264441792473;0.02301851831043125
215;0.00015020869385986516;0.023051414089641696
220;0.00015253247955459225;0.023153804259189167
225;0.00015145082909401452;0.023089918464317783
230;0.000153274303805376;0.023174134798177044
235;0.00015263044287464113;0.02314317400996905
240;0.00015344649606260452;0.023175962968088843
245;0.00015348908989616902;0.023175352669491146
250;0.00015427117537104146;0.02320062414451478
255;0.00015527838198806397;0.023245578153771984
260;0.00015468947382546393;0.023205021866886017
265;0.00015391879563251054;0.02317059488058291
270;0.00015419233409225618;0.02317210885799271
275;0.00015497694432573504;0.02320571419662317
280;0.00015452579190832313;0.023178167720682787
285;0.00015526180327239748;0.02321592119705998
290;0.0001575357471410793;0.023322239912520238
295;0.0001570627430026131;0.02329339443253849
300;0.00015751366203703912;0.02330886132054107
