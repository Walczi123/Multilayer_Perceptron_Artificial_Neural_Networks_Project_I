Train dataset: data/regression/data.cube.train.1000.csv
Test dataset: data/regression/data.cube.test.1000.csv
Layers: [1, 2, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.47759538550540886;0.13144539139732084
10;0.5352680261912247;0.12370447304282278
15;0.5240119034331002;0.12493560662593632
20;0.5126861116142787;0.12629043992797642
25;0.5380550627317255;0.12341566843916152
30;0.3477957226452355;0.23129260606472582
35;0.3712438315464465;0.17489065316347838
40;0.40222750546744696;0.15286273919935753
45;0.39601209239648605;0.15604632716755426
50;0.4271176338724537;0.14318709460913145
55;0.34993661653523656;0.21879553705886984
60;0.48343318684569464;0.13046693350345884
65;0.3904376967051154;0.15928645666796887
70;0.5032051835643562;0.12752700181360785
75;0.4366981931702599;0.1403558728037567
80;0.5669657369232534;0.12073962001357139
85;0.38541790568913176;0.1625922612578397
90;0.43512278388599845;0.1407959684682657
95;0.40739181448454437;0.1504987292811439
100;0.3598418669364181;0.19086843048425187
105;0.4552603421219484;0.1357879313321799
110;0.3919521233788261;0.15836529759058732
115;0.3843415049257692;0.16335755880603597
120;0.5999242356260339;0.11825965188471352
125;0.39204963057652964;0.1583070890702555
130;0.42984808496626836;0.1423408682922257
135;0.400307986554033;0.15380325467634154
140;0.583283708474364;0.11944678351468462
145;0.37491178614682935;0.17116171492352386
150;0.5297592773206113;0.12429359891288226
155;0.35927497329485486;0.1919328425843514
160;0.41246424772353757;0.14838435545076106
165;0.40981538152650326;0.1494648057851984
170;0.3457492336061881;0.2593703477354661
175;0.4065337538306438;0.1508758229638252
180;0.36254087621145675;0.18625411407440481
185;0.4033915404705287;0.15230943594534782
190;0.471396354915352;0.13254907086862983
195;0.6477053708562353;0.11543121904475737
200;0.3879015926561883;0.16090528381201077
205;0.441841312834478;0.13898157914546375
210;0.3730593944251032;0.17298486604166416
215;0.5207104940379685;0.1253177841680893
220;0.4436925514225998;0.13850891503994428
225;0.5295534363169219;0.12431609886080663
230;0.34878576478415924;0.22478472495604282
235;0.3593953171881355;0.19170377134711766
240;0.6503936012146021;0.11529321180431051
245;0.4202473820285948;0.14547461131824901
250;0.587199040815543;0.11915629911532942
255;0.3951360485397296;0.1565292681695513
260;0.37505360229614787;0.17102679008257513
265;0.6262957116914825;0.11660483000825206
270;0.3573541353421674;0.19584149945454765
275;0.4821931592374489;0.13067010580206498
280;0.35333670403345;0.2061029249925222
285;0.3909596013359952;0.15896532303030475
290;0.5231666672575205;0.125032496763416
295;0.3507580588403906;0.21518800393599982
300;0.6133853960212023;0.11738326413612805
