Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 16, 8, 4, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-449.33974358484426;0.16;89.33333333333333
10;-426.0333208181678;0.18666666666666668;91.0
15;-442.917969239631;0.18666666666666668;90.33333333333333
20;-437.35924101177307;0.23333333333333334;90.66666666666666
25;-434.09050671252544;0.06666666666666667;93.33333333333333
30;-426.2303221717199;0.06;93.0
35;-436.353398274379;0.05333333333333334;92.0
40;-420.97282716635874;0.04666666666666667;93.33333333333333
45;-429.8909703790307;0.29333333333333333;88.66666666666667
50;-452.0873185393684;0.09333333333333334;90.33333333333333
55;-436.9808782870883;0.07333333333333333;92.33333333333333
60;-318.33075831093197;0.1;83.0
65;-439.04676849538976;0.16666666666666666;91.0
70;-456.97791320438205;0.14666666666666667;89.66666666666666
75;-428.3754306812504;0.06;92.33333333333333
80;-431.93184701961655;0.18666666666666668;91.0
85;-423.4577336494801;0.04;93.33333333333333
90;-392.21190804076906;0.17333333333333334;88.0
95;-420.0441139311527;0.05333333333333334;93.66666666666667
100;-400.4754688739751;0.56;81.33333333333333
105;-443.4683197501522;0.09333333333333334;92.33333333333333
110;-444.85461401127213;0.07333333333333333;90.0
115;-471.8623385353945;0.09333333333333334;89.66666666666666
120;-400.72667496104054;0.08666666666666667;91.33333333333333
125;-408.7703096720197;0.04666666666666667;92.33333333333333
130;-434.652319607384;0.18;91.0
135;-436.353398274379;0.05333333333333334;92.0
140;-450.6603707281135;0.22666666666666666;90.33333333333333
145;-504.74357569324997;0.43333333333333335;82.0
150;-325.6155787735006;0.10666666666666667;83.33333333333334
155;-435.7780341961421;0.09333333333333334;92.0
160;-422.8167024533925;0.06;93.33333333333333
165;-503.9983126282176;0.48;80.66666666666666
170;-474.28157790066507;0.08666666666666667;87.66666666666667
175;-436.353398274379;0.05333333333333334;92.0
180;-396.55424099430246;0.13333333333333333;89.66666666666666
185;-457.8680616884941;0.08;90.0
190;-461.50369632808923;0.10666666666666667;90.0
195;-426.6879031976338;0.08;92.66666666666666
200;-413.45244059914404;0.05333333333333334;93.0
205;-426.6357872631614;0.05333333333333334;93.0
210;-434.70443554185636;0.2;90.33333333333333
215;-347.836940501554;0.04;86.66666666666667
220;-427.8521825374859;0.04;93.33333333333333
225;-408.87454154096446;0.10666666666666667;91.33333333333333
230;-458.88745560926645;0.13333333333333333;89.33333333333333
235;-421.4304081922726;0.06666666666666667;93.0
240;-439.3480017178865;0.1;92.0
245;-432.5864293990825;0.07333333333333333;92.33333333333333
250;-430.715451745292;0.2;90.66666666666666
255;-441.93714006995253;0.17333333333333334;91.33333333333333
260;-448.37246559854424;0.07333333333333333;89.66666666666666
265;-438.07949050908974;0.07333333333333333;92.0
270;-437.4384593130021;0.10666666666666667;92.0
275;-517.8477040560383;0.25333333333333335;78.66666666666666
280;-405.5787048749601;0.10666666666666667;91.0
285;-400.72667496104054;0.08666666666666667;91.33333333333333
290;-388.7190700212126;0.30666666666666664;85.33333333333334
295;-347.836940501554;0.04;86.66666666666667
300;-384.0911438276017;0.04;90.33333333333333
