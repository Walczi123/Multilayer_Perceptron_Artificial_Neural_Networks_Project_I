Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 256, 128, 64, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4122.83260384662;0.2673333333333333;88.6
10;-4032.279447031291;0.23666666666666666;86.63333333333333
15;-4122.549099405584;0.218;88.96666666666667
20;-4193.636824643547;0.12466666666666666;91.5
25;-4099.049852883437;0.13;90.8
30;-4150.972309356624;0.14066666666666666;91.23333333333333
35;-4117.67623352203;0.098;91.4
40;-4107.226910629159;0.15533333333333332;90.16666666666666
45;-4281.367365801205;0.18333333333333332;90.63333333333333
50;-4300.877628526788;0.24466666666666667;88.4
55;-4312.140988790716;0.428;80.9
60;-3816.7419173712096;0.4666666666666667;79.4
65;-3968.731925941044;0.19866666666666666;88.66666666666667
70;-4157.446199636309;0.16466666666666666;89.86666666666666
75;-4196.894096558458;0.15066666666666667;90.93333333333334
80;-4225.190149871878;0.15133333333333332;89.8
85;-4008.30489070177;0.228;88.46666666666667
90;-3977.7834921884582;0.156;88.63333333333333
95;-4113.281784634025;0.10666666666666667;91.60000000000001
100;-4139.573437258912;0.09466666666666666;91.2
105;-4091.9505713900835;0.11333333333333333;91.23333333333333
110;-4064.460252272331;0.096;91.06666666666666
115;-4136.472513147419;0.11133333333333334;90.93333333333334
120;-4027.7328279379503;0.146;90.0
125;-4119.570135944496;0.13733333333333334;90.8
130;-4058.845230511919;0.18333333333333332;89.73333333333333
135;-4319.762500038702;0.22866666666666666;89.36666666666667
140;-4242.757501428697;0.20266666666666666;87.76666666666667
145;-4284.452649930279;0.2;90.3
150;-3995.7052633121543;0.10733333333333334;90.13333333333333
155;-4168.534464926228;0.22666666666666666;87.96666666666667
160;-4111.725591386109;0.12333333333333334;90.43333333333334
165;-4080.1107766380096;0.16733333333333333;90.23333333333333
170;-3864.9922632527478;0.492;76.06666666666668
175;-4092.0277008922712;0.134;90.4
180;-4184.74160619955;0.146;90.5
185;-4184.023445501274;0.134;91.26666666666667
190;-4153.316508018747;0.13733333333333334;90.73333333333333
195;-4144.136714723804;0.2813333333333333;88.1
200;-4137.02286365794;0.11066666666666666;90.9
205;-3977.2967199967466;0.22133333333333333;88.46666666666667
210;-3992.6616511223474;0.244;87.7
215;-4091.6816365215577;0.286;87.3
220;-4086.7087163671413;0.092;91.2
225;-4251.4400785367225;0.254;87.9
230;-4107.423911982711;0.08466666666666667;91.66666666666666
235;-4607.604098190294;0.4706666666666667;79.66666666666666
240;-4081.8118553050044;0.154;90.0
245;-4400.047695332291;0.314;87.76666666666667
250;-4087.855266925533;0.12866666666666668;90.86666666666666
255;-4235.673859917762;0.19533333333333333;89.13333333333333
260;-4103.645480723077;0.08733333333333333;91.5
265;-3963.8163177083143;0.18266666666666667;88.73333333333333
270;-3512.700462732549;0.562;77.93333333333334
275;-3729.3178054232626;0.5513333333333333;80.5
280;-3793.872239660813;0.38666666666666666;83.89999999999999
285;-4055.3909572434573;0.19;89.4
290;-3069.418708319965;1.1026666666666667;64.53333333333333
295;-3831.5012748636436;0.3273333333333333;84.33333333333334
300;-3855.169349962677;0.668;54.06666666666666
