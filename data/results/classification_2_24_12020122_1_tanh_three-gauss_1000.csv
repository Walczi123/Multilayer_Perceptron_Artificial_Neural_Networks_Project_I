Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 16, 8, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4293.232174120994;0.112;92.4
10;-4209.685529314412;0.11333333333333333;92.13333333333334
15;-4826.266547140453;0.22;88.86666666666667
20;-4320.421260016249;0.122;92.73333333333333
25;-4823.499154605427;0.11;90.56666666666666
30;-4347.519665225938;0.128;92.73333333333333
35;-4331.921256794732;0.074;93.36666666666666
40;-4277.044850428173;0.08533333333333333;92.86666666666666
45;-4282.678619359178;0.08666666666666667;93.10000000000001
50;-4293.929498849636;0.06866666666666667;92.93333333333334
55;-4185.51606043038;0.09933333333333333;92.23333333333333
60;-4826.8220936381895;0.096;90.86666666666666
65;-4411.318392403251;0.12333333333333334;92.76666666666667
70;-4275.448003630122;0.07066666666666667;93.30000000000001
75;-4230.468480846873;0.092;92.73333333333333
80;-4477.730253111214;0.17066666666666666;91.0
85;-4238.65282337885;0.12333333333333334;92.36666666666666
90;-4459.738637271585;0.088;92.93333333333334
95;-4247.403156403768;0.11266666666666666;92.60000000000001
100;-4350.8624218392;0.09133333333333334;92.80000000000001
105;-4209.646964563318;0.092;92.56666666666666
110;-4167.310784865647;0.10266666666666667;92.03333333333333
115;-4300.6212264525075;0.10133333333333333;93.13333333333334
120;-4233.161851067884;0.09666666666666666;92.73333333333333
125;-4219.154023037605;0.10266666666666667;92.46666666666667
130;-4337.976130799598;0.07466666666666667;93.60000000000001
135;-4302.01169831171;0.08266666666666667;92.9
140;-4905.698069901984;0.07733333333333334;89.76666666666667
145;-4850.078489269434;0.12733333333333333;90.4
150;-4291.546735436418;0.076;93.4
155;-4731.161523223793;0.09933333333333333;91.46666666666667
160;-4109.820226579307;0.07466666666666667;91.9
165;-4253.842659530441;0.07133333333333333;93.03333333333333
170;-4314.864620587432;0.10133333333333333;93.06666666666666
175;-4379.580598615614;0.072;93.63333333333334
180;-4313.462686343893;0.12666666666666668;92.76666666666667
185;-4248.920784900589;0.10466666666666667;92.7
190;-4236.430585367131;0.10666666666666667;92.53333333333333
195;-4801.4727054318855;0.09133333333333334;91.2
200;-4074.1955920650094;0.068;91.60000000000001
205;-4407.777616047304;0.08066666666666666;93.46666666666667
210;-4349.900339840115;0.12933333333333333;92.46666666666667
215;-4858.419179604827;0.09;90.7
220;-3995.5916578579127;0.06466666666666666;91.03333333333333
225;-4287.752664194366;0.09533333333333334;93.06666666666666
230;-4405.815957707947;0.07533333333333334;93.7
235;-4356.025058560913;0.07666666666666666;93.5
240;-4358.26084775601;0.078;93.76666666666667
245;-4460.18266711412;0.094;93.06666666666666
250;-4255.265429743614;0.08866666666666667;93.03333333333333
255;-4334.460368011367;0.066;93.0
260;-4397.772322996968;0.076;93.36666666666666
265;-4347.0777241824435;0.09266666666666666;93.16666666666666
270;-3996.0335989014075;0.06533333333333333;91.23333333333333
275;-4260.047614941601;0.16;91.7
280;-4183.934853614748;0.068;92.83333333333333
285;-4489.91086422601;0.096;92.66666666666666
290;-4130.768899500481;0.09066666666666667;91.83333333333333
295;-4337.113084682242;0.07133333333333333;93.7
300;-4819.983391817196;0.114;91.06666666666666
