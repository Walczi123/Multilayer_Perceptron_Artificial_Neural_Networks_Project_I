Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-3657.0012561582807;0.10666666666666667;86.66666666666667
10;-4040.712906851293;0.25266666666666665;88.26666666666667
15;-4913.234096451618;0.212;85.73333333333333
20;-4415.672187741122;0.16;91.43333333333334
25;-4480.816555629419;0.17733333333333334;90.76666666666667
30;-4222.681248210174;0.18066666666666667;90.63333333333333
35;-3967.5238858628827;0.088;90.36666666666666
40;-4183.088465868946;0.238;89.33333333333333
45;-3539.9167030153367;0.12533333333333332;85.43333333333332
50;-4151.262080194783;0.126;91.46666666666667
55;-3955.4464362071226;0.152;89.36666666666667
60;-4604.852397658465;0.17266666666666666;90.73333333333333
65;-4250.658339519637;0.15333333333333332;91.33333333333333
70;-3909.422505935385;0.15733333333333333;88.96666666666667
75;-4150.634600182074;0.13;91.16666666666666
80;-4254.159532735357;0.11066666666666666;91.66666666666666
85;-4075.134697274644;0.27666666666666667;87.8
90;-4369.122920526578;0.19;91.0
95;-4378.94476340674;0.194;91.13333333333333
100;-4206.6283659412275;0.26666666666666666;88.76666666666667
105;-4281.058847792453;0.08933333333333333;92.36666666666666
110;-3724.0499184434734;0.284;84.96666666666667
115;-4081.3584518771727;0.11066666666666666;91.03333333333333
120;-4038.9774410312857;0.18866666666666668;89.4
125;-3900.7607647969926;0.206;87.93333333333334
130;-4462.078658335627;0.116;92.26666666666667
135;-4313.616945348269;0.18866666666666668;91.06666666666666
140;-4786.692511969817;0.15466666666666667;87.2
145;-4077.2652362116637;0.10666666666666667;90.96666666666667
150;-4182.931099676396;0.074;92.26666666666667
155;-4279.766341405073;0.236;89.86666666666666
160;-4417.796460281019;0.11;92.60000000000001
165;-4083.2367143172187;0.17466666666666666;90.0
170;-4024.1513980318687;0.124;90.33333333333333
175;-4321.35725803771;0.22466666666666665;90.16666666666666
180;-4361.060538645006;0.1;92.43333333333334
185;-4451.185305600219;0.112;92.4
190;-4420.478368117691;0.09133333333333334;92.60000000000001
195;-4492.221694124253;0.16466666666666666;91.13333333333333
200;-3984.157328197281;0.11266666666666666;90.16666666666666
205;-4325.889307558541;0.124;92.33333333333333
210;-4416.946965347041;0.10333333333333333;92.76666666666667
215;-4196.121731126668;0.136;91.43333333333334
220;-4032.47334119667;0.09066666666666667;90.73333333333333
225;-4035.0020084180996;0.18066666666666667;89.36666666666667
230;-4328.6441672993205;0.196;90.73333333333333
235;-4305.785951973261;0.144;91.8
240;-3719.7065671008068;0.14333333333333334;87.16666666666667
245;-4176.319608763886;0.14866666666666667;91.13333333333333
250;-4052.8945883759984;0.16733333333333333;89.8
255;-4164.164011216804;0.082;91.7
260;-4225.390258413604;0.152;91.56666666666666
265;-4035.2719616757577;0.256;88.23333333333333
270;-4292.235704968896;0.15266666666666667;91.66666666666666
275;-3802.0149102535233;0.234;86.63333333333333
280;-4140.982656288707;0.12266666666666666;91.3
285;-3999.867253283687;0.27;87.4
290;-3827.9803160881984;0.17866666666666667;87.83333333333333
295;-4255.614601302501;0.16333333333333333;91.3
300;-4501.381669838695;0.124;92.16666666666666
