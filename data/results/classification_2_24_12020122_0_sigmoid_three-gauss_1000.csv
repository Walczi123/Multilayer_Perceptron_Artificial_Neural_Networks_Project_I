Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 16, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4409.530810648772;0.114;92.66666666666666
10;-4238.786246413592;0.102;92.53333333333333
15;-4428.234320789553;0.08533333333333333;93.13333333333334
20;-4389.452468631207;0.09466666666666666;93.4
25;-4475.406890418723;0.102;92.33333333333333
30;-4405.499084503032;0.11;92.93333333333334
35;-4401.0952620297285;0.07733333333333334;93.26666666666667
40;-4383.660263097744;0.086;93.06666666666666
45;-4366.290931283611;0.09066666666666667;93.13333333333334
50;-4435.949619911278;0.07866666666666666;93.5
55;-4399.811110838513;0.08666666666666667;93.4
60;-4530.378155068931;0.08066666666666666;92.96666666666667
65;-4372.253035803869;0.10533333333333333;93.0
70;-4341.154184413279;0.072;93.56666666666666
75;-4410.339652032613;0.08666666666666667;93.53333333333333
80;-4426.626011607165;0.08066666666666666;93.06666666666666
85;-4417.388906390536;0.08866666666666667;93.33333333333333
90;-4529.90911165868;0.094;92.86666666666666
95;-4438.067626054052;0.078;93.46666666666667
100;-4492.567758494968;0.07466666666666667;93.46666666666667
105;-4401.2380586497675;0.07;93.7
110;-4398.347687075205;0.076;93.63333333333334
115;-4482.888712234844;0.07066666666666667;93.63333333333334
120;-4331.554356454384;0.076;93.56666666666666
125;-4330.625643219178;0.07733333333333334;93.53333333333333
130;-4453.12195037186;0.06733333333333333;93.7
135;-4465.428699735144;0.06933333333333333;93.56666666666666
140;-4584.262269881474;0.07533333333333334;93.2
145;-4538.945037923674;0.07266666666666667;93.60000000000001
150;-4431.790737127918;0.068;93.53333333333333
155;-4565.678631592056;0.07666666666666666;93.03333333333333
160;-4422.3608081558195;0.07333333333333333;93.46666666666667
165;-4413.988837855587;0.08866666666666667;93.43333333333334
170;-4477.09441790234;0.08266666666666667;93.4
175;-4416.383063653142;0.076;93.66666666666667
180;-4323.549286494499;0.09;93.30000000000001
185;-4360.40595626554;0.07666666666666666;93.56666666666666
190;-4430.062556094167;0.08866666666666667;93.13333333333334
195;-4518.855233521774;0.07333333333333333;93.46666666666667
200;-4337.597768074913;0.06933333333333333;93.56666666666666
205;-4506.600600092962;0.07266666666666667;93.43333333333334
210;-4499.642026420605;0.08;93.66666666666667
215;-4499.6826799707405;0.07266666666666667;93.46666666666667
220;-4322.203645783514;0.06866666666666667;93.23333333333333
225;-4459.464506415845;0.074;93.36666666666666
230;-4408.117414020895;0.07333333333333333;93.53333333333333
235;-4535.23018498285;0.07466666666666667;93.23333333333333
240;-4429.566410317159;0.07666666666666666;93.33333333333333
245;-4473.379564961516;0.082;93.33333333333333
250;-4365.989698061114;0.09266666666666666;93.13333333333334
255;-4521.786258646471;0.07733333333333334;93.10000000000001
260;-4523.630133933505;0.07533333333333334;93.2
265;-4413.701155816469;0.08733333333333333;93.16666666666666
270;-4350.08796760837;0.06733333333333333;93.60000000000001
275;-4372.359356471856;0.08666666666666667;93.23333333333333
280;-4465.754946525356;0.082;93.10000000000001
285;-4500.595753223528;0.09133333333333334;92.93333333333334
290;-4374.359579562306;0.09666666666666666;93.26666666666667
295;-4377.696069778445;0.078;93.56666666666666
300;-4490.343431684208;0.07533333333333334;93.56666666666666
