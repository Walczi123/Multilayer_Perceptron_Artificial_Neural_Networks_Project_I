Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 32, 16, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-408.48053883386035;0.3933333333333333;85.66666666666667
10;-422.5404827986114;0.34;87.33333333333333
15;-423.4035289159667;0.36666666666666664;87.0
20;-416.13225963677644;0.2733333333333333;88.33333333333333
25;-420.6444915771052;0.26;89.0
30;-415.0857633492474;0.30666666666666664;88.0
35;-414.22271723189203;0.28;88.33333333333333
40;-416.9953057541318;0.3;88.0
45;-419.24464613260704;0.34;87.0
50;-413.0063219575675;0.29333333333333333;88.0
55;-417.51855389789637;0.28;88.66666666666667
60;-416.13225963677644;0.2733333333333333;88.33333333333333
65;-416.3021586235718;0.29333333333333333;88.33333333333333
70;-422.01723465484685;0.36;86.66666666666667
75;-406.59809879573254;0.24;89.0
80;-427.91576085629555;0.36;86.66666666666667
85;-409.7240364749415;0.22;89.33333333333333
90;-421.3240875242869;0.35333333333333333;87.0
95;-414.22271723189203;0.28;88.33333333333333
100;-417.3486549111009;0.26;88.66666666666667
105;-411.26667853947845;0.32666666666666666;87.0
110;-409.03088934438154;0.21333333333333335;89.66666666666666
115;-395.45353997326004;0.5;82.66666666666667
120;-409.03088934438154;0.21333333333333335;89.66666666666666
125;-416.13225963677644;0.2733333333333333;88.33333333333333
130;-419.58444410619785;0.38666666666666666;86.0
135;-410.24728461870603;0.2;90.0
140;-429.65540427438464;0.32666666666666666;87.66666666666667
145;-413.17622094436285;0.32;87.0
150;-410.7569815790922;0.25333333333333335;89.0
155;-417.3486549111009;0.26;88.66666666666667
160;-413.35967111453664;0.25333333333333335;88.66666666666667
165;-413.69946908812744;0.3;87.66666666666667
170;-420.1076922499624;0.36666666666666664;86.66666666666667
175;-410.7569815790922;0.25333333333333335;89.0
180;-413.69946908812744;0.3;87.66666666666667
185;-409.0173381610032;0.2866666666666667;88.0
190;-410.9268805658877;0.28;88.0
195;-418.90484815901624;0.29333333333333333;88.0
200;-411.2802297228568;0.24;88.66666666666667
205;-402.94891297275905;0.28;88.0
210;-416.81185558395805;0.36666666666666664;86.33333333333333
215;-407.4611449130879;0.25333333333333335;88.66666666666667
220;-415.09931453262567;0.22;89.66666666666666
225;-416.13225963677644;0.2733333333333333;88.33333333333333
230;-416.47205761036724;0.32;87.33333333333333
235;-420.6444915771052;0.26;89.0
240;-419.9513444465453;0.25333333333333335;89.33333333333333
245;-409.03088934438154;0.21333333333333335;89.66666666666666
250;-424.45002520349584;0.3333333333333333;87.33333333333333
255;-424.6199241902912;0.36;86.33333333333333
260;-414.22271723189203;0.28;88.33333333333333
265;-411.4501287096522;0.26;88.66666666666667
270;-413.69946908812744;0.3;87.66666666666667
275;-419.4280963027808;0.2733333333333333;88.66666666666667
280;-411.1103307360614;0.21333333333333335;89.66666666666666
285;-416.655507780541;0.25333333333333335;89.0
290;-420.46104140693154;0.32666666666666666;87.33333333333333
295;-414.22271723189203;0.28;88.33333333333333
300;-407.617492716505;0.36666666666666664;86.0
