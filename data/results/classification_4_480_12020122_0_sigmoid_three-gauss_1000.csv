Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 256, 128, 64, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4287.911100796823;0.09866666666666667;92.56666666666666
10;-4170.446096130153;0.16933333333333334;90.76666666666667
15;-4309.7092686519745;0.14133333333333334;91.83333333333333
20;-4393.153770388654;0.092;93.5
25;-4408.111147623772;0.16533333333333333;91.26666666666667
30;-4483.122189540449;0.10466666666666667;92.83333333333333
35;-4423.81276953479;0.08866666666666667;93.30000000000001
40;-4383.098450202886;0.07266666666666667;93.4
45;-4330.168062193265;0.09666666666666666;92.83333333333333
50;-4429.292279461419;0.07333333333333333;93.53333333333333
55;-4387.542926226323;0.09666666666666666;93.36666666666666
60;-4523.4602349467095;0.082;92.7
65;-4385.214367546619;0.10266666666666667;93.10000000000001
70;-4331.253123231887;0.08533333333333333;93.36666666666666
75;-4412.482671743103;0.11866666666666667;92.73333333333333
80;-4344.8961397208595;0.062;93.73333333333333
85;-4434.169322943055;0.084;93.36666666666666
90;-4493.602792398159;0.09933333333333333;92.60000000000001
95;-4427.147170951888;0.06866666666666667;93.66666666666667
100;-4432.248318153833;0.074;93.33333333333333
105;-4431.607286957745;0.07333333333333333;93.53333333333333
110;-4365.978235676776;0.07133333333333333;93.7
115;-4435.345064667244;0.10133333333333333;93.0
120;-4361.112654579479;0.068;93.8
125;-4317.951993515547;0.08466666666666667;93.36666666666666
130;-4423.223854273175;0.07066666666666667;93.06666666666666
135;-4390.369719482076;0.07266666666666667;93.43333333333334
140;-4433.4376110614;0.08266666666666667;92.86666666666666
145;-4365.978235676776;0.072;93.66666666666667
150;-4429.697744552861;0.07333333333333333;93.60000000000001
155;-4487.2445963717555;0.072;93.06666666666666
160;-4432.431768324007;0.076;93.56666666666666
165;-4377.512619608272;0.08466666666666667;93.56666666666666
170;-4382.104069849829;0.094;92.60000000000001
175;-4435.949619911278;0.07666666666666666;93.16666666666666
180;-4396.150462631202;0.088;93.23333333333333
185;-4386.446402803363;0.08933333333333333;92.96666666666667
190;-4464.590667185504;0.08266666666666667;93.26666666666667
195;-4386.394286868891;0.09266666666666666;93.13333333333334
200;-4349.446936412282;0.06733333333333333;93.7
205;-4462.576892911675;0.084;93.06666666666666
210;-4426.571806873651;0.078;93.10000000000001
215;-4482.628132562482;0.07133333333333333;93.03333333333333
220;-4316.173785346364;0.08;93.10000000000001
225;-4402.728584779832;0.08066666666666666;93.33333333333333
230;-4437.426594857965;0.07666666666666666;93.16666666666666
235;-4488.66945538397;0.096;92.76666666666667
240;-4425.68165838954;0.08066666666666666;93.10000000000001
245;-4461.648179676469;0.07733333333333334;93.2
250;-4403.525963779337;0.08933333333333333;93.0
255;-4508.811375720344;0.07;93.33333333333333
260;-4430.325224565569;0.072;93.4
265;-4384.496206848344;0.09266666666666666;93.03333333333333
270;-4459.333172180143;0.078;93.36666666666666
275;-4374.726479902653;0.09133333333333334;92.86666666666666
280;-4534.430717184305;0.086;93.06666666666666
285;-4545.573187207736;0.09666666666666666;92.7
290;-4429.369408963607;0.08866666666666667;93.10000000000001
295;-4486.891247214787;0.08266666666666667;93.13333333333334
300;-4482.666697313576;0.07266666666666667;93.60000000000001
