Train dataset: data/regression/data.activation.train.1000.csv
Test dataset: data/regression/data.activation.test.1000.csv
Layers: [1, 8, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.0007729721417679996;0.044639849477987915
10;0.0007978897118187899;0.048161266641935346
15;0.0006121877354373605;0.04587409342662569
20;0.0004950049063858655;0.04361453858316748
25;0.0005678108712206622;0.045080258798047716
30;0.00046016468933741847;0.04260498958310666
35;0.00044757796949484226;0.04205394797028045
40;0.0004314180492482421;0.041404584119153647
45;0.000385273919361963;0.0399413334789504
50;0.0003655069876562743;0.03901932972718728
55;0.00041119793962660577;0.03999787584496345
60;0.0003598578760937735;0.038500326229673316
65;0.0003605522221464845;0.038398838796385386
70;0.00034469592927060725;0.037751639597121515
75;0.0003071273587940105;0.03648899763685359
80;0.00031109446079230957;0.036414072894030806
85;0.00031833245867853466;0.03650969053512239
90;0.0003210423258560662;0.03662568740182134
95;0.00032513677852885625;0.036514389060986155
100;0.000319981020361997;0.036268765914328094
105;0.00028531881382132826;0.035031352813775125
110;0.00029138745268414266;0.03515458701937969
115;0.00027587958348091867;0.03460893505831468
120;0.00025565049805008767;0.03383238273882692
125;0.0002617922622065519;0.03401469283730638
130;0.00026636162037709784;0.0341421964852676
135;0.00026181892426242146;0.03394760691486825
140;0.00025217716027441486;0.033510475268015386
145;0.0002596765805620571;0.03373394981382844
150;0.00024699085638054465;0.03327818680286776
155;0.00022466916023835542;0.03244336782628455
160;0.00023129331723085601;0.03266863373589101
165;0.00022326256515299426;0.0324377023951899
170;0.00020159613386294047;0.03144994563304942
175;0.00021656640769269028;0.03218908839472665
180;0.00020302909173034193;0.03162340352150693
185;0.0002186539464109125;0.03228599208085293
190;0.00021438689507265063;0.032064176059115
195;0.00020299982487846112;0.031620967590053985
200;0.00020812195705535754;0.03182795342960797
205;0.0002037595272714223;0.03172131191593637
210;0.00019062590430853307;0.031224908068623936
215;0.00018920120058483025;0.03122804772121134
220;0.00018932461956506027;0.031247761580693947
225;0.00018746594913256139;0.03115272095584846
230;0.00017841640832317885;0.030734843478507162
235;0.00018087871236069562;0.03095332405216081
240;0.00017531598274845515;0.03067937987608767
245;0.0001775343604359466;0.030886762765392768
250;0.00017159043062207858;0.030662339304870008
255;0.0001490151649909783;0.029496687620959555
260;0.00014483435112429762;0.02934730934459148
265;0.0001614531516600201;0.030343579510733985
270;0.00016100263017875042;0.030369120687499168
275;0.00016582127747172734;0.03058523930557053
280;0.00015118356189511352;0.02992563886671923
285;0.00014559506720298617;0.029689650384159216
290;0.0001376959288520992;0.029210396359131592
295;0.00014608132533585225;0.02971474851022435
300;0.00014078589876163024;0.02962367631994211
