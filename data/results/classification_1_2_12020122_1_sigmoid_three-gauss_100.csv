Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-440.8520790313295;0.09333333333333334;91.66666666666666
10;-435.30690198684994;0.05333333333333334;92.33333333333333
15;-438.2493894958851;0.1;92.33333333333333
20;-442.4082722792448;0.11333333333333333;92.33333333333333
25;-435.8822660650868;0.07333333333333333;92.66666666666666
30;-437.3206762606791;0.10666666666666667;92.66666666666666
35;-430.91245309884414;0.05333333333333334;93.66666666666667
40;-426.7535703154844;0.04;93.66666666666667
45;-431.2001351379626;0.06666666666666667;93.33333333333333
50;-438.5370715350035;0.09333333333333334;93.0
55;-431.31791819028564;0.04666666666666667;93.66666666666667
60;-429.8138408768427;0.05333333333333334;94.0
65;-425.4193919888369;0.05333333333333334;94.0
70;-435.7644830127638;0.07333333333333333;93.33333333333333
75;-430.50698800740264;0.06;93.66666666666667
80;-431.6056002294041;0.06;93.33333333333333
85;-427.73439948516284;0.04;94.0
90;-438.0659393257113;0.15333333333333332;92.0
95;-430.50698800740264;0.06;93.66666666666667
100;-430.50698800740264;0.06;93.66666666666667
105;-430.50698800740264;0.06;93.66666666666667
110;-431.6056002294041;0.06;93.33333333333333
115;-430.50698800740264;0.06;93.66666666666667
120;-431.8276151506718;0.10666666666666667;93.0
125;-425.4193919888369;0.05333333333333334;94.0
130;-432.2330802421133;0.1;93.0
135;-434.1426226469978;0.09333333333333334;93.0
140;-435.7509318293854;0.16666666666666666;92.0
145;-431.6056002294041;0.06;93.33333333333333
150;-435.05778469882546;0.16;92.33333333333333
155;-430.50698800740264;0.06;93.66666666666667
160;-432.2330802421133;0.1;93.0
165;-434.1426226469978;0.09333333333333334;93.0
170;-429.8138408768427;0.05333333333333334;94.0
175;-429.8138408768427;0.05333333333333334;94.0
180;-432.9262273726733;0.10666666666666667;92.66666666666666
185;-430.50698800740264;0.06;93.66666666666667
190;-430.50698800740264;0.06;93.66666666666667
195;-430.50698800740264;0.06;93.66666666666667
200;-434.1426226469978;0.09333333333333334;93.0
205;-435.0713358822038;0.06666666666666667;93.66666666666667
210;-429.4083757854012;0.06;94.0
215;-426.3481052240429;0.04666666666666667;93.66666666666667
220;-423.3399505971571;0.04;94.0
225;-429.8138408768427;0.05333333333333334;94.0
230;-434.5480877384393;0.08666666666666667;93.0
235;-430.50698800740264;0.06;93.66666666666667
240;-426.63578726316143;0.04;94.33333333333334
245;-423.67974857074785;0.08666666666666667;93.0
250;-432.9262273726733;0.10666666666666667;92.66666666666666
255;-433.21390941179175;0.12;92.33333333333333
260;-429.4083757854012;0.06;94.0
265;-430.50698800740264;0.06;93.66666666666667
270;-435.05778469882546;0.16;92.33333333333333
275;-432.9262273726733;0.10666666666666667;92.66666666666666
280;-423.3399505971571;0.04;94.0
285;-430.50698800740264;0.06;93.66666666666667
290;-433.4494755164378;0.08666666666666667;93.33333333333333
295;-424.89614384507234;0.07333333333333333;93.33333333333333
300;-425.4193919888369;0.05333333333333334;94.0
