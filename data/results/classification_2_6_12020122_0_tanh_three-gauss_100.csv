Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 4, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-414.40616740206576;0.21333333333333335;90.0
10;-414.5896175722395;0.16666666666666666;90.66666666666666
15;-415.9759118333594;0.16;91.0
20;-409.03088934438154;0.2;89.66666666666666
25;-415.9759118333594;0.16;91.0
30;-420.1347946167191;0.18666666666666668;91.0
35;-408.33774221382157;0.20666666666666667;90.0
40;-416.83895795071476;0.18666666666666668;90.66666666666666
45;-409.8939354617369;0.22666666666666666;89.33333333333333
50;-401.73251769843455;0.28;87.66666666666667
55;-393.0478517913677;0.36666666666666664;85.33333333333334
60;-410.6006337756752;0.14666666666666667;90.66666666666666
65;-380.88389904812277;0.5;82.0
70;-387.37134051118676;0.41333333333333333;83.66666666666667
75;-414.75951655903486;0.17333333333333334;90.66666666666666
80;-407.98439305685247;0.24;88.33333333333333
85;-371.6895361806696;0.5;81.66666666666667
90;-391.4781073600741;0.4066666666666667;84.33333333333334
95;-400.5161224241101;0.29333333333333333;87.33333333333333
100;-415.45266368959483;0.18;90.33333333333333
105;-407.2912459262925;0.23333333333333334;88.66666666666667
110;-387.8424727204789;0.37333333333333335;85.0
115;-386.6260774461544;0.38666666666666666;84.66666666666667
120;-396.3572396407504;0.28;87.33333333333333
125;-409.21433951455526;0.15333333333333332;90.33333333333333
130;-416.48560879374554;0.23333333333333334;89.0
135;-400.69957259428384;0.24666666666666667;88.0
140;-437.8032708543086;0.37333333333333335;85.66666666666667
145;-402.4256648289945;0.32;85.66666666666667
150;-402.0858668554037;0.25333333333333335;88.33333333333333
155;-405.21180453461267;0.23333333333333334;88.66666666666667
160;-412.4966249971813;0.22666666666666666;89.0
165;-402.4256648289945;0.2866666666666667;87.33333333333333
170;-381.4206983752656;0.3933333333333333;84.33333333333334
175;-387.3327757600928;0.32;86.0
180;-400.69957259428384;0.24666666666666667;88.0
185;-353.27370807900684;0.6933333333333334;76.66666666666667
190;-404.8720065610218;0.18666666666666668;89.66666666666666
195;-368.9033964750515;0.5666666666666667;80.33333333333333
200;-390.96841039968785;0.35333333333333333;85.33333333333334
205;-403.47216111652364;0.26666666666666666;87.66666666666667
210;-411.29378090623516;0.16666666666666666;90.33333333333333
215;-407.65814626663996;0.13333333333333333;91.0
220;-411.8170290499997;0.14666666666666667;91.0
225;-403.87762620796514;0.26;87.66666666666667
230;-372.72248128482045;0.5533333333333333;80.33333333333333
235;-413.3867734812933;0.09333333333333334;92.0
240;-416.6690589639193;0.16666666666666666;90.66666666666666
245;-409.3842385013507;0.17333333333333334;90.33333333333333
250;-413.01987314094583;0.20666666666666667;89.66666666666666
255;-414.57606638886114;0.24666666666666667;88.0
260;-410.07738563191066;0.18;90.0
265;-387.50267474688815;0.32666666666666666;86.0
270;-413.7130202715058;0.21333333333333335;89.33333333333333
275;-408.18139441040455;0.1;91.66666666666666
280;-407.65814626663996;0.13333333333333333;91.0
285;-407.99794424023077;0.16666666666666666;90.0
290;-415.79246166318563;0.22666666666666666;89.33333333333333
295;-409.3842385013507;0.17333333333333334;90.33333333333333
300;-386.6260774461544;0.38666666666666666;84.66666666666667
