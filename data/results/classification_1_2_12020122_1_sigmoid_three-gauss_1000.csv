Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4314.513360229504;0.08533333333333333;92.30000000000001
10;-4258.574817592997;0.092;92.33333333333333
15;-4280.585626784119;0.09866666666666667;92.56666666666666
20;-4286.72909267551;0.146;91.76666666666667
25;-4338.388880677295;0.16133333333333333;91.66666666666666
30;-4297.531764725351;0.148;91.76666666666667
35;-4273.038137850149;0.11133333333333334;92.30000000000001
40;-4252.705482557346;0.06733333333333333;92.56666666666666
45;-4257.843105711343;0.08466666666666667;92.60000000000001
50;-4262.196901049214;0.098;92.5
55;-4253.7613524301705;0.09533333333333334;92.56666666666666
60;-4368.837327286501;0.14333333333333334;92.23333333333333
65;-4276.816569109782;0.12933333333333333;91.96666666666667
70;-4240.317426093791;0.08466666666666667;92.60000000000001
75;-4266.342232649195;0.10266666666666667;92.5
80;-4296.4800724506085;0.07733333333333334;92.66666666666666
85;-4282.742197677988;0.116;92.16666666666666
90;-4356.596245041068;0.13466666666666666;92.30000000000001
95;-4275.914958241333;0.118;92.16666666666666
100;-4302.635000726336;0.11466666666666667;92.30000000000001
105;-4262.029090861459;0.076;92.7
110;-4250.087153039482;0.086;92.63333333333334
115;-4278.820969798315;0.086;92.80000000000001
120;-4264.509819746499;0.124;92.03333333333333
125;-4256.95086842819;0.114;92.23333333333333
130;-4258.381993837526;0.07266666666666667;92.5
135;-4273.665617862858;0.114;92.26666666666667
140;-4364.458518380915;0.10733333333333334;92.73333333333333
145;-4335.93107656093;0.14666666666666667;91.93333333333334
150;-4257.474116571954;0.11333333333333333;92.30000000000001
155;-4329.447812695948;0.092;92.96666666666667
160;-4285.962993640845;0.07933333333333334;92.83333333333333
165;-4263.007831232097;0.094;92.63333333333334
170;-4260.028867771008;0.07066666666666667;92.7
175;-4284.128491939107;0.11666666666666667;92.2
180;-4311.512490388874;0.154;91.86666666666666
185;-4263.96364683406;0.08933333333333333;92.60000000000001
190;-4292.110637130318;0.07333333333333333;92.86666666666666
195;-4357.430099992625;0.18133333333333335;91.56666666666666
200;-4265.9930610903075;0.07;92.7
205;-4306.925217745397;0.10666666666666667;92.5
210;-4348.065838138377;0.18266666666666667;91.4
215;-4280.547062033026;0.08666666666666667;92.80000000000001
220;-4236.344082279647;0.06533333333333333;92.53333333333333
225;-4289.279666276483;0.14066666666666666;91.8
230;-4283.120560402673;0.12666666666666668;92.06666666666666
235;-4346.6587079076235;0.10333333333333333;92.7
240;-4283.278997005131;0.106;92.5
245;-4336.114526731104;0.14;92.10000000000001
250;-4267.649308609086;0.11333333333333333;92.26666666666667
255;-4374.073986322229;0.07933333333333334;93.06666666666666
260;-4315.1773161942665;0.118;92.33333333333333
265;-4265.048707872683;0.09266666666666666;92.56666666666666
270;-4254.311702940693;0.086;92.56666666666666
275;-4299.362088829007;0.15866666666666668;91.7
280;-4285.177077025677;0.08666666666666667;92.80000000000001
285;-4327.2599618372415;0.14333333333333334;91.96666666666667
290;-4234.690941949042;0.11666666666666667;92.13333333333334
295;-4270.792975069755;0.07;92.76666666666667
300;-4329.252900141437;0.07866666666666666;92.96666666666667
