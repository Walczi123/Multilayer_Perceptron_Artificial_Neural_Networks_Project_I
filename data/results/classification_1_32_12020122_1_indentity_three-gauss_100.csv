Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 32, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-437.6740254176482;0.08;92.0
10;-426.38666997513695;0.16;91.66666666666666
15;-447.43020117995985;0.17333333333333334;91.0
20;-434.6002036729116;0.12666666666666668;92.66666666666666
25;-428.54532966804584;0.04666666666666667;93.0
30;-421.4304081922726;0.06666666666666667;93.0
35;-429.7617249423703;0.05333333333333334;92.66666666666666
40;-422.3591214274786;0.04;93.66666666666667
45;-436.73176099906385;0.18;91.0
50;-446.88193946847963;0.08;92.0
55;-432.5864293990825;0.07333333333333333;92.33333333333333
60;-372.79023720171216;0.14;87.66666666666667
65;-433.3838083985871;0.14;92.33333333333333
70;-446.34514014133674;0.1;92.0
75;-429.7617249423703;0.05333333333333334;92.66666666666666
80;-428.81946052378595;0.13333333333333333;92.33333333333333
85;-420.0441139311527;0.05333333333333334;93.66666666666667
90;-396.72413998109784;0.16;88.66666666666667
95;-426.92346930227984;0.04666666666666667;93.66666666666667
100;-398.23967967887813;0.43333333333333335;84.0
105;-434.6658707907623;0.08666666666666667;92.33333333333333
110;-438.5506227183819;0.06;92.0
115;-442.5396065149461;0.07333333333333333;92.66666666666666
120;-400.72667496104054;0.08666666666666667;91.33333333333333
125;-418.54003661770975;0.06;92.66666666666666
130;-422.7510353355418;0.11333333333333333;92.33333333333333
135;-434.1561738303761;0.05333333333333334;92.66666666666666
140;-438.4714044171528;0.14666666666666667;92.0
145;-459.30647188408636;0.10666666666666667;90.66666666666666
150;-420.0441139311527;0.05333333333333334;93.66666666666667
155;-430.45487207293024;0.06;92.33333333333333
160;-424.3728957013078;0.09333333333333334;92.66666666666666
165;-460.64065021073384;0.1;89.66666666666666
170;-452.1394344738407;0.08666666666666667;89.66666666666666
175;-434.1561738303761;0.05333333333333334;92.66666666666666
180;-417.8990054216221;0.08;92.66666666666666
185;-451.4462873432808;0.08;90.0
190;-444.73683095894904;0.07333333333333333;92.0
195;-424.3728957013078;0.09333333333333334;92.66666666666666
200;-417.84688948714984;0.05333333333333334;93.0
205;-430.04940698148874;0.04;92.66666666666666
210;-441.41389192618806;0.19333333333333333;90.66666666666666
215;-387.3869804936061;0.04;90.66666666666666
220;-427.5645004983674;0.05333333333333334;93.33333333333333
225;-407.5539143976953;0.06;92.0
230;-456.8080142175867;0.12;89.33333333333333
235;-423.0522685580386;0.04666666666666667;93.33333333333333
240;-434.2082897648485;0.05333333333333334;92.66666666666666
245;-430.7946700465211;0.06666666666666667;93.0
250;-426.38666997513695;0.16;91.66666666666666
255;-437.2550091428283;0.16;91.66666666666666
260;-438.19727356141277;0.06;92.66666666666666
265;-436.9808782870883;0.07333333333333333;92.33333333333333
270;-441.83290820100785;0.10666666666666667;92.0
275;-484.2868709510012;0.12;87.0
280;-411.3073320896135;0.09333333333333334;92.0
285;-405.2389069013693;0.07333333333333333;92.0
290;-408.3377422138216;0.21333333333333335;89.0
295;-383.214546526868;0.06666666666666667;90.0
300;-415.19208401723307;0.05333333333333334;93.0
