Train dataset: data/regression/data.cube.train.100.csv
Test dataset: data/regression/data.cube.test.100.csv
Layers: [1, 32, 16, 8, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.37721864867800037;0.45548934189654977
10;0.37209534033915853;0.23986075020003222
15;0.4064673756829039;0.22215374093373644
20;0.3680743624274717;0.3751305446584733
25;0.44352603920254524;0.22057801494066118
30;0.37574729727459305;0.2742824160538794
35;0.4355025344585836;0.20784775358296184
40;0.4653338801390696;0.21980682364958115
45;0.43681716376724466;0.1973571175123399
50;0.3742091717830324;0.281463490919884
55;0.42564374330681354;0.2139728884563357
60;0.4161678338231947;0.241223117849341
65;0.49737089838843057;0.1956031201672797
70;0.45519622038194624;0.2092043748583066
75;0.4064334359291609;0.21538459563566945
80;0.48904329395362944;0.19996164903025462
85;0.5444944527138792;0.16491924968337882
90;0.3795990639234421;0.3017679256020631
95;0.5376709450917102;0.1923635799818394
100;0.4722116850189492;0.20446249266194633
105;0.5834462023282593;0.19491561412901864
110;0.42099530554803505;0.2173832684981594
115;0.4095201206056924;0.22343659218448367
120;0.4468965954899867;0.21043524271172498
125;0.3697592897069284;0.32402853305333734
130;0.41864803815670965;0.2240506074101799
135;0.4495780670026686;0.19901283213156393
140;0.3884884813521969;0.26453382813774085
145;0.37619296619187564;0.23677450216840149
150;0.41021054432657733;0.23073871538847054
155;0.4167371854431333;0.24413517699032955
160;0.48799412890249216;0.20667115469572478
165;0.3624755045562845;0.2824133531612111
170;0.44241982092594523;0.2049112323852222
175;0.40936616256275443;0.2210162803115387
180;0.5232288215901075;0.18740632412043282
185;0.548570453196334;0.19920391418369424
190;0.4373291220563139;0.19068132260126636
195;0.4033449483768827;0.20988978054472834
200;0.4331284708791492;0.2111522617251843
205;0.48638644557681715;0.16174786856500842
210;0.49791575366621443;0.2041328910095555
215;0.43285446087795415;0.221054462738783
220;0.5473008571065807;0.19930854266748976
225;0.40599411263825375;0.2171133150770845
230;0.4353134132172559;0.2110186579623084
235;0.36647573818595025;0.2902062873242077
240;0.3668155781633484;0.3015875881441816
245;0.4212899645996721;0.18311288417081054
250;0.4627002041114843;0.19438169017441512
255;0.41219867069913174;0.21675424232745627
260;0.4613763501745365;0.2074333915370777
265;0.3833654400719315;0.25628814513136633
270;0.44205908780488035;0.19322188708251387
275;0.3958698097557812;0.20498770306135133
280;0.4045852988879132;0.24260227817406108
285;0.4151285769493559;0.21624591423129158
290;0.4594773424809517;0.2133958380869173
295;0.42655273294774004;0.20081008492808736
300;0.4843611785400108;0.2090558961350373
