Train dataset: data/regression/data.cube.train.100.csv
Test dataset: data/regression/data.cube.test.100.csv
Layers: [1, 8, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.3721719517624734;0.2291803533907802
10;0.49962776314889423;0.33522198130640085
15;0.38121951448587466;0.19770591671892726
20;0.3662655524493722;0.2905230641176643
25;0.4357305280973091;0.19124207130039386
30;0.6297019627451133;0.16127552372268172
35;0.6096411765043541;0.16042415052604936
40;0.6608146722896399;0.17150954238595362
45;0.4502717727394795;0.16792060973165607
50;0.3668650707296998;0.22298555626912928
55;0.5165941710446308;0.1665566284501574
60;0.38980784706229826;0.21686483486733532
65;0.5890314058234792;0.16659811216071402
70;0.38308098320861855;0.1992817515333182
75;0.3990602563784803;0.17837599444780564
80;0.5027334233427512;0.15930009833293304
85;0.5328167560989695;0.1482982442807776
90;0.361604550398263;0.2399080783251423
95;0.5261277745703887;0.1595477106952005
100;0.5361827115745342;0.15255458753182302
105;0.5728060144641409;0.16462141015980442
110;0.41987455706837856;0.17680790507792804
115;0.41145204732640767;0.18585524817482568
120;0.445627276841977;0.16867114108119793
125;0.37403415898002346;0.4753636171934937
130;0.43403152160907943;0.17554668472072288
135;0.4372897659483958;0.1687452799185241
140;0.38896231797750547;0.23989470204132943
145;0.46880412181867565;0.15784891000547102
150;0.4089548791067466;0.19907453452003462
155;0.4271460272964707;0.20209699484597735
160;0.47909029654014335;0.17762079733686897
165;0.3844888025943841;0.4796386124613784
170;0.5083814817331598;0.17863595307129512
175;0.4023738312559933;0.19218541065327488
180;0.6813498371382977;0.15679465155703362
185;0.6538785920656783;0.16642775577105084
190;0.4179528919040605;0.17149775610412438
195;0.38899017070843434;0.1738401070906604
200;0.4082241407640548;0.17791354455343247
205;0.4550548803515882;0.1592869400141705
210;0.553993121657142;0.16513657395074718
215;0.5347737731305293;0.1723179590706886
220;0.6748119145844946;0.16555598154894094
225;0.36251547378787385;0.2467551996773493
230;0.41226198747362464;0.17891198390390134
235;0.362008095568797;0.33131015539759334
240;0.3566049230816818;0.309068620390139
245;0.42469776392470776;0.1588027167946098
250;0.5970986476764684;0.16673624489470507
255;0.40152579587241544;0.19925187306516476
260;0.5769126241278829;0.16860954731931724
265;0.36212951761634987;0.28028713212854894
270;0.39309387215775055;0.21006850606028785
275;0.3678088635716145;0.22571239364785897
280;0.3974559198706546;0.20935003244913392
285;0.43084199597341466;0.1825527830969199
290;0.5108008957860178;0.1759441069985593
295;0.3864325828466469;0.20936746306184503
300;0.491905004905602;0.16793627243822512
