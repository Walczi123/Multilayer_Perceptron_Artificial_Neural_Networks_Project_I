Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 64, 32, 16, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4080.960271571987;0.198;89.73333333333333
10;-4019.9341329169133;0.22133333333333333;88.26666666666667
15;-3954.3623935576315;0.3333333333333333;86.03333333333333
20;-4321.463578705696;0.20733333333333334;90.73333333333333
25;-4329.555151753066;0.26866666666666666;88.76666666666667
30;-4139.623464394343;0.102;91.73333333333333
35;-4120.73859288243;0.09066666666666667;91.23333333333333
40;-4059.7510189784502;0.14733333333333334;90.3
45;-4122.997306846201;0.14533333333333334;90.96666666666667
50;-4200.631874267957;0.186;89.2
55;-4563.161374734189;0.4053333333333333;84.63333333333334
60;-3816.4031898075277;0.216;83.96666666666667
65;-4078.88709657743;0.096;91.3
70;-4178.84099119906;0.19;89.63333333333333
75;-4228.647530328513;0.18466666666666667;90.0
80;-4236.871508021493;0.184;88.66666666666667
85;-4119.298093887796;0.10066666666666667;91.43333333333334
90;-4081.356363078132;0.12066666666666667;90.9
95;-4131.736177486781;0.10533333333333333;91.63333333333334
100;-4131.9196276569555;0.09666666666666666;91.7
105;-4102.166416977349;0.098;91.63333333333334
110;-4032.7547568386653;0.15;90.06666666666666
115;-4191.858616474365;0.14666666666666667;90.3
120;-4037.9080199750815;0.14266666666666666;90.36666666666666
125;-4274.927862674531;0.22333333333333333;90.4
130;-4075.1972572043214;0.12466666666666666;90.83333333333333
135;-4351.264727721693;0.29733333333333334;87.6
140;-4144.658944478437;0.12333333333333334;90.7
145;-4005.4145191272073;0.22733333333333333;88.3
150;-4090.0003754350637;0.16666666666666666;90.06666666666666
155;-4205.626700801915;0.19;89.86666666666666
160;-4128.975051348879;0.156;89.13333333333333
165;-4127.092611310751;0.12;91.36666666666666
170;-3758.97615781922;0.684;77.16666666666666
175;-4213.253408037115;0.13866666666666666;91.36666666666666
180;-4282.92355904912;0.174;90.03333333333333
185;-4194.706245699751;0.17533333333333334;90.43333333333334
190;-4136.284885379163;0.168;89.96666666666667
195;-3671.986702128513;0.6893333333333334;76.76666666666667
200;-3952.1370483577402;0.216;87.83333333333333
205;-4089.8711299984034;0.10133333333333333;91.4
210;-4066.481311332416;0.184;88.36666666666667
215;-4098.976900979331;0.09266666666666666;91.3
220;-4015.3489490724787;0.12733333333333333;90.26666666666667
225;-4329.059005976058;0.254;89.3
230;-4074.175774484508;0.12133333333333333;90.63333333333333
235;-4475.78836033158;0.35733333333333334;85.83333333333333
240;-4093.0898371622197;0.09666666666666666;91.5
245;-4137.306368098977;0.11666666666666667;91.3
250;-4071.480315464456;0.13533333333333333;90.53333333333333
255;-4142.124010859884;0.10066666666666667;90.60000000000001
260;-4046.957497423455;0.13666666666666666;89.9
265;-4108.781015078033;0.144;90.76666666666667
270;-4032.154379192713;0.13266666666666665;90.46666666666667
275;-3820.9758408577163;0.502;81.73333333333333
280;-4092.632256136306;0.09733333333333333;91.36666666666666
285;-4218.234683387695;0.17066666666666666;91.13333333333333
290;-4278.468639030479;0.3486666666666667;85.5
295;-4048.3052269334817;0.166;89.63333333333333
300;-4185.668230635715;0.25333333333333335;88.23333333333333
