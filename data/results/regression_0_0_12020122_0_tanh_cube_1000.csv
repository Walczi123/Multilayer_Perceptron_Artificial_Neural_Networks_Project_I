Train dataset: data/regression/data.cube.train.1000.csv
Test dataset: data/regression/data.cube.test.1000.csv
Layers: [1, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.5019352159477143;0.12770043928077202
10;0.7533771280739933;0.11117274836463988
15;0.7809566825618194;0.11035702543056188
20;0.5063996976575211;0.12709910934770818
25;0.6754915114314172;0.11409347084896007
30;0.34745362620955433;0.23399980004478957
35;0.43023249607469877;0.1422243765413092
40;0.5881529736675318;0.11908660466491829
45;0.4708015173749918;11.954507844133543
50;0.36364104287077437;0.5097667133973998
55;0.5748822317589402;0.12009518965849042
60;0.6860841102942387;0.11363088514217999
65;0.3728930639688295;0.6262950700862178
70;0.6129037235538971;0.1174134392786691
75;0.6971799237512336;0.11317120853306366
80;0.7150676243456017;0.11247912998806261
85;0.9679533963853101;0.10660621062582128
90;0.7829751312911192;0.11030090052810261
95;0.9728864797783555;0.1065364609369187
100;0.8176533967553846;0.40038936507498485
105;0.35714865387229605;0.1962906872546886
110;0.5696678634024223;0.12051584240562382
115;0.34846408487425473;0.33352693420002427
120;0.983219853271168;0.10639387195484692
125;0.46370536936432494;15.620808545500312
130;0.3722494572733948;0.17381965983051012
135;0.354232421609605;0.40298730884232137
140;0.5707964662258048;0.12042356333315975
145;0.3710965300571705;0.1750508831610021
150;0.5839285343930282;0.11939844632736468
155;0.5935483207922522;0.9165902087016663
160;0.6035231593744986;0.11801843488476685
165;0.579773403974805;0.11971343822248719
170;0.5241045323064272;1.8552944047521815
175;0.4967287718175371;0.12843218095890524
180;0.358237511704358;0.44784720033838926
185;0.3630203718187322;0.5024876339189773
190;0.4904710170218257;0.12935845911982263
195;0.7406772051609335;0.11158164526339094
200;0.7561784288536009;0.46176844663404265
205;0.6206085623737629;0.11694068393504888
210;0.35878278464040536;0.45397774532150625
215;0.6004510546419028;0.1182240147081123
220;0.38177573602093834;0.16527349725857035
225;0.3817768813262769;0.1652726114481053
230;0.6366872689762242;0.7108841915970976
235;0.40621167966993105;1.2999494273050785
240;0.5288146451459602;0.1243971503079032
245;0.5368400587540016;0.12354082890824625
250;0.8567795396787115;0.10852621234656203
255;0.6947384763703114;0.11327026405717647
260;0.3827646633732031;0.1645190655425298
265;0.8744025901591158;0.10817034766543136
270;0.3624834657445259;0.18634533754086072
275;0.5603825367342861;0.12130219250097893
280;0.36306075901946666;0.18544026734658992
285;1.2385806236361447;0.10396457234460955
290;0.7613898830567414;0.1109259736980059
295;0.6163251096547104;0.7933178154879464
300;1.0244084385378776;0.10586934086870255
