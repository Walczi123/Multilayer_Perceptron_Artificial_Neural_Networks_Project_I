Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 64, 32, 16, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-405.74860386175556;0.12666666666666668;91.0
10;-409.21433951455526;0.15333333333333332;90.33333333333333
15;-413.7265714548841;0.12666666666666668;91.0
20;-414.07992061185325;0.1;91.66666666666666
25;-412.3402771937643;0.13333333333333333;90.66666666666666
30;-421.9401051526588;0.10666666666666667;92.0
35;-416.44704404265156;0.13333333333333333;91.0
40;-420.84149293065735;0.12666666666666668;91.33333333333333
45;-425.8634218313724;0.16666666666666666;91.0
50;-408.57330831846764;0.20666666666666667;86.0
55;-421.600307179068;0.07333333333333333;93.0
60;-407.52681203093863;0.25333333333333335;88.0
65;-412.6936263507333;0.08666666666666667;92.33333333333333
70;-407.2776947429142;0.3333333333333333;85.66666666666667
75;-408.86099035758616;0.19333333333333333;89.66666666666666
80;-413.83080332382883;0.21333333333333335;89.0
85;-420.71015869495596;0.20666666666666667;90.0
90;-414.0663694284749;0.17333333333333334;88.66666666666667
95;-411.4772310764089;0.1;92.0
100;-422.9209343223372;0.12;92.33333333333333
105;-414.8772996113579;0.16;90.0
110;-391.59589041239707;0.4266666666666667;83.33333333333334
115;-416.6826101472976;0.08;92.33333333333333
120;-411.789926683243;0.30666666666666664;87.66666666666667
125;-405.146137416762;0.26666666666666666;87.33333333333333
130;-429.3020551174154;0.38666666666666666;84.0
135;-421.18129090424816;0.18;89.33333333333333
140;-423.48274721719577;0.24;87.66666666666667
145;-419.32386443383604;0.23333333333333334;88.0
150;-420.6444915771053;0.26;89.0
155;-419.0497335780959;0.14;89.0
160;-425.3537248709862;0.13333333333333333;90.33333333333333
165;-415.11286571600397;0.13333333333333333;90.0
170;-411.5428981942596;0.06666666666666667;92.0
175;-423.0387173746603;0.18666666666666668;89.0
180;-417.0745240553608;0.18;90.0
185;-391.2175276877123;0.28;87.0
190;-425.4058408054585;0.13333333333333333;91.33333333333333
195;-389.817682243214;0.31333333333333335;86.0
200;-401.9159678686083;0.22;88.33333333333333
205;-404.3623096006356;0.12666666666666668;90.0
210;-394.12145044565347;0.18666666666666668;89.0
215;-377.9956162726009;0.25333333333333335;86.0
220;-414.2498195986487;0.14666666666666667;89.66666666666666
225;-425.9426401326014;0.08666666666666667;90.33333333333333
230;-405.90495166517263;0.23333333333333334;87.33333333333333
235;-408.92665747543685;0.13333333333333333;89.66666666666666
240;-406.96499913608;0.11333333333333333;91.33333333333333
245;-413.3867734812933;0.09333333333333334;92.0
250;-409.9074866451152;0.16666666666666666;88.0
255;-435.501814541361;0.3333333333333333;82.0
260;-414.4197185854441;0.14666666666666667;90.66666666666666
265;-423.7839804396925;0.22;87.0
270;-425.693522844577;0.14;92.0
275;-427.40606389590937;0.2866666666666667;88.66666666666667
280;-407.65814626663996;0.12666666666666668;90.33333333333333
285;-410.2608358020844;0.13333333333333333;90.66666666666666
290;-411.1759978539121;0.16666666666666666;89.66666666666666
295;-409.5812398549028;0.06666666666666667;92.66666666666666
300;-406.885780834851;0.24666666666666667;88.33333333333333
