Train dataset: data/regression/data.activation.train.1000.csv
Test dataset: data/regression/data.activation.test.1000.csv
Layers: [1, 4, 2, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.00132117561588227;0.02530506290937962
10;0.000825333278622722;0.03146693902589212
15;0.0010105504569303272;0.034110104211033575
20;0.0008247138150121725;0.03078201414345768
25;0.0007710277682238774;0.03105585747569244
30;0.0006638931298478604;0.03007810862785079
35;0.0006571840139306537;0.03146376362545963
40;0.0004971566327837532;0.028824207165231024
45;0.00041021521596679286;0.02730596297646023
50;0.000381122656379736;0.02738383201282568
55;0.00031778440743076365;0.025950471781340613
60;0.000294137761682078;0.025708304772092586
65;0.00024354432604088415;0.02363841143004905
70;0.00022789311136152803;0.02242493078826347
75;0.00021544061095307848;0.02363392384194601
80;0.00017112966111024387;0.02125748978588017
85;0.00016320222030260435;0.022238984698167805
90;0.00014306374656658361;0.020910448176602717
95;0.00014361990798595524;0.022588173932658415
100;0.00012116590392881766;0.020175697597788988
105;0.00011611016396155611;0.021123660541829074
110;0.00011176930790967666;0.02106596166237887
115;9.75577030886627e-05;0.02015463149619795
120;9.576898080798149e-05;0.018944685795321776
125;9.191513424698346e-05;0.019147526008920716
130;9.142746955171189e-05;0.02026625273723383
135;8.348263088261198e-05;0.020051277532213238
140;8.119762105588256e-05;0.01954917992395358
145;7.109305564523429e-05;0.01881009590033552
150;7.271939566353398e-05;0.018894247306007143
155;7.184717095094468e-05;0.019532766241782067
160;6.633773756976146e-05;0.01835348008656541
165;6.48381098701444e-05;0.018284343633461396
170;6.0358341730810215e-05;0.01822368669987653
175;6.780026547127354e-05;0.019235168032080495
180;5.786826192289808e-05;0.018104742363240115
185;6.374362802440001e-05;0.019139288688697707
190;5.61183451816691e-05;0.018383629097075083
195;5.54422984843152e-05;0.018078627041111676
200;5.5537314485813225e-05;0.01822387663423633
205;5.476541815119633e-05;0.017713984015645612
210;4.939658448402016e-05;0.01817221904455003
215;5.339807052705806e-05;0.018762068335872666
220;5.082427143803079e-05;0.018728483879435737
225;5.194914579940733e-05;0.01877498360827422
230;5.2700606835380265e-05;0.019063891924977087
235;4.882056243844012e-05;0.017893415325577512
240;4.500612262271526e-05;0.017996817442083816
245;4.8660906104309305e-05;0.018743133934451307
250;4.520571022727569e-05;0.018608174677744723
255;4.9376709988652386e-05;0.019235403298440347
260;4.762359941077418e-05;0.019389343437869182
265;4.433904914476931e-05;0.01870321785002886
270;4.3277880879617925e-05;0.01859512298696459
275;4.4705640413823486e-05;0.01897339507009718
280;4.100826596960824e-05;0.018222522044159875
285;3.856582300639249e-05;0.017948699284849663
290;3.859890432291809e-05;0.018115644065610524
295;4.28397849454663e-05;0.019595743421733782
300;3.825274749891346e-05;0.018273123514091282
