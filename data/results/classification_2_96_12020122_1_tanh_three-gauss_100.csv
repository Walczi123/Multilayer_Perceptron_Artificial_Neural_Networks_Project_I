Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 64, 32, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-434.61375485629;0.05333333333333334;93.33333333333333
10;-428.9507947594873;0.04666666666666667;93.66666666666667
15;-437.2685603262067;0.06666666666666667;93.0
20;-457.85451050511585;0.08;93.33333333333333
25;-464.10638586353366;0.05333333333333334;93.0
30;-448.54236458533967;0.08;93.33333333333333
35;-435.25478605237754;0.06;93.0
40;-449.30117883375027;0.06666666666666667;93.33333333333333
45;-428.126313393226;0.11333333333333333;92.66666666666666
50;-469.7828971437147;0.08;92.33333333333333
55;-463.8187038244152;0.06666666666666667;93.0
60;-427.8521825374859;0.04;93.33333333333333
65;-425.1317099497184;0.06;93.33333333333333
70;-463.70092077209216;0.06;93.0
75;-444.9588458802168;0.06666666666666667;93.33333333333333
80;-463.0077736415322;0.05333333333333334;93.33333333333333
85;-457.0571315056111;0.06666666666666667;93.0
90;-462.65442448456304;0.05333333333333334;92.66666666666666
95;-441.8985753188586;0.05333333333333334;93.0
100;-445.6519930107768;0.07333333333333333;93.0
105;-452.12588329046247;0.08666666666666667;93.0
110;-463.29545568065066;0.04;93.33333333333333
115;-452.54489956528226;0.08;92.33333333333333
120;-454.4408907867884;0.07333333333333333;93.0
125;-447.9148845726304;0.06;93.0
130;-454.5586738391114;0.06;93.66666666666667
135;-454.67645689143444;0.06666666666666667;93.66666666666667
140;-448.4110303496383;0.18666666666666668;91.33333333333333
145;-465.2049980855351;0.05333333333333334;92.66666666666666
150;-446.80272116725064;0.11333333333333333;92.33333333333333
155;-465.2049980855351;0.05333333333333334;92.66666666666666
160;-461.67359531488466;0.06;93.0
165;-469.8871290126594;0.04;92.66666666666666
170;-455.6051701266405;0.03333333333333333;93.66666666666667
175;-469.2596489999502;0.05333333333333334;92.66666666666666
180;-462.07906040632616;0.08;92.66666666666666
185;-458.73110780584943;0.04;94.0
190;-454.96413893055296;0.05333333333333334;93.66666666666667
195;-470.8158422478655;0.06666666666666667;92.66666666666666
200;-458.9010067926448;0.06666666666666667;93.0
205;-456.06275115255437;0.05333333333333334;93.33333333333333
210;-458.20785966208484;0.06;93.33333333333333
215;-451.56407039560384;0.04666666666666667;94.0
220;-424.43856281915845;0.05333333333333334;93.66666666666667
225;-458.32564271440793;0.06666666666666667;93.33333333333333
230;-460.5228671584108;0.06666666666666667;92.66666666666666
235;-455.3696040219944;0.04666666666666667;93.66666666666667
240;-453.40794568263755;0.03333333333333333;94.33333333333334
245;-435.0713358822038;0.06666666666666667;93.66666666666667
250;-462.07906040632616;0.03333333333333333;93.66666666666667
255;-457.7367274527927;0.07333333333333333;93.33333333333333
260;-454.27099179999294;0.04666666666666667;94.0
265;-450.5696900425471;0.05333333333333334;93.66666666666667
270;-455.94496810023134;0.06666666666666667;92.66666666666666
275;-463.1776726283276;0.03333333333333333;93.33333333333333
280;-429.93162392916577;0.05333333333333334;93.33333333333333
285;-455.6051701266405;0.03333333333333333;93.66666666666667
290;-464.7995329940936;0.06;92.66666666666666
295;-443.23275364550614;0.04;94.0
300;-457.6846115183203;0.08;92.66666666666666
