Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-449.6409768073411;0.1;91.0
10;-427.5895140660831;0.22;90.33333333333333
15;-445.2850926704293;0.21333333333333335;90.0
20;-437.9481562733883;0.16666666666666666;91.33333333333333
25;-427.8521825374859;0.04;93.33333333333333
30;-423.915314675394;0.06;93.0
35;-430.86033716437174;0.05333333333333334;92.33333333333333
40;-422.3591214274786;0.04;93.66666666666667
45;-433.2003582284134;0.20666666666666667;90.66666666666666
50;-456.19408538825576;0.10666666666666667;90.33333333333333
55;-432.180964307641;0.08;92.33333333333333
60;-368.80125340514786;0.13333333333333333;87.66666666666667
65;-428.8715764582583;0.15333333333333332;91.66666666666666
70;-445.2465279193353;0.1;92.33333333333333
75;-434.9671040132591;0.06666666666666667;92.33333333333333
80;-430.3756537717012;0.16666666666666666;91.66666666666666
85;-420.0441139311527;0.05333333333333334;93.66666666666667
90;-411.98692803679506;0.17333333333333334;90.0
95;-432.180964307641;0.08;92.33333333333333
100;-394.7739440260784;0.4066666666666667;84.66666666666667
105;-445.2465279193353;0.1;92.33333333333333
110;-434.1561738303761;0.05333333333333334;92.66666666666666
115;-448.8435978078364;0.08666666666666667;92.0
120;-411.3073320896135;0.09333333333333334;92.0
125;-424.4385628191585;0.04;93.66666666666667
130;-417.02240812088843;0.14;91.33333333333333
135;-437.16432845726195;0.07333333333333333;92.33333333333333
140;-439.73991562594966;0.17333333333333334;92.0
145;-498.51671390254774;0.12666666666666668;86.0
150;-406.2854031888984;0.06666666666666667;92.33333333333333
155;-446.0574581022183;0.11333333333333333;92.0
160;-432.06318125531794;0.09333333333333334;93.0
165;-474.51714400531125;0.10666666666666667;89.33333333333333
170;-436.23561522205597;0.05333333333333334;92.66666666666666
175;-428.6631127203689;0.05333333333333334;93.0
180;-423.27428347930635;0.09333333333333334;93.0
185;-449.92865884645954;0.13333333333333333;91.33333333333333
190;-448.42458153301664;0.11333333333333333;92.0
195;-423.0522685580386;0.04666666666666667;93.33333333333333
200;-419.0632847614743;0.04;93.33333333333333
205;-426.7535703154844;0.04;93.66666666666667
210;-446.21380590563535;0.18666666666666668;90.66666666666666
215;-411.55644937763793;0.04;92.66666666666666
220;-427.5645004983674;0.05333333333333334;93.33333333333333
225;-414.66883587346854;0.04;93.33333333333333
230;-449.9807747809318;0.12666666666666668;90.66666666666666
235;-428.6631127203689;0.05333333333333334;93.0
240;-427.2111513413983;0.06;93.33333333333333
245;-422.58113634874644;0.08666666666666667;93.33333333333333
250;-428.4661113668168;0.16;91.66666666666666
255;-437.5426911819468;0.17333333333333334;91.33333333333333
260;-432.12884837316864;0.04;92.66666666666666
265;-429.8138408768427;0.05333333333333334;92.66666666666666
270;-434.83576977755774;0.11333333333333333;92.66666666666666
275;-489.8977151133315;0.10666666666666667;87.33333333333333
280;-410.61418495905355;0.08666666666666667;92.33333333333333
285;-397.7841874520053;0.06;91.66666666666666
290;-398.4502322158086;0.21333333333333335;88.0
295;-397.7841874520053;0.06;91.66666666666666
300;-438.9560878098233;0.08666666666666667;92.33333333333333
