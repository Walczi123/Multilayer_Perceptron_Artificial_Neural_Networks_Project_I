Train dataset: data/regression/data.activation.train.1000.csv
Test dataset: data/regression/data.activation.test.1000.csv
Layers: [1, 2, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.002372522177310773;0.03944737256774554
10;0.0025302287818447684;0.041300594699056316
15;0.0026861043699164394;0.042817564823838604
20;0.002225841926662542;0.03979188853893515
25;0.002629534813080675;0.04339100306516459
30;0.002660763866776283;0.0446055897207349
35;0.00247621532822917;0.045635635582862585
40;0.0028429947170834483;0.047434915780687134
45;0.0031032126699475143;0.04791928244562484
50;0.0036551365613481423;0.050169651675754656
55;0.0030539429807171638;0.048374409570634554
60;0.003926368073769369;0.05115609386452154
65;0.0030439122470910427;0.04844452696577525
70;0.0030917979362595645;0.047666476217548805
75;0.003203989758541456;0.04934216650531529
80;0.003157034035201916;0.04941817338577913
85;0.0034248270737915884;0.05039103530701698
90;0.0036665239270028834;0.0513941976842892
95;0.004307664841325004;0.0533816497914761
100;0.0036097238662572604;0.050786855859811554
105;0.0039856839362818535;0.05258519388656649
110;0.0037976804681728233;0.05216650300020935
115;0.0034391978719379933;0.05128313366085516
120;0.0031445867721562504;0.050104180233016236
125;0.003793560817415851;0.05179044626820982
130;0.0041085749833337445;0.05295511118051248
135;0.004041458613893562;0.05314652002403757
140;0.005445035893906539;0.055729655866765294
145;0.004240408083521164;0.05291452251523995
150;0.00402348690415431;0.052751853785906744
155;0.0030304621978206204;0.050479804188747014
160;0.004025982832834045;0.05244769715778285
165;0.0044674892523978325;0.053688882442543516
170;0.003919942843749171;0.05262941658872313
175;0.0031901917659486;0.05031136295390212
180;0.0035443301383887853;0.05175210551911341
185;0.0037451809339385063;0.05202407950647907
190;0.004285905282513295;0.05327123987235835
195;0.0046937257473300955;0.05432932967803717
200;0.004223683129744265;0.053348363000977096
205;0.003901025683272898;0.0523172343641249
210;0.0051389531012103066;0.055518170181453635
215;0.0038575289042335004;0.05263119798444996
220;0.004491526319215244;0.05382913411422793
225;0.004072804885787293;0.05259134466377357
230;0.0041564719163795045;0.0528186494707016
235;0.0035964941427728135;0.05140361837638298
240;0.005235807286672079;0.055231010612053946
245;0.004790338159873261;0.05373324078091766
250;0.005092165869989239;0.054645758234034225
255;0.002770287357613567;0.0488414985778787
260;0.0038846548996969684;0.05186397998288815
265;0.003677850986555119;0.05187101810116292
270;0.003932968573585739;0.05181901172177768
275;0.004660097286832316;0.05334410541454522
280;0.005126880979339165;0.05470606467560859
285;0.005328822111935509;0.05485925178784711
290;0.0046017868965870685;0.053399490143385346
295;0.003966208626752819;0.05155895355786247
300;0.004593551220559079;0.05372724813988011
