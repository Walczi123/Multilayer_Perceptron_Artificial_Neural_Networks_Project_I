Train dataset: data/regression/data.activation.train.1000.csv
Test dataset: data/regression/data.activation.test.1000.csv
Layers: [1, 8, 4, 2, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.3663089747585265;0.071047829073574
10;0.3247920658531189;0.07189367944964194
15;0.42884741858694025;0.07056228077433566
20;0.23057768811865165;0.08177849761909303
25;0.392489560396758;0.07076514280712216
30;0.3864580117245031;0.07081807748567653
35;0.26273555224372097;0.07543754445763533
40;0.2582671527534444;0.07594746981729147
45;0.5017903502816414;0.0705388792398418
50;0.28496077032993605;0.07361215139756376
55;0.43309947898500667;0.07054917966848653
60;0.27364102730571854;0.07442037061174817
65;0.3396748221653415;0.07151651115797718
70;0.5875948053108558;0.07083835660943785
75;0.43405443471692534;0.07054649269309858
80;0.3905343699089988;0.07078159279522615
85;0.36822062695932795;0.07102209431737984
90;0.38754641026716746;0.07080803975752381
95;0.3149095984100232;0.07220649872832495
100;0.38934572094912034;0.070791921570196
105;0.2914452070504855;0.0732321903812855
110;0.3275222949064064;0.07181673195977474
115;0.24989643974213985;0.07710713067405357
120;0.4592760818873707;0.07050563745503009
125;0.34742117442433446;0.07135646397212421
130;0.30925355337834626;0.07241302833588253
135;0.2515928473817676;0.07684647999126493
140;0.43495219027483706;0.07054404998831953
145;0.7072445113051984;0.07149543940778089
150;0.3196855864539428;0.07204824448779056
155;0.2535265500339652;0.07656652708098656
160;0.7643530435896557;0.07184953322353048
165;0.38555707564166924;0.070826553475764
170;0.2605987521660914;0.07567339540357657
175;0.2746699796394789;0.07433788603041387
180;0.620426329084631;0.07100075278959303
185;0.2615407835962632;0.07556769489370227
190;0.23649787737226735;0.0798737535288246
195;0.36728738544605827;0.0710345442914675
200;0.5122795274613097;0.07056183912096282
205;0.525729401902921;0.07059801288479037
210;0.40048895299378995;0.07070448256064053
215;0.4204080740166077;0.07059410204081054
220;0.3289734178004868;0.0717773510036492
225;0.31285046411724643;0.07227916813701846
230;0.3626356077551195;0.07109989024480289
235;0.6004081098858248;0.07089951462426172
240;0.41018146864068955;0.07064407835356018
245;0.4806571001299287;0.07050897451551291
250;0.2385601310205526;0.07933909752961425
255;0.2337814353279193;0.08066862799420274
260;0.2292319757059125;0.08231750926349148
265;0.3471218949593889;0.07136224579442996
270;0.3116459163267521;0.07232299175521086
275;0.4679394194844822;0.07050331176253148
280;0.6460720203657181;0.07113886160270197
285;0.6588614949943962;0.07121065149199605
290;0.3830438359802939;0.07085101553453974
295;0.2487034843937204;0.0772996095336373
300;0.3157608366900837;0.07217726084343802
