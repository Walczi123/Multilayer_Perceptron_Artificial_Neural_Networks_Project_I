Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-3977.069509088264;0.10466666666666667;90.26666666666667
10;-4193.422094508534;0.216;89.83333333333333
15;-4518.1891887579695;0.118;91.83333333333333
20;-4339.81582848855;0.154;91.60000000000001
25;-4416.863569447731;0.14333333333333334;91.86666666666666
30;-4315.97260639473;0.16733333333333333;91.23333333333333
35;-4157.844379941495;0.08866666666666667;91.93333333333334
40;-4241.058511560743;0.15466666666666667;91.46666666666667
45;-3853.358895460299;0.11466666666666667;88.96666666666667
50;-4250.868892056567;0.13333333333333333;91.9
55;-4162.191908882243;0.18733333333333332;90.36666666666666
60;-4538.42178977991;0.122;91.8
65;-4360.782230191185;0.13333333333333333;92.0
70;-4124.7369502642905;0.14933333333333335;90.76666666666667
75;-4214.775214132018;0.088;92.36666666666666
80;-4337.731191109655;0.092;92.23333333333333
85;-4261.640284141569;0.21866666666666668;90.10000000000001
90;-4331.457409371695;0.17333333333333334;91.2
95;-4342.053706482688;0.13266666666666665;92.10000000000001
100;-4300.122991876458;0.14;91.8
105;-4348.203438771201;0.10066666666666667;92.63333333333334
110;-4193.269924303199;0.142;91.3
115;-4223.14509563321;0.09666666666666666;92.16666666666666
120;-4134.939244668178;0.136;91.03333333333333
125;-4203.18453666797;0.12533333333333332;91.8
130;-4273.196574452607;0.10533333333333333;92.2
135;-4326.043566562917;0.16133333333333333;91.4
140;-4528.219495376022;0.12266666666666666;91.63333333333334
145;-4301.015229159611;0.10266666666666667;92.5
150;-4239.730599631218;0.078;92.63333333333334
155;-4331.339626319373;0.17333333333333334;91.26666666666667
160;-4364.095795638649;0.09733333333333333;92.66666666666666
165;-4235.787465372003;0.15933333333333333;91.33333333333333
170;-4235.216278891848;0.10266666666666667;92.16666666666666
175;-4403.9658160237905;0.17466666666666666;91.46666666666667
180;-4135.335336174323;0.094;91.56666666666666
185;-4318.031211816777;0.09466666666666666;92.63333333333334
190;-4311.167496428068;0.08533333333333333;92.5
195;-4475.75606197761;0.15733333333333333;91.60000000000001
200;-4176.572903649992;0.08866666666666667;92.16666666666666
205;-4345.245311279747;0.126;92.33333333333333
210;-4285.124961091205;0.09733333333333333;92.56666666666666
215;-4247.2103326482975;0.09133333333333334;92.36666666666666
220;-4072.086959507532;0.09733333333333333;91.13333333333333
225;-4221.675405472779;0.162;91.10000000000001
230;-4315.1231114607535;0.15533333333333332;91.53333333333333
235;-4427.602663178762;0.11866666666666667;92.2
240;-4084.2081699016007;0.12466666666666666;90.86666666666666
245;-4350.4913439007705;0.112;92.46666666666667
250;-4157.51186675416;0.15466666666666667;90.8
255;-4322.950997647587;0.08733333333333333;92.53333333333333
260;-4333.44825887685;0.12666666666666668;92.23333333333333
265;-4199.129885753555;0.12933333333333333;91.66666666666666
270;-4295.467963316091;0.12733333333333333;92.10000000000001
275;-4178.371947788809;0.16;90.9
280;-4220.51530373101;0.10533333333333333;92.06666666666666
285;-4282.450338040787;0.19066666666666668;90.83333333333333
290;-4127.131176061845;0.13733333333333334;90.93333333333334
295;-4271.955165610566;0.09;92.56666666666666
300;-4500.899075245065;0.10866666666666666;92.03333333333333
