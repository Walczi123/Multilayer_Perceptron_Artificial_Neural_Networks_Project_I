Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 8, 4, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-349.08772292889046;0.82;74.33333333333333
10;-411.29378090623516;0.16666666666666666;90.33333333333333
15;-410.07738563191066;0.18;90.0
20;-411.46367989303053;0.17333333333333334;90.33333333333333
25;-410.2472846187061;0.18666666666666668;90.0
30;-416.83895795071476;0.18666666666666668;90.66666666666666
35;-411.9869280367951;0.16666666666666666;91.0
40;-416.83895795071476;0.18666666666666668;90.66666666666666
45;-414.75951655903486;0.17333333333333334;90.66666666666666
50;-412.44450906270896;0.18666666666666668;89.33333333333333
55;-402.96246415613746;0.19333333333333333;89.66666666666666
60;-413.0334243243242;0.12;91.33333333333333
65;-409.3842385013507;0.17333333333333334;90.33333333333333
70;-410.8747646314153;0.24;88.33333333333333
75;-414.75951655903486;0.17333333333333334;90.66666666666666
80;-412.9020900886228;0.22;89.0
85;-405.39525470478645;0.16666666666666666;90.33333333333333
90;-409.7240364749415;0.20666666666666667;89.33333333333333
95;-412.32672601038587;0.2;90.0
100;-412.6800751673551;0.16;90.66666666666666
105;-406.95144795270164;0.18666666666666668;89.66666666666666
110;-410.6006337756752;0.14666666666666667;90.66666666666666
115;-398.620131202604;0.23333333333333334;88.0
120;-411.29378090623516;0.16666666666666666;90.33333333333333
125;-412.86352533752876;0.11333333333333333;91.33333333333333
130;-422.3841349951943;0.22666666666666666;90.0
135;-421.24695802209885;0.1;92.33333333333333
140;-433.99773722791804;0.3;87.33333333333333
145;-415.2441999517054;0.05333333333333334;90.33333333333333
150;-417.19230710768386;0.14666666666666667;91.33333333333333
155;-414.7074006245625;0.14;90.0
160;-415.23064876832706;0.14;90.0
165;-414.30193553312097;0.14666666666666667;90.0
170;-410.9539829326443;0.12;91.33333333333333
175;-420.671593943862;0.12;90.66666666666666
180;-407.1870140573478;0.17333333333333334;89.66666666666666
185;-390.6807283605694;0.34;85.66666666666667
190;-416.6826101472977;0.09333333333333334;92.33333333333333
195;-410.09093681528896;0.09333333333333334;91.66666666666666
200;-412.51017618055965;0.15333333333333332;90.66666666666666
205;-411.3458968407075;0.18666666666666668;89.66666666666666
210;-412.86352533752876;0.11333333333333333;91.33333333333333
215;-411.1374331028181;0.06666666666666667;93.0
220;-413.9100216250579;0.07333333333333333;92.66666666666666
225;-411.1895490372904;0.08666666666666667;91.0
230;-418.6442684866544;0.10666666666666667;91.66666666666666
235;-415.0086338470593;0.07333333333333333;92.33333333333333
240;-418.76205153897746;0.10666666666666667;92.33333333333333
245;-414.2498195986486;0.12;91.66666666666666
250;-410.48285072335216;0.16;90.0
255;-405.26392046908506;0.26666666666666666;86.0
260;-405.5787048749601;0.10666666666666667;91.0
265;-411.3073320896135;0.09333333333333334;92.0
270;-418.2388033952129;0.11333333333333333;91.66666666666666
275;-414.3154867164993;0.06666666666666667;92.66666666666666
280;-412.9291924553795;0.07333333333333333;92.33333333333333
285;-419.978446813302;0.09333333333333334;92.66666666666666
290;-413.7265714548841;0.12666666666666668;91.0
295;-410.61418495905355;0.07333333333333333;92.33333333333333
300;-417.0224081208885;0.12666666666666668;91.33333333333333
