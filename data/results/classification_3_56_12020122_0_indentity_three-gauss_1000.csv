Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 32, 16, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-3996.0231549062023;0.25533333333333336;88.16666666666667
10;-4079.669853983648;0.324;87.16666666666667
15;-4064.6520056178933;0.38666666666666666;85.76666666666667
20;-4120.4091868832675;0.34;87.06666666666666
25;-4114.857743441665;0.44733333333333336;84.46666666666667
30;-4140.6396991061665;0.37866666666666665;86.3
35;-4125.770913757573;0.3466666666666667;86.83333333333333
40;-4102.1632577684;0.36;86.56666666666666
45;-4016.1859112122097;0.32666666666666666;86.76666666666667
50;-4068.0698029343025;0.31;87.3
55;-4090.250511112221;0.3233333333333333;87.23333333333333
60;-4098.643317382087;0.3893333333333333;85.76666666666667
65;-4077.590412591968;0.32266666666666666;87.16666666666667
70;-4057.9581892159804;0.3413333333333333;86.53333333333333
75;-4094.4031274984577;0.438;84.86666666666667
80;-4055.695297654127;0.346;86.46666666666667
85;-4097.18198241782;0.32866666666666666;87.1
90;-4070.0950395924688;0.3446666666666667;86.63333333333333
95;-4090.73310570585;0.348;86.7
100;-4144.132537125723;0.364;86.56666666666666
105;-4036.8917332424826;0.288;87.66666666666667
110;-4024.5015879798884;0.364;86.13333333333333
115;-4051.5635172375237;0.32866666666666666;87.0
120;-4084.5354350809457;0.31866666666666665;87.3
125;-4056.293586501038;0.404;85.36666666666667
130;-4060.458735681521;0.29933333333333334;87.63333333333333
135;-4169.439182982851;0.376;86.23333333333333
140;-4109.890019274463;0.408;85.46666666666667
145;-4026.4747087035826;0.3953333333333333;85.33333333333334
150;-4010.538591097827;0.2826666666666667;87.66666666666667
155;-4244.12917409653;0.432;84.73333333333333
160;-4163.030959821015;0.36933333333333335;86.33333333333333
165;-4112.180013203074;0.38466666666666666;86.06666666666666
170;-4000.5833251829217;0.32266666666666666;86.83333333333333
175;-4193.20318677544;0.37866666666666665;86.13333333333333
180;-4183.524140515317;0.3913333333333333;86.0
185;-4109.617977217765;0.36;86.6
190;-3991.1377562284033;0.36733333333333335;85.8
195;-4162.270056773564;0.41333333333333333;85.33333333333334
200;-4042.654747610148;0.36466666666666664;86.1
205;-4063.190670653626;0.3233333333333333;87.1
210;-4070.842391456542;0.312;87.26666666666667
215;-4082.55813675917;0.362;86.36666666666667
220;-3972.7667592749576;0.296;87.23333333333333
225;-4145.648076823502;0.3913333333333333;85.9
230;-4093.295141691159;0.37333333333333335;86.26666666666667
235;-4119.084382141917;0.4066666666666667;85.5
240;-4009.856906351604;0.30866666666666664;87.13333333333333
245;-4109.890019274463;0.408;85.46666666666667
250;-4159.775776705146;0.344;87.1
255;-4073.887022035481;0.3606666666666667;86.3
260;-4053.2896094722346;0.332;86.83333333333333
265;-3977.417610237243;0.37733333333333335;85.53333333333333
270;-4011.0420216610896;0.392;85.39999999999999
275;-4060.091835341174;0.308;87.4
280;-4048.8565958331346;0.3233333333333333;87.03333333333333
285;-4039.3661957303993;0.4673333333333333;83.96666666666667
290;-4074.7907217029715;0.33666666666666667;86.86666666666667
295;-4060.466020467776;0.40066666666666667;85.53333333333333
300;-4050.408611482968;0.3973333333333333;85.43333333333332
