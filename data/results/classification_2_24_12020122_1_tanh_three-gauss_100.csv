Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 16, 8, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-438.19727356141277;0.06666666666666667;93.33333333333333
10;-444.38348180197994;0.09333333333333334;93.33333333333333
15;-441.257544122771;0.07333333333333333;93.0
20;-459.8818359623233;0.05333333333333334;93.66666666666667
25;-453.8134107740791;0.06;93.33333333333333
30;-459.2408047662357;0.06666666666666667;93.0
35;-445.429978089509;0.05333333333333334;93.33333333333333
40;-441.61089327974014;0.06;92.33333333333333
45;-432.991894490524;0.06666666666666667;93.66666666666667
50;-467.06242455594725;0.05333333333333334;93.33333333333333
55;-463.1255566938553;0.04;94.0
60;-446.2930242068644;0.05333333333333334;93.0
65;-433.16179347731935;0.09333333333333334;92.66666666666666
70;-463.29545568065066;0.04;93.33333333333333
75;-441.6630092142125;0.08;93.0
80;-464.10638586353366;0.05333333333333334;93.0
85;-461.7392624327353;0.05333333333333334;93.0
90;-462.7722075368861;0.06;92.66666666666666
95;-447.3916364288658;0.06;92.0
100;-447.2738533765428;0.05333333333333334;93.33333333333333
105;-454.96413893055296;0.07333333333333333;93.0
110;-462.1968434586492;0.04;93.66666666666667
115;-463.8187038244152;0.06666666666666667;93.0
120;-459.3585878185587;0.05333333333333334;93.66666666666667
125;-449.30117883375027;0.07333333333333333;92.66666666666666
130;-449.3532947682226;0.06666666666666667;93.33333333333333
135;-457.04358032223274;0.06666666666666667;93.66666666666667
140;-449.6930927418134;0.11333333333333333;92.33333333333333
145;-466.3036103075366;0.05333333333333334;92.33333333333333
150;-453.34227856478697;0.07333333333333333;93.33333333333333
155;-460.9804481843247;0.05333333333333334;93.33333333333333
160;-460.45720004056017;0.05333333333333334;93.33333333333333
165;-467.4543384640104;0.04666666666666667;92.66666666666666
170;-454.388774852316;0.04666666666666667;93.33333333333333
175;-467.520005581861;0.04;92.66666666666666
180;-462.48452549776766;0.07333333333333333;92.66666666666666
185;-465.32278113785816;0.04;93.33333333333333
190;-459.3585878185587;0.05333333333333334;93.66666666666667
195;-470.0049120649825;0.02666666666666667;93.33333333333333
200;-463.5831377197691;0.05333333333333334;93.0
205;-460.45720004056017;0.05333333333333334;93.33333333333333
210;-461.96127735400313;0.04666666666666667;93.0
215;-446.35869132471504;0.03333333333333333;94.33333333333334
220;-446.7506052327782;0.07333333333333333;92.66666666666666
225;-454.1010928131975;0.04;94.0
230;-463.0077736415322;0.05333333333333334;93.33333333333333
235;-454.27099179999294;0.04666666666666667;94.0
240;-455.199705035199;0.04;93.66666666666667
245;-436.45763014332374;0.08;93.0
250;-461.7913783672077;0.04666666666666667;93.66666666666667
255;-456.9257972699097;0.08;93.0
260;-459.18868883176333;0.02666666666666667;94.66666666666667
265;-449.3532947682226;0.06666666666666667;93.33333333333333
270;-463.6352536542415;0.06666666666666667;93.0
275;-458.6654406879988;0.04666666666666667;92.66666666666666
280;-449.70664392519177;0.04;94.0
285;-464.2241689158567;0.04;93.66666666666667
290;-452.4792324474315;0.04;93.33333333333333
295;-446.52859031151047;0.02666666666666667;93.0
300;-460.9804481843247;0.03333333333333333;94.0
