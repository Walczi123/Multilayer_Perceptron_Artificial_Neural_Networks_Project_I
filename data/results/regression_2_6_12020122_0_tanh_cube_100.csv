Train dataset: data/regression/data.cube.train.100.csv
Test dataset: data/regression/data.cube.test.100.csv
Layers: [1, 4, 2, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.423392827330506;0.2445028644343689
10;0.36214759498130134;0.2334784400657346
15;0.41118490378001454;0.21500076964541828
20;0.3650355080111256;0.2957617393579961
25;0.4526848084690398;0.23716319944483588
30;0.39783245411105445;0.2440021068385511
35;0.4465180240236525;0.22273758463044802
40;0.47313800783381893;0.23582817616272186
45;0.42765209711800334;0.21371958199859023
50;0.3726648013710375;0.2860859656839622
55;0.4155007097494053;0.2388357270146196
60;0.4120216473387213;0.25676480703109306
65;0.47523525074797773;0.22035793680279764
70;0.4295464371815929;0.23938122478593313
75;0.3918060849616265;0.225995488870072
80;0.4763473377387061;0.2228298613639634
85;0.448047550706015;0.20171064633191427
90;0.3900774928738046;0.3059460113062044
95;0.4932555585015524;0.2234829114123561
100;0.4608449688246643;0.23419691308781918
105;0.5276444397025246;0.225633004115916
110;0.42236036487900225;0.24451507498022373
115;0.39892602439977576;0.2512957166998025
120;0.44683545127629887;0.23563090642128373
125;0.37477424610149296;0.30314819107104163
130;0.419499800953063;0.2445821649500942
135;0.43789295484886887;0.22340492645912974
140;0.377767767228417;0.2963936306458933
145;0.39842842825699365;0.22364403232624716
150;0.4289225473566893;0.2458430050696754
155;0.41120956551408216;0.29815716935428194
160;0.471907221013556;0.23787218794404236
165;0.3657421763615191;0.2673457051196367
170;0.4645828509484933;0.23314821658365364
175;0.4025872718121065;0.24816711019095963
180;0.48205442064788595;0.22254105470025937
185;0.5074559379198419;0.23843132934420946
190;0.41079553761632304;0.23336042187779946
195;0.39821151926825543;0.23463470686705637
200;0.4293811866967899;0.23833035906636568
205;0.4183276466654308;0.2027831007267666
210;0.4980240707187038;0.24458995093816976
215;0.4137765812676593;0.26649719340571965
220;0.5385436291409178;0.23413849978778212
225;0.38837214920498975;0.24629280132392636
230;0.4313291083517575;0.2435142337817633
235;0.3747207698175117;0.2547277150806223
240;0.37086966288486295;0.30424883463194075
245;0.40046020357469575;0.2156926312861444
250;0.4869204946583593;0.22256278419763045
255;0.40113604822155957;0.2562434712877333
260;0.44770768094770774;0.24123435154588013
265;0.3964217763567133;0.2578281711681774
270;0.40589709332867735;0.23316051369948254
275;0.3827404502689538;0.2246239896184538
280;0.41699729649794465;0.2669762902979124
285;0.4088753417847879;0.23759678202315188
290;0.4659509972999205;0.2385016989375961
295;0.39948201825132823;0.2490720740081266
300;0.49679518860060273;0.23287242592543483
