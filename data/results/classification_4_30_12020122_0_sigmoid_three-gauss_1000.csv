Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 16, 8, 4, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4063.112522762305;0.17266666666666666;88.53333333333333
10;-4434.953150759181;0.15266666666666667;91.8
15;-4462.7874454486055;0.12066666666666667;92.4
20;-4493.129571389826;0.09733333333333333;93.26666666666667
25;-4507.592891646978;0.118;92.16666666666666
30;-4529.984152361826;0.102;92.5
35;-4452.181774752316;0.09266666666666666;93.03333333333333
40;-4339.2217172397195;0.098;92.46666666666667
45;-4357.791804345759;0.09;93.06666666666666
50;-4372.809652711513;0.10866666666666666;92.26666666666667
55;-4384.289831909495;0.08666666666666667;93.13333333333334
60;-4447.209872987033;0.08133333333333333;93.60000000000001
65;-4456.077989064274;0.07866666666666666;93.73333333333333
70;-4382.013389164263;0.07866666666666666;93.53333333333333
75;-4402.481556290849;0.078;93.56666666666666
80;-4378.36629214033;0.08933333333333333;93.06666666666666
85;-4419.914466423792;0.086;93.60000000000001
90;-4390.999288293826;0.07933333333333334;93.5
95;-4401.919743395991;0.082;93.36666666666666
100;-4359.975477606383;0.08;93.30000000000001
105;-4342.96158374826;0.09066666666666667;92.86666666666666
110;-4366.8954865276455;0.08266666666666667;93.13333333333334
115;-4400.193651161279;0.08866666666666667;93.33333333333333
120;-4372.087314415156;0.096;93.06666666666666
125;-4381.68714237405;0.08066666666666666;93.36666666666666
130;-4357.739688411286;0.07266666666666667;93.30000000000001
135;-4375.709397871373;0.07733333333333334;93.56666666666666
140;-4377.997303000942;0.07866666666666666;93.56666666666666
145;-4343.901759367803;0.07666666666666666;93.4
150;-4361.257539998559;0.07933333333333334;93.46666666666667
155;-4353.687126295912;0.09533333333333334;92.7
160;-4382.640869176972;0.078;93.56666666666666
165;-4335.7538927878795;0.078;93.30000000000001
170;-4355.202665993693;0.092;93.13333333333334
175;-4332.967753082261;0.078;93.33333333333333
180;-4375.120482609757;0.074;93.73333333333333
185;-4330.562064900369;0.07733333333333334;93.2
190;-4371.235730682138;0.08333333333333333;93.60000000000001
195;-4366.134583480194;0.08466666666666667;93.5
200;-4361.284642365315;0.08333333333333333;93.16666666666666
205;-4368.424577408804;0.078;93.63333333333334
210;-4436.026749413467;0.09066666666666667;93.43333333333334
215;-4350.559099817662;0.08;93.33333333333333
220;-4375.04335310757;0.08333333333333333;93.30000000000001
225;-4436.851230779728;0.09533333333333334;93.0
230;-4485.819737359542;0.08;93.23333333333333
235;-4507.400067891507;0.08066666666666666;93.16666666666666
240;-4453.160515122954;0.09;93.26666666666667
245;-4455.946654828573;0.086;93.4
250;-4386.172271947622;0.088;93.46666666666667
255;-4430.601444220351;0.08333333333333333;93.46666666666667
260;-4477.370637557121;0.078;93.56666666666666
265;-4361.400336618597;0.09066666666666667;93.30000000000001
270;-4458.433650110735;0.09533333333333334;93.10000000000001
275;-4387.191665868395;0.078;93.56666666666666
280;-4410.15829066148;0.078;93.66666666666667
285;-4403.553066146093;0.07533333333333334;93.7
290;-4392.057246965693;0.07666666666666666;93.56666666666666
295;-4407.73905129621;0.074;93.7
300;-4397.432525023377;0.07466666666666667;93.66666666666667
