Train dataset: data/regression/data.cube.train.100.csv
Test dataset: data/regression/data.cube.test.100.csv
Layers: [1, 64, 32, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.40115438053690117;1.0779304818806548
10;0.36668032140149626;0.4281610437394246
15;0.41575278728466425;0.203494243388962
20;0.3799444252128274;0.22613062776854145
25;0.4597505985071355;0.2127430616823983
30;0.36825763032191045;0.4479297534505376
35;0.3757463996599539;0.26581755252455963
40;0.4604449690636486;0.20632357744309943
45;0.426907802049709;0.18949369435173608
50;0.382345655724843;0.19465899381309512
55;0.5142651404613425;0.16967626074108128
60;0.4081440219202383;0.23764616645599312
65;0.5645990487354658;0.18345371501279756
70;0.46485018636242653;0.17944594719343
75;0.44126534982691873;0.17243011514562112
80;0.4740499083322067;0.2158914070555743
85;0.637634485087139;0.15276046771503782
90;0.3695695316870274;0.4670871673332964
95;0.5507877854035015;0.18922641655581582
100;0.5595786073041429;0.17930086252148558
105;0.5931560942307749;0.19012816706178118
110;0.41586325856878403;0.2113369580657007
115;0.5254655932767119;0.17152577537815186
120;0.4492359373797094;0.2113025130274768
125;0.3762012038919243;0.5610584367418194
130;0.440701407332565;0.19906620945199816
135;0.45156547674043257;0.19689934203449216
140;0.43665627241242577;0.18786401056828753
145;0.3901369605155755;0.20968576718796855
150;0.41661365667225597;0.21944138514837813
155;0.442538760136487;0.21187345989929943
160;0.4524020552336757;0.20740843890759944
165;0.3981602851715752;0.96590969325901
170;0.45906054293335763;0.20103628569742107
175;0.42219096054136274;0.20620124945570256
180;0.8076746642589573;0.1596179147275324
185;0.6366065831886141;0.1883842625093602
190;0.4359673455914116;0.16814874009686614
195;0.40270264490515867;0.19155964119655475
200;0.43687480807175977;0.198547185083258
205;0.5335615906861378;0.14245772768557485
210;0.4608042806653526;0.21840654157298126
215;0.4737050160231459;0.18350443971256933
220;0.5334093700215508;0.20249722348940602
225;0.5056540512161318;0.15794679645071938
230;0.43235452677458863;0.1894686336166218
235;0.4032024601291081;1.0960842255074295
240;0.3588242088132794;0.3108716609344056
245;0.4214832107255025;0.16629023324467168
250;0.49687536123824433;0.1779363785378783
255;0.4054924166720745;0.21697535595830356
260;0.500505225721681;0.1911274054311452
265;0.3672254202204912;0.4082491576228887
270;0.4189047493330138;0.1908265605021169
275;0.40017882334838967;0.18046898537538164
280;0.4308166182589445;0.20833719903363102
285;0.42680552402577776;0.19592302869777675
290;0.4746312043438318;0.21038508136958822
295;0.4474143145786515;0.17911251812071086
300;0.4568415778742057;0.21543985914318758
