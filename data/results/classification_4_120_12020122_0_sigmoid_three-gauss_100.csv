Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 64, 32, 16, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-480.3572878751646;1.1866666666666668;45.666666666666664
10;-357.1834735743421;0.8266666666666667;73.0
15;-437.77825728659286;0.16;91.66666666666666
20;-445.83544318095045;0.07333333333333333;93.0
25;-471.08997310360553;0.12;90.33333333333333
30;-454.5586738391114;0.08;93.0
35;-435.43823622255127;0.08666666666666667;92.66666666666666
40;-439.41366883573727;0.07333333333333333;93.0
45;-435.0713358822038;0.08666666666666667;93.0
50;-464.6296340072982;0.08;92.66666666666666
55;-449.36684595160096;0.06666666666666667;92.66666666666666
60;-442.9450716063876;0.06666666666666667;92.66666666666666
65;-426.1125391193968;0.08;93.0
70;-459.7119369755278;0.05333333333333334;93.0
75;-432.7042124514055;0.08666666666666667;93.0
80;-468.95841577745335;0.08666666666666667;91.33333333333333
85;-457.0571315056111;0.06666666666666667;93.0
90;-462.7722075368861;0.06;92.66666666666666
95;-453.4079456826376;0.04;93.66666666666667
100;-437.5041264308528;0.06;93.66666666666667
105;-452.88469753887307;0.06;93.0
110;-449.70664392519177;0.04666666666666667;93.33333333333333
115;-455.77506911343596;0.06666666666666667;93.33333333333333
120;-457.04358032223274;0.06666666666666667;93.66666666666667
125;-443.808117723743;0.07333333333333333;93.0
130;-448.0847835594258;0.06666666666666667;93.0
135;-454.96413893055296;0.07333333333333333;93.0
140;-446.8683882851013;0.08;92.66666666666666
145;-460.5228671584108;0.04666666666666667;93.33333333333333
150;-452.53134838190397;0.08;93.0
155;-458.6133247535264;0.05333333333333334;93.33333333333333
160;-452.88469753887307;0.06;93.0
165;-458.4955417012033;0.04666666666666667;93.33333333333333
170;-450.51757410807477;0.06;93.0
175;-460.9283322498523;0.04;93.33333333333333
180;-458.0900766097618;0.07333333333333333;92.66666666666666
185;-460.9283322498523;0.04;93.33333333333333
190;-460.81054919752927;0.05333333333333334;92.66666666666666
195;-460.9283322498523;0.04;93.33333333333333
200;-459.3064718840863;0.06;93.0
205;-456.06275115255437;0.07333333333333333;92.66666666666666
210;-448.43813271639493;0.04666666666666667;93.0
215;-456.9914643877604;0.07333333333333333;93.0
220;-456.9914643877604;0.07333333333333333;93.0
225;-465.32278113785816;0.04;93.33333333333333
230;-454.50655790463907;0.04;93.33333333333333
235;-454.5586738391114;0.08;93.0
240;-458.73110780584943;0.04;94.0
245;-446.8683882851013;0.08;92.66666666666666
250;-457.10924744008344;0.06;93.66666666666667
255;-460.3394169882372;0.06666666666666667;92.66666666666666
260;-450.92303919951627;0.05333333333333334;93.0
265;-457.2791464268788;0.06;93.0
270;-460.3394169882372;0.06666666666666667;92.66666666666666
275;-457.68461151832037;0.05333333333333334;93.0
280;-452.649131434227;0.06666666666666667;93.66666666666667
285;-466.4213933598596;0.04;93.0
290;-457.10924744008344;0.06;93.66666666666667
295;-453.0545965256685;0.06;93.66666666666667
300;-454.50655790463907;0.04;93.33333333333333
