Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 128, 64, 32, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4064.8250638136383;0.106;91.23333333333333
10;-4231.956918177896;0.12266666666666666;92.2
15;-4806.891796248654;0.412;84.83333333333334
20;-4220.304751194079;0.10466666666666667;92.30000000000001
25;-5161.244238969164;0.08866666666666667;83.36666666666666
30;-4553.537603617487;0.11866666666666667;91.83333333333333
35;-4401.894729828275;0.10133333333333333;92.73333333333333
40;-4377.5553619574475;0.08933333333333333;92.80000000000001
45;-4302.075276630519;0.084;93.10000000000001
50;-4196.947282902838;0.146;87.56666666666668
55;-4127.040495376279;0.1;91.46666666666667
60;-5003.893573934933;0.08666666666666667;87.36666666666667
65;-4330.8799564944175;0.18866666666666668;91.43333333333334
70;-4276.440295184138;0.08666666666666667;93.06666666666666
75;-4193.065638163392;0.08933333333333333;92.33333333333333
80;-4681.76151959569;0.25666666666666665;88.46666666666667
85;-4380.593726139264;0.16533333333333333;91.23333333333333
90;-4487.989859436788;0.08066666666666666;92.86666666666666
95;-4443.927587504407;0.10466666666666667;92.80000000000001
100;-4333.187679204488;0.09666666666666666;93.03333333333333
105;-4317.9019663801155;0.09066666666666667;92.80000000000001
110;-4262.49813427171;0.08666666666666667;92.83333333333333
115;-4325.717319772704;0.13266666666666665;92.53333333333333
120;-4218.030397247888;0.08866666666666667;92.60000000000001
125;-4199.494697294861;0.12933333333333333;91.83333333333333
130;-4335.348427696437;0.07466666666666667;93.16666666666666
135;-4440.212734563584;0.096;93.23333333333333
140;-4892.136360513282;0.09;88.06666666666668
145;-4816.241436509616;0.10266666666666667;91.33333333333333
150;-4453.967267707755;0.168;91.73333333333333
155;-4421.013078645794;0.09933333333333333;90.8
160;-4302.326482717584;0.08466666666666667;92.5
165;-4292.122099514655;0.09066666666666667;93.0
170;-4491.795393063178;0.10666666666666667;92.03333333333333
175;-4337.257970101323;0.082;92.93333333333334
180;-4312.429741239743;0.124;92.73333333333333
185;-4396.476709421415;0.09133333333333334;92.53333333333333
190;-4066.9107716024405;0.072;91.03333333333333
195;-4559.75091422481;0.10666666666666667;91.60000000000001
200;-4132.997403909323;0.08133333333333333;91.5
205;-4376.76735654324;0.088;93.26666666666667
210;-4397.299101988635;0.15466666666666667;91.56666666666666
215;-4616.266909738595;0.10333333333333333;90.86666666666666
220;-4136.735181618822;0.068;92.30000000000001
225;-4431.854315446729;0.11333333333333333;92.66666666666666
230;-4548.380162882988;0.198;90.8
235;-4382.119709832249;0.09666666666666666;92.76666666666667
240;-4391.717448992102;0.074;93.43333333333334
245;-4675.225069386326;0.08666666666666667;88.96666666666667
250;-4094.5980920737447;0.11066666666666666;90.26666666666667
255;-1334.3901334281422;0.106;62.1
260;-4340.506886820069;0.20266666666666666;90.9
265;-4032.142916808376;0.13733333333333334;87.53333333333333
270;-1380.253538298381;0.11733333333333333;63.3
275;-4408.101774038476;0.15533333333333332;91.86666666666666
280;-4436.315501862494;0.2733333333333333;86.83333333333333
285;-4197.417344702222;0.12533333333333332;91.03333333333333
290;-3463.4483476701457;1.344;62.8
295;-4199.700053844577;0.11333333333333333;88.06666666666668
300;-4706.470894995037;0.172;90.43333333333334
