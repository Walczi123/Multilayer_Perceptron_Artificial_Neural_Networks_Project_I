Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4058.719092263432;0.30266666666666664;87.13333333333333
10;-4040.7379204190083;0.27266666666666667;87.9
15;-4052.901873162253;0.25666666666666665;87.9
20;-4121.442131987418;0.3446666666666667;86.63333333333333
25;-4265.004895113598;0.39666666666666667;85.23333333333333
30;-4093.7162467650205;0.3293333333333333;86.86666666666667
35;-4111.232552797275;0.258;88.33333333333333
40;-4028.7230306929255;0.20066666666666666;89.16666666666667
45;-4051.644824337794;0.2853333333333333;87.5
50;-4082.8635475797482;0.28933333333333333;87.63333333333333
55;-4107.606291742976;0.32133333333333336;87.13333333333333
60;-4090.2776134789774;0.31133333333333335;86.76666666666667
65;-4130.520800601589;0.312;87.33333333333333
70;-4115.088113559097;0.30866666666666664;87.4
75;-4132.090545032883;0.30666666666666664;87.43333333333332
80;-4144.600562146841;0.188;89.8
85;-4086.8118778261774;0.30666666666666664;87.33333333333333
90;-4176.139265781885;0.31066666666666665;87.63333333333333
95;-4088.891319217857;0.30933333333333335;87.33333333333333
100;-4112.02993179678;0.2673333333333333;88.2
105;-4049.9458344698405;0.2633333333333333;88.2
110;-3960.924875723843;0.3913333333333333;85.0
115;-4032.352398935397;0.306;86.96666666666667
120;-4049.8374250028137;0.324;86.76666666666667
125;-4120.110042459812;0.31266666666666665;87.16666666666667
130;-4097.922049495638;0.202;89.4
135;-4191.481272138812;0.3;87.73333333333333
140;-4204.807415422868;0.31733333333333336;87.23333333333333
145;-4155.331300681709;0.306;87.46666666666667
150;-4080.1149542360918;0.106;91.3
155;-4094.8169477860624;0.2906666666666667;87.66666666666667
160;-4127.088433712669;0.186;89.66666666666666
165;-4148.141338502788;0.24733333333333332;88.66666666666667
170;-3957.8531427781477;0.3626666666666667;85.43333333333332
175;-4216.606556624806;0.28;88.13333333333333
180;-4241.861086547461;0.29;88.26666666666667
185;-4176.940822379472;0.246;88.8
190;-4151.724857207912;0.24933333333333332;88.76666666666667
195;-4135.277972231861;0.372;85.93333333333332
200;-4058.3428183377882;0.256;88.06666666666668
205;-4105.893750691644;0.30733333333333335;87.36666666666667
210;-4139.837124119447;0.23333333333333334;88.63333333333333
215;-4144.843413037743;0.288;87.63333333333333
220;-4013.390397921295;0.278;87.6
225;-4176.508254921275;0.2633333333333333;88.36666666666667
230;-4125.104868993771;0.336;86.7
235;-4239.661773304417;0.328;87.0
240;-4123.629982846125;0.2813333333333333;88.06666666666668
245;-4178.347952610226;0.3413333333333333;86.73333333333333
250;-4183.084288270864;0.308;87.56666666666668
255;-4040.2688770087575;0.24066666666666667;88.26666666666667
260;-4084.406189644285;0.294;87.5
265;-4030.850410420995;0.2733333333333333;87.9
270;-4078.641086477579;0.256;88.23333333333333
275;-4114.462722345428;0.26466666666666666;88.26666666666667
280;-4096.359589850599;0.30266666666666664;87.43333333333332
285;-4099.574119416334;0.35533333333333333;86.16666666666667
290;-4114.734764402128;0.31066666666666665;87.43333333333332
295;-4144.856964221122;0.278;88.0
300;-4056.3947111818097;0.242;88.16666666666667
