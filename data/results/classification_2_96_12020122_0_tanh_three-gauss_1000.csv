Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 64, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4057.3526155828135;0.196;89.3
10;-4064.9157444992043;0.14266666666666666;90.26666666666667
15;-4120.326861393865;0.24733333333333332;88.33333333333333
20;-4225.961444893758;0.20933333333333334;89.73333333333333
25;-4335.648590509026;0.29;88.26666666666667
30;-4144.013735684267;0.16;90.63333333333333
35;-4172.371278517456;0.13666666666666666;91.23333333333333
40;-4079.0549067651846;0.13333333333333333;90.60000000000001
45;-4062.9019702253754;0.12733333333333333;90.86666666666666
50;-4139.725607464247;0.16066666666666668;90.06666666666666
55;-4357.346704093315;0.2806666666666667;88.83333333333333
60;-4143.384166872517;0.2;88.6
65;-4110.74267341739;0.13466666666666666;91.03333333333333
70;-4139.503592542979;0.14933333333333335;90.66666666666666
75;-4234.738880285433;0.18066666666666667;91.0
80;-4284.157683104904;0.22066666666666668;89.23333333333333
85;-4087.6718167553595;0.13533333333333333;90.7
90;-4147.296021166893;0.16266666666666665;90.4
95;-4143.701040077433;0.14333333333333334;91.26666666666667
100;-4176.591650820585;0.16666666666666666;90.76666666666667
105;-4124.632718395345;0.136;91.3
110;-4056.541685399931;0.18933333333333333;89.56666666666668
115;-4121.144057973871;0.09733333333333333;91.33333333333333
120;-4120.616632232024;0.14466666666666667;90.76666666666667
125;-4160.13956985732;0.16533333333333333;90.73333333333333
130;-4016.309960661656;0.272;87.6
135;-4340.921725496807;0.25466666666666665;88.5
140;-4219.528208164208;0.226;89.16666666666667
145;-3972.6896297727694;0.2713333333333333;86.96666666666667
150;-4044.1077793990275;0.17733333333333334;89.56666666666668
155;-4127.926466262309;0.172;90.2
160;-4194.864682302209;0.21;89.5
165;-4102.320675981726;0.13066666666666665;90.53333333333333
170;-3999.2647868386935;0.31533333333333335;86.73333333333333
175;-4183.226066501769;0.16;90.33333333333333
180;-4425.000992032449;0.33466666666666667;86.3
185;-4108.506884222294;0.132;91.0
190;-4110.860456469713;0.17333333333333334;90.2
195;-4092.7958887259783;0.18066666666666667;89.46666666666667
200;-4156.96569384172;0.17933333333333334;89.76666666666667
205;-4092.523846669279;0.13933333333333334;90.56666666666666
210;-4145.1623750417;0.18333333333333332;89.83333333333333
215;-4151.35276088035;0.15333333333333332;90.83333333333333
220;-4053.055113777497;0.12733333333333333;90.63333333333333
225;-4153.56144770869;0.156;90.73333333333333
230;-4117.4906945528155;0.15133333333333332;90.23333333333333
235;-4367.226929305073;0.2713333333333333;88.0
240;-4072.6331324199714;0.11666666666666667;91.13333333333333
245;-4158.859596264187;0.144;91.03333333333333
250;-4154.057593485698;0.168;90.56666666666666
255;-4104.370926207608;0.20933333333333334;88.9
260;-4114.20840907019;0.13866666666666666;90.76666666666667
265;-4072.7238131055374;0.15666666666666668;90.33333333333333
270;-4082.5977719201724;0.15933333333333333;90.33333333333333
275;-4167.071041162919;0.15533333333333332;90.9
280;-4131.013839190424;0.162;90.4
285;-4286.394490689135;0.2853333333333333;87.83333333333333
290;-4131.550638517567;0.15133333333333332;91.0
295;-4085.293230940224;0.114;91.3
300;-4301.534299705294;0.31333333333333335;87.06666666666666
