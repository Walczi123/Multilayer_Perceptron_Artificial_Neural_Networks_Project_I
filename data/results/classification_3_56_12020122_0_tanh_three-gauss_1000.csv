Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 32, 16, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4105.573770298554;0.19;89.66666666666666
10;-3996.239973840256;0.15;89.5
15;-4260.90128747366;0.30933333333333335;87.16666666666667
20;-4182.78932144549;0.194;90.06666666666666
25;-4314.707202374107;0.338;86.76666666666667
30;-4147.296021166893;0.16933333333333334;90.60000000000001
35;-4139.924697616841;0.13;91.03333333333333
40;-4065.3504007564434;0.10866666666666666;90.96666666666667
45;-4022.4888841159673;0.14;90.2
50;-4169.150482554599;0.23466666666666666;87.6
55;-4194.466501997023;0.26466666666666666;88.1
60;-4100.928115323483;0.25066666666666665;86.56666666666666
65;-4016.6674874167074;0.154;89.96666666666667
70;-4085.449578743641;0.12933333333333333;91.03333333333333
75;-4098.513053556295;0.16466666666666666;90.5
80;-4282.207487149886;0.2886666666666667;87.6
85;-4056.1633226752456;0.17333333333333334;90.0
90;-4110.8062517362;0.16933333333333334;90.23333333333333
95;-4050.3325523906888;0.148;90.33333333333333
100;-4198.602460011708;0.186;90.5
105;-4113.841508729843;0.15933333333333333;90.73333333333333
110;-4006.542322515007;0.18933333333333333;89.33333333333333
115;-4129.160590318093;0.11133333333333334;91.43333333333334
120;-4119.488828844225;0.19733333333333333;89.73333333333333
125;-4129.586891379169;0.17933333333333334;90.23333333333333
130;-3962.126701425657;0.254;87.46666666666667
135;-4347.173600855224;0.256;88.23333333333333
140;-4175.448207450367;0.31333333333333335;86.76666666666667
145;-4047.7642500082566;0.21533333333333332;88.23333333333333
150;-4129.355502872604;0.18733333333333332;89.60000000000001
155;-4148.181992052924;0.23133333333333334;89.2
160;-4159.346368455897;0.17333333333333334;90.03333333333333
165;-4117.961826762108;0.14533333333333334;90.56666666666666
170;-4039.761268847412;0.21866666666666668;88.86666666666667
175;-4158.471859954205;0.108;91.06666666666666
180;-4366.44829747616;0.33666666666666667;85.56666666666666
185;-4078.66090405808;0.134;90.83333333333333
190;-4113.250504669186;0.21133333333333335;89.43333333333334
195;-4142.231349917003;0.21866666666666668;89.2
200;-4084.28738820283;0.12466666666666666;90.76666666666667
205;-4098.435924054106;0.13533333333333333;90.83333333333333
210;-4128.329842554709;0.19133333333333333;89.4
215;-4131.654870386512;0.16733333333333333;90.5
220;-4047.5099367330176;0.11733333333333333;90.76666666666667
225;-4164.298452640679;0.16866666666666666;90.43333333333334
230;-4082.96467226052;0.12133333333333333;91.0
235;-4417.706797984585;0.32666666666666666;86.76666666666667
240;-4070.8799378185035;0.12933333333333333;90.76666666666667
245;-4317.053489835271;0.244;89.73333333333333
250;-4138.7948054299995;0.16466666666666666;90.53333333333333
255;-3999.318991572207;0.25666666666666665;86.86666666666667
260;-4111.537963617854;0.182;89.96666666666667
265;-3985.3445323058077;0.154;89.63333333333333
270;-4081.834780073679;0.22533333333333333;88.96666666666667
275;-4161.172514961471;0.156;90.8
280;-4112.615739870221;0.11666666666666667;91.26666666666667
285;-4260.041348544479;0.2733333333333333;88.23333333333333
290;-4112.744985306882;0.14533333333333334;90.76666666666667
295;-4108.336985235498;0.12666666666666668;91.10000000000001
300;-4291.594673772809;0.276;87.73333333333333
