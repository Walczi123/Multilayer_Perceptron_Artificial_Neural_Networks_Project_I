Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 4, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4346.68581027438;0.09;93.16666666666666
10;-4275.629365001255;0.09;92.83333333333333
15;-4458.6942297830965;0.094;92.86666666666666
20;-4404.767372621377;0.09866666666666667;93.23333333333333
25;-4423.561563447725;0.09733333333333333;93.13333333333334
30;-4511.65900494573;0.13;92.30000000000001
35;-4409.569375399866;0.07733333333333334;93.43333333333334
40;-4220.51739253005;0.08866666666666667;92.33333333333333
45;-4336.995301629919;0.076;93.4
50;-4411.007785595458;0.07733333333333334;93.36666666666666
55;-4378.230780306547;0.09466666666666666;93.23333333333333
60;-4456.691917893604;0.08466666666666667;93.16666666666666
65;-4335.3192365306395;0.102;93.0
70;-4306.535392636375;0.07666666666666666;93.10000000000001
75;-4442.226508837412;0.08333333333333333;93.33333333333333
80;-4454.890784955747;0.12;92.06666666666666
85;-4437.465159609059;0.084;93.26666666666667
90;-4469.954482858851;0.09533333333333334;92.83333333333333
95;-4333.685913780537;0.08466666666666667;93.2
100;-4221.364798664987;0.10533333333333333;92.30000000000001
105;-4399.015820638049;0.07133333333333333;93.36666666666666
110;-4241.9643000272745;0.09666666666666666;92.5
115;-4426.009993978793;0.07733333333333334;93.26666666666667
120;-4245.613485850247;0.09666666666666666;92.43333333333334
125;-4267.703513342599;0.09266666666666666;92.80000000000001
130;-4342.6603505257635;0.07;93.23333333333333
135;-4434.837456505898;0.07666666666666666;93.43333333333334
140;-4442.541293243287;0.076;93.33333333333333
145;-4473.302435459327;0.1;92.76666666666667
150;-4372.975374100227;0.07466666666666667;93.46666666666667
155;-4401.265161016524;0.06866666666666667;93.33333333333333
160;-4251.172214078105;0.092;92.7
165;-4320.097102025078;0.086;93.13333333333334
170;-4275.067552106397;0.09;92.63333333333334
175;-4427.736086213504;0.07533333333333334;93.30000000000001
180;-4350.137994743802;0.09533333333333334;93.06666666666666
185;-4329.069449971263;0.08133333333333333;93.23333333333333
190;-4279.056535902961;0.09066666666666667;92.63333333333334
195;-4369.586767949615;0.08466666666666667;93.23333333333333
200;-4356.142841613236;0.07533333333333334;93.43333333333334
205;-4394.320138527546;0.07133333333333333;93.43333333333334
210;-4346.693095060636;0.17266666666666666;91.63333333333334
215;-4262.4345559529;0.08533333333333333;92.7
220;-4248.6487428438895;0.088;92.73333333333333
225;-4365.310102113933;0.08333333333333333;93.30000000000001
230;-4366.997629597548;0.08066666666666666;93.33333333333333
235;-4363.53189394475;0.078;93.4
240;-4403.815734617497;0.07066666666666667;93.36666666666666
245;-4486.877696031408;0.098;92.53333333333333
250;-4325.119030925793;0.08933333333333333;93.03333333333333
255;-4401.396495252226;0.07533333333333334;93.26666666666667
260;-4418.6073904639015;0.07;93.33333333333333
265;-4427.722535030125;0.07666666666666666;93.36666666666666
270;-4477.9595528187365;0.09866666666666667;92.5
275;-4259.916280705899;0.174;91.23333333333333
280;-4279.8539149024655;0.092;92.7
285;-4444.0047170065955;0.08333333333333333;93.16666666666666
290;-4397.67746471332;0.12066666666666667;92.7
295;-4272.256398833063;0.08;92.9
300;-4361.216886448424;0.07933333333333334;93.4
