Train dataset: data/regression/data.activation.train.1000.csv
Test dataset: data/regression/data.activation.test.1000.csv
Layers: [1, 128, 64, 32, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.00024628607807351024;0.031835761825664805
10;0.0001026242142521143;0.026523739362523432
15;0.00010895425645582534;0.02711562236876622
20;7.492052521199153e-05;0.02606589782714279
25;6.099608586805094e-05;0.02547295091632197
30;7.483870330367355e-05;0.027142728192368723
35;4.3439922928301365e-05;0.024007895261012612
40;4.442039848372477e-05;0.024706859015342614
45;4.7297119334883526e-05;0.02527076411326747
50;4.2766467242738976e-05;0.024898295689034074
55;4.4186776861588405e-05;0.02523052649332068
60;4.424786111520067e-05;0.025396414217614332
65;4.4185735285750856e-05;0.025498502210582256
70;4.1903349879520235e-05;0.025229768911714166
75;3.98948991228554e-05;0.024946819551970614
80;4.18036096319322e-05;0.02532439907391404
85;4.245901187914415e-05;0.025408976904662057
90;4.1336965208036555e-05;0.02541546795660766
95;3.930463869633886e-05;0.025049446870669456
100;4.288937375289753e-05;0.02572086330200994
105;4.043508827084427e-05;0.025318200519989852
110;4.350457147919085e-05;0.02583584043520911
115;3.868979197850532e-05;0.025146105586615543
120;4.36847699680364e-05;0.025950422886798035
125;3.6726100384937444e-05;0.024779148990919462
130;3.873514185008533e-05;0.025178900615304124
135;3.80972318536826e-05;0.02510157189463928
140;3.5155480768129075e-05;0.024544755087768256
145;3.889227229644352e-05;0.02527956403683782
150;4.062609197287112e-05;0.02558396781145245
155;3.631085895770776e-05;0.024847566810086204
160;3.739921965376958e-05;0.02510075608082281
165;3.93418368158546e-05;0.02547925467908872
170;3.742950216401154e-05;0.02510982456394099
175;3.3648870225209974e-05;0.02441089583102383
180;3.494680019315094e-05;0.02465593931779567
185;3.768316198964718e-05;0.025240225911171556
190;3.4495832666713216e-05;0.024627598748108607
195;3.270245023075815e-05;0.024270353719131964
200;3.393770666705232e-05;0.02453008405537581
205;3.4950821164980403e-05;0.024785799654493828
210;3.182076704238183e-05;0.024139928788305093
215;3.344625735847403e-05;0.02449468478843456
220;3.32499655814334e-05;0.024493293470557405
225;3.322466736057468e-05;0.02449455109187639
230;3.479724276144901e-05;0.02477045009414734
235;3.220786103068165e-05;0.02429470486324536
240;3.280270428989436e-05;0.024443108083547004
245;3.369758614960265e-05;0.024626093208512976
250;3.4447453182545775e-05;0.024753848527082425
255;2.9773683853608243e-05;0.023786524576246137
260;3.061287910796748e-05;0.02397782015763952
265;3.378306343532506e-05;0.024728738992724934
270;3.230351111313573e-05;0.024394666141024576
275;3.564971689752485e-05;0.025100823897919188
280;2.9891155623979156e-05;0.023850531369748303
285;3.099534225781883e-05;0.02413042631730572
290;3.140853675236886e-05;0.02422866456772047
295;3.1005636033886385e-05;0.02416372522590027
300;3.068682012302728e-05;0.024081252836874928
