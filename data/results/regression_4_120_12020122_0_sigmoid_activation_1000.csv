Train dataset: data/regression/data.activation.train.1000.csv
Test dataset: data/regression/data.activation.test.1000.csv
Layers: [1, 64, 32, 16, 8, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.0008775560117516715;inf
10;0.0007746978321677442;inf
15;0.0005500825708485575;inf
20;0.0002816902441967201;inf
25;0.0003093698082886268;inf
30;0.0003500734289554973;inf
35;0.00014394962551189213;inf
40;0.0002303931600144023;inf
45;0.00014369272301206285;inf
50;0.0001313326225323587;inf
55;0.00010299869483855955;0.0349874887844331
60;0.00014348934819138738;inf
65;0.0001309667073108731;0.02645785124487102
70;0.0001468176037542365;0.015429000956571789
75;9.521352556124812e-05;0.010912864935304791
80;0.00012551534888649842;0.012647147021513561
85;8.722660478776315e-05;0.011387449560905472
90;0.00011776479083028402;0.011262212599748394
95;7.211546264771235e-05;0.013945120432393739
100;9.741625720978865e-05;0.011288676004214848
105;7.021776666282602e-05;0.014052087165899835
110;7.34081971189096e-05;0.014811358393232787
115;7.014774874972116e-05;0.013958931713004113
120;0.00011084182248891876;0.011651571105442928
125;0.00010038543372809369;0.011926714195649911
130;7.11036438931671e-05;0.015360805907810604
135;6.617900727120952e-05;0.01575934084359016
140;6.843126913063086e-05;0.014942626158006877
145;6.820224816009846e-05;0.01305556031818388
150;7.495332773505426e-05;0.013326515709103273
155;6.29984949610408e-05;0.016276638000272233
160;7.626273818044072e-05;0.012856398620141951
165;7.247059561891874e-05;0.01341546730368877
170;6.660415681395646e-05;0.012949856370703686
175;6.795120990071126e-05;0.015480764262246156
180;7.354016220739197e-05;0.012494958440438153
185;6.37340782701143e-05;0.015388625295779735
190;5.638333653700154e-05;0.014129139026324731
195;6.683474275433867e-05;0.013073449899457787
200;5.7177578058233426e-05;0.014195056798048424
205;7.698893845214582e-05;0.012052792664482415
210;4.9447814571146486e-05;0.01384489988494743
215;5.325379974091381e-05;0.014918217596029064
220;4.857656648984265e-05;0.015169939275440577
225;5.2274494582917286e-05;0.014790135556532052
230;5.205666770563844e-05;0.015374912885783142
235;7.08797230793641e-05;0.012318512228869318
240;4.855378662726824e-05;0.013468898037492374
245;4.989959661233378e-05;0.014067647572763055
250;4.405159792390278e-05;0.014293636549656622
255;4.605190753033435e-05;0.01557522765150082
260;4.360078634647383e-05;0.01676033535365481
265;4.930761781630226e-05;0.01299434171205
270;4.6622779447392014e-05;0.013277590147656525
275;4.483268581317168e-05;0.014698806617105884
280;5.1921277364271084e-05;0.012293141063254527
285;4.8508984800124895e-05;0.012100448313808337
290;4.6228722380334924e-05;0.012614781728559316
295;3.733918121596054e-05;0.016558543462008028
300;4.555339904390904e-05;0.012647236516375655
