Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 16, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-415.45266368959483;0.18;90.33333333333333
10;-411.80347786662134;0.22;89.33333333333333
15;-420.30469360351447;0.21333333333333335;90.0
20;-412.1568270235905;0.18;90.0
25;-413.3867734812933;0.09333333333333334;92.0
30;-416.1458108201548;0.18666666666666668;90.0
35;-403.1459143263112;0.14666666666666667;90.33333333333333
40;-412.86352533752876;0.11333333333333333;91.33333333333333
45;-408.507641200617;0.22;89.0
50;-407.00356388717404;0.28;87.0
55;-409.2278906979336;0.08;92.0
60;-411.07176598496744;0.16666666666666666;90.0
65;-408.52119238399536;0.14666666666666667;90.66666666666666
70;-410.35151648765077;0.28;87.0
75;-412.6936263507333;0.08666666666666667;92.33333333333333
80;-419.1018495125683;0.14;91.33333333333333
85;-406.55953404463855;0.11333333333333333;91.0
90;-402.7790139859637;0.24666666666666667;88.0
95;-417.0224081208885;0.12666666666666668;91.33333333333333
100;-417.02240812088843;0.12666666666666668;91.33333333333333
105;-412.86352533752876;0.11333333333333333;91.33333333333333
110;-396.64492167986884;0.30666666666666664;86.0
115;-398.09688305883947;0.2866666666666667;87.0
120;-401.22282073804837;0.22666666666666666;88.66666666666667
125;-415.5318819908239;0.05333333333333334;93.0
130;-450.98661751832594;0.4;83.0
135;-426.6222360797831;0.14;90.66666666666666
140;-452.54281076624125;0.43333333333333335;82.33333333333334
145;-433.67149043770553;0.23333333333333334;88.0
150;-421.69098786463434;0.22666666666666666;89.33333333333333
155;-424.4114604524018;0.24;87.66666666666667
160;-415.9759118333594;0.16666666666666666;90.0
165;-428.70167747146286;0.17333333333333334;89.0
170;-414.8637484279796;0.2866666666666667;86.33333333333333
175;-427.0141499878462;0.28;87.33333333333333
180;-418.5786013688038;0.17333333333333334;89.66666666666666
185;-409.78970359279214;0.18666666666666668;88.33333333333333
190;-420.6580427604836;0.17333333333333334;90.66666666666666
195;-418.91839934239454;0.24;88.0
200;-413.8964704416795;0.16666666666666666;90.0
205;-423.7839804396925;0.15333333333333332;91.0
210;-414.4197185854441;0.14666666666666667;90.66666666666666
215;-401.86385193413594;0.24;87.66666666666667
220;-419.69076477418355;0.10666666666666667;91.0
225;-420.0305627477744;0.12;91.0
230;-417.0745240553608;0.18;89.66666666666666
235;-417.3622060944793;0.22666666666666666;89.0
240;-427.315383210343;0.14666666666666667;90.33333333333333
245;-416.1593620035331;0.11333333333333333;91.66666666666666
250;-411.97337685341677;0.26;87.33333333333333
255;-440.0661624161622;0.32666666666666666;86.33333333333333
260;-403.47216111652364;0.26666666666666666;87.66666666666667
265;-426.9620340533738;0.18666666666666668;89.66666666666666
270;-429.32915748417213;0.19333333333333333;90.33333333333333
275;-406.15406895319705;0.14;90.0
280;-410.9539829326443;0.12;91.33333333333333
285;-435.1099006332978;0.24;88.0
290;-412.6800751673551;0.16666666666666666;89.66666666666666
295;-411.5293470108812;0.15333333333333332;90.33333333333333
300;-422.03078583822514;0.30666666666666664;86.66666666666667
