Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-436.9808782870883;0.07333333333333333;92.33333333333333
10;-430.84678598099345;0.10666666666666667;92.66666666666666
15;-439.5700166391543;0.14666666666666667;91.66666666666666
20;-439.51790070468195;0.10666666666666667;92.0
25;-425.5371750411599;0.05333333333333334;93.33333333333333
30;-429.64394189004724;0.04666666666666667;92.66666666666666
35;-426.2303221717199;0.06;93.0
40;-420.0441139311527;0.05333333333333334;93.66666666666667
45;-437.0329942215606;0.11333333333333333;92.0
50;-437.16432845726195;0.07333333333333333;92.33333333333333
55;-433.109677542847;0.05333333333333334;93.0
60;-412.52372736393795;0.08;92.33333333333333
65;-430.44132088955195;0.11333333333333333;92.66666666666666
70;-446.0574581022183;0.11333333333333333;92.0
75;-427.5645004983674;0.05333333333333334;93.33333333333333
80;-426.45233709298765;0.10666666666666667;92.66666666666666
85;-420.0441139311527;0.05333333333333334;93.66666666666667
90;-433.6193745032332;0.12666666666666668;92.33333333333333
95;-431.0302361511672;0.04;93.0
100;-427.60306524946145;0.14666666666666667;92.0
105;-434.6658707907623;0.08666666666666667;92.33333333333333
110;-430.45487207293024;0.06;92.33333333333333
115;-438.43283966605884;0.06;92.66666666666666
120;-420.7372610617126;0.06;93.33333333333333
125;-426.7535703154844;0.04;93.66666666666667
130;-426.2303221717199;0.06;93.0
135;-428.9507947594873;0.04;93.0
140;-428.81946052378595;0.13333333333333333;92.33333333333333
145;-455.31748808752207;0.1;90.66666666666666
150;-420.0441139311527;0.05333333333333334;93.66666666666667
155;-429.7617249423703;0.05333333333333334;92.66666666666666
160;-432.9262273726733;0.12;92.66666666666666
165;-447.7449855858349;0.08666666666666667;91.0
170;-434.1561738303761;0.05333333333333334;92.66666666666666
175;-430.86033716437174;0.05333333333333334;92.33333333333333
180;-429.29059273307814;0.07333333333333333;93.33333333333333
185;-428.9507947594873;0.04;93.0
190;-434.1561738303761;0.05333333333333334;92.66666666666666
195;-433.109677542847;0.05333333333333334;93.0
200;-427.4467174460444;0.04666666666666667;93.33333333333333
205;-428.9507947594873;0.04;93.0
210;-445.5863258929261;0.12666666666666668;92.0
215;-424.0987648455677;0.04666666666666667;93.0
220;-426.7535703154844;0.04;93.66666666666667
225;-423.0522685580386;0.04666666666666667;93.33333333333333
230;-444.5533807887753;0.09333333333333334;92.66666666666666
235;-427.4467174460444;0.04666666666666667;93.33333333333333
240;-427.4467174460444;0.04666666666666667;93.33333333333333
245;-427.2111513413983;0.06;93.33333333333333
250;-434.83576977755774;0.11333333333333333;92.66666666666666
255;-443.0493034753324;0.09333333333333334;92.33333333333333
260;-427.4467174460444;0.04666666666666667;93.33333333333333
265;-431.8932822685225;0.06666666666666667;92.66666666666666
270;-434.6658707907623;0.08666666666666667;92.33333333333333
275;-459.8818359623233;0.1;90.0
280;-420.0441139311527;0.05333333333333334;93.66666666666667
285;-416.7482772651484;0.05333333333333334;93.33333333333333
290;-426.9099181189015;0.14;92.33333333333333
295;-420.0441139311527;0.05333333333333334;93.66666666666667
300;-427.5645004983674;0.05333333333333334;93.33333333333333
