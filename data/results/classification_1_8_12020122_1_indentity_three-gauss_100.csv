Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 8, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-436.5097460777961;0.13333333333333333;91.33333333333333
10;-418.238803395213;0.12666666666666668;91.66666666666666
15;-443.9644655271601;0.14666666666666667;91.66666666666666
20;-433.21390941179175;0.13333333333333333;92.33333333333333
25;-428.54532966804584;0.04666666666666667;93.0
30;-420.7372610617126;0.06;93.33333333333333
35;-434.1561738303761;0.05333333333333334;92.66666666666666
40;-422.3591214274786;0.04;93.66666666666667
45;-436.73176099906385;0.18;91.0
50;-446.88193946847963;0.08;92.0
55;-432.5864293990825;0.07333333333333333;92.33333333333333
60;-357.69734813281036;0.14666666666666667;86.33333333333333
65;-433.3838083985871;0.14;92.33333333333333
70;-445.2465279193353;0.1;92.33333333333333
75;-429.7617249423703;0.05333333333333334;92.66666666666666
80;-428.81946052378595;0.13333333333333333;92.33333333333333
85;-420.0441139311527;0.05333333333333334;93.66666666666667
90;-392.21190804076906;0.17333333333333334;88.0
95;-425.5371750411599;0.05333333333333334;93.33333333333333
100;-401.01226820111793;0.4533333333333333;83.66666666666667
105;-435.8822660650868;0.07333333333333333;92.66666666666666
110;-443.75600178927067;0.08;91.0
115;-444.73683095894904;0.07333333333333333;92.0
120;-397.43083829503615;0.08666666666666667;91.0
125;-419.75643189203424;0.04666666666666667;93.0
130;-422.7510353355418;0.11333333333333333;92.33333333333333
135;-434.1561738303761;0.05333333333333334;92.66666666666666
140;-438.4714044171528;0.14666666666666667;92.0
145;-459.30647188408636;0.10666666666666667;90.66666666666666
150;-420.0441139311527;0.05333333333333334;93.66666666666667
155;-438.9560878098233;0.08666666666666667;92.33333333333333
160;-424.3728957013078;0.09333333333333334;92.66666666666666
165;-460.64065021073384;0.1;89.66666666666666
170;-452.1394344738407;0.08666666666666667;89.66666666666666
175;-434.1561738303761;0.05333333333333334;92.66666666666666
180;-418.3044705130636;0.07333333333333333;92.66666666666666
185;-456.939348453288;0.08;89.66666666666666
190;-445.8354431809505;0.07333333333333333;91.66666666666666
195;-423.1565004269833;0.10666666666666667;92.33333333333333
200;-419.75643189203424;0.04666666666666667;93.0
205;-434.731537908613;0.03333333333333333;93.33333333333333
210;-440.1974966518636;0.20666666666666667;90.33333333333333
215;-380.79530716159735;0.04;90.0
220;-428.6631127203689;0.05333333333333334;93.0
225;-407.5539143976953;0.06;92.0
230;-460.103850883591;0.12;89.66666666666666
235;-419.75643189203424;0.04666666666666667;93.0
240;-434.2082897648485;0.05333333333333334;92.66666666666666
245;-432.5864293990825;0.07333333333333333;92.33333333333333
250;-424.3072285834571;0.14666666666666667;91.66666666666666
255;-436.84954405138683;0.16666666666666666;91.66666666666666
260;-442.4739393970955;0.07333333333333333;92.0
265;-436.9808782870883;0.07333333333333333;92.33333333333333
270;-441.83290820100785;0.10666666666666667;92.0
275;-484.2868709510012;0.12;87.0
280;-404.71565875760484;0.09333333333333334;91.33333333333333
285;-405.2389069013693;0.07333333333333333;92.0
290;-403.82551027349274;0.22666666666666666;88.33333333333333
295;-383.214546526868;0.06666666666666667;90.0
300;-415.19208401723307;0.05333333333333334;93.0
