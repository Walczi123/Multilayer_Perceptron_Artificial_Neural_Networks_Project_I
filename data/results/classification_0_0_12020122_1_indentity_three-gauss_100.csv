Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-437.4384593130021;0.10666666666666667;92.0
10;-427.7729642362568;0.15333333333333332;92.0
15;-441.41389192618806;0.19333333333333333;90.66666666666666
20;-439.5700166391543;0.14666666666666667;91.66666666666666
25;-421.1427261531542;0.05333333333333334;93.33333333333333
30;-426.2303221717199;0.06;93.0
35;-422.3591214274786;0.04;93.66666666666667
40;-420.7372610617126;0.06;93.33333333333333
45;-436.84954405138683;0.16666666666666666;91.66666666666666
50;-444.5669319721536;0.09333333333333334;92.0
55;-429.29059273307814;0.07333333333333333;93.33333333333333
60;-394.1350016290318;0.08666666666666667;90.66666666666666
65;-427.60306524946145;0.14666666666666667;92.0
70;-447.15607032421974;0.11333333333333333;91.66666666666666
75;-426.46588827636594;0.05333333333333334;93.66666666666667
80;-427.60306524946145;0.14666666666666667;92.0
85;-413.45244059914404;0.05333333333333334;93.0
90;-424.3072285834571;0.14666666666666667;91.66666666666666
95;-429.29059273307814;0.07333333333333333;93.33333333333333
100;-420.6444915771052;0.26;89.0
105;-433.16179347731935;0.09333333333333334;92.66666666666666
110;-429.7617249423703;0.05333333333333334;92.66666666666666
115;-433.7507087389346;0.06;92.66666666666666
120;-411.830580233378;0.07333333333333333;92.66666666666666
125;-421.8358732837141;0.06;93.0
130;-425.7591899624277;0.1;93.0
135;-429.7617249423703;0.05333333333333334;92.66666666666666
140;-436.84954405138683;0.16666666666666666;91.66666666666666
145;-462.7200916024138;0.11333333333333333;91.0
150;-416.7482772651484;0.05333333333333334;93.33333333333333
155;-430.45487207293024;0.06;92.33333333333333
160;-430.84678598099345;0.10666666666666667;92.66666666666666
165;-457.3448135447295;0.1;90.66666666666666
170;-436.35339827437895;0.06;92.66666666666666
175;-429.7617249423703;0.05333333333333334;92.66666666666666
180;-423.27428347930635;0.09333333333333334;93.0
185;-429.7617249423703;0.05333333333333334;92.66666666666666
190;-438.43283966605884;0.06;92.66666666666666
195;-430.9645690333165;0.09333333333333334;93.33333333333333
200;-420.0441139311527;0.05333333333333334;93.66666666666667
205;-428.9507947594873;0.04;93.0
210;-441.36177599171566;0.15333333333333332;91.0
215;-412.9427436387578;0.03333333333333333;93.0
220;-422.3591214274786;0.04;93.66666666666667
225;-418.13457152626825;0.06666666666666667;92.66666666666666
230;-449.11772866357654;0.12;91.66666666666666
235;-426.3481052240429;0.04666666666666667;93.66666666666667
240;-427.4467174460444;0.04666666666666667;93.33333333333333
245;-429.9837398636381;0.08;93.0
250;-432.1152971897903;0.13333333333333333;92.66666666666666
255;-444.4877136709246;0.12666666666666668;92.33333333333333
260;-431.7754992161995;0.08;93.33333333333333
265;-430.38920495507955;0.07333333333333333;93.0
270;-437.0329942215606;0.11333333333333333;92.0
275;-474.51714400531125;0.10666666666666667;89.33333333333333
280;-419.5208657873882;0.07333333333333333;93.0
285;-409.0579917111382;0.05333333333333334;93.0
290;-421.69098786463434;0.22;90.33333333333333
295;-401.08002411800965;0.06;92.0
300;-423.1700516103616;0.05333333333333334;93.33333333333333
