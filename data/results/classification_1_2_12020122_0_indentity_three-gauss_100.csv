Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-408.83388799082945;0.35333333333333333;86.33333333333333
10;-416.9953057541318;0.3;88.0
15;-422.2006848250206;0.29333333333333333;88.33333333333333
20;-413.69946908812744;0.3;87.66666666666667
25;-419.9513444465453;0.25333333333333335;89.33333333333333
30;-416.9953057541318;0.3;88.0
35;-418.7349491722208;0.26666666666666666;89.0
40;-415.4391125062165;0.26666666666666666;88.66666666666667
45;-416.9953057541318;0.3;88.0
50;-415.4391125062165;0.26666666666666666;88.66666666666667
55;-418.7349491722208;0.26666666666666666;89.0
60;-415.4391125062165;0.26666666666666666;88.66666666666667
65;-414.22271723189203;0.28;88.33333333333333
70;-421.67743668125604;0.31333333333333335;87.66666666666667
75;-410.7569815790922;0.25333333333333335;89.0
80;-424.45002520349584;0.3333333333333333;87.33333333333333
85;-413.8829192583012;0.23333333333333334;89.33333333333333
90;-419.24464613260704;0.34;87.0
95;-416.3021586235718;0.29333333333333333;88.33333333333333
100;-419.4280963027808;0.2733333333333333;88.66666666666667
105;-412.483073813803;0.31333333333333335;87.33333333333333
110;-413.8829192583012;0.23333333333333334;89.33333333333333
115;-410.050283265154;0.34;86.66666666666667
120;-413.1897721277412;0.22666666666666666;89.66666666666666
125;-416.13225963677644;0.2733333333333333;88.33333333333333
130;-419.24464613260704;0.34;87.0
135;-415.09931453262567;0.22;89.66666666666666
140;-418.90484815901624;0.29333333333333333;88.0
145;-411.26667853947845;0.32666666666666666;87.0
150;-413.1897721277412;0.22666666666666666;89.66666666666666
155;-416.13225963677644;0.2733333333333333;88.33333333333333
160;-418.7349491722208;0.26666666666666666;89.0
165;-414.915864362452;0.2866666666666667;88.0
170;-412.483073813803;0.31333333333333335;87.33333333333333
175;-412.66652398397673;0.24666666666666667;89.0
180;-416.9953057541318;0.3;88.0
185;-414.22271723189203;0.28;88.33333333333333
190;-408.15429204364784;0.26;88.33333333333333
195;-413.69946908812744;0.3;87.66666666666667
200;-415.4391125062165;0.26666666666666666;88.66666666666667
205;-409.54058630476777;0.26666666666666666;88.66666666666667
210;-421.3240875242869;0.35333333333333333;87.0
215;-409.8939354617369;0.22666666666666666;89.33333333333333
220;-414.57606638886114;0.24;89.0
225;-417.3486549111009;0.26;88.66666666666667
230;-413.69946908812744;0.3;87.66666666666667
235;-416.13225963677644;0.2733333333333333;88.33333333333333
240;-417.87190305486547;0.24;89.33333333333333
245;-409.7240364749415;0.22;89.33333333333333
250;-421.67743668125604;0.31333333333333335;87.66666666666667
255;-424.45002520349584;0.3333333333333333;87.33333333333333
260;-418.7349491722208;0.26666666666666666;89.0
265;-412.14327584021214;0.26666666666666666;88.33333333333333
270;-416.13225963677644;0.2733333333333333;88.33333333333333
275;-418.7349491722208;0.26666666666666666;89.0
280;-409.7240364749415;0.22;89.33333333333333
285;-416.655507780541;0.25333333333333335;89.0
290;-413.69946908812744;0.3;87.66666666666667
295;-416.3021586235718;0.29333333333333333;88.33333333333333
300;-411.78992668324304;0.30666666666666664;87.66666666666667
