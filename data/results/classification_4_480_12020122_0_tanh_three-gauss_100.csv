Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 256, 128, 64, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-408.0114954236092;0.09333333333333334;91.66666666666666
10;-418.06890440841755;0.1;92.66666666666666
15;-414.48538570329475;0.09333333333333334;91.66666666666666
20;-414.7730677424132;0.1;92.33333333333333
25;-424.83047672722165;0.11333333333333333;92.33333333333333
30;-416.5648270949746;0.10666666666666667;91.66666666666666
35;-411.3073320896135;0.07333333333333333;93.0
40;-418.5786013688038;0.16;90.66666666666666
45;-414.22271723189203;0.28;88.33333333333333
50;-414.5239504543888;0.24;88.0
55;-407.3183482930492;0.07333333333333333;92.0
60;-410.4307347888798;0.13333333333333333;90.33333333333333
65;-359.87893259439386;0.5933333333333334;79.0
70;-403.66916247007566;0.12666666666666668;91.0
75;-402.2828682089558;0.10666666666666667;90.66666666666666
80;-409.7375876583198;0.13333333333333333;91.0
85;-401.10503768572534;0.24;88.0
90;-398.0968830588394;0.24666666666666667;86.33333333333333
95;-407.48824727984453;0.1;91.0
100;-400.72667496104054;0.07333333333333333;91.33333333333333
105;-406.2718520055201;0.11333333333333333;90.66666666666666
110;-366.5612866119689;0.7733333333333333;75.33333333333333
115;-391.5437744779248;0.3933333333333333;83.66666666666667
120;-379.68105495717657;0.41333333333333333;83.33333333333334
125;-395.9382233659305;0.37333333333333335;84.66666666666667
130;-432.15386194088427;0.26666666666666666;86.33333333333333
135;-412.3131748270076;0.29333333333333333;87.33333333333333
140;-439.37301528560226;0.32;86.66666666666667
145;-426.2167709883415;0.18;89.33333333333333
150;-417.53210508127466;0.19333333333333333;90.33333333333333
155;-416.1187084533981;0.38666666666666666;84.66666666666667
160;-404.92412249549415;0.24;88.33333333333333
165;-420.2004617345698;0.16;90.33333333333333
170;-418.7620515389775;0.12666666666666668;91.66666666666666
175;-410.4964019067305;0.11333333333333333;90.33333333333333
180;-401.7460688818129;0.20666666666666667;89.33333333333333
185;-380.19075191756275;0.5266666666666666;81.66666666666667
190;-416.4991599771239;0.18666666666666668;87.66666666666667
195;-404.2309753649342;0.25333333333333335;87.66666666666667
200;-396.8804877845149;0.26;88.0
205;-420.2525776690421;0.20666666666666667;87.66666666666667
210;-395.1387555673849;0.6933333333333334;76.33333333333333
215;-378.19052882711196;0.38666666666666666;84.0
220;-426.9755852367522;0.1;91.66666666666666
225;-425.7591899624277;0.12;91.0
230;-431.329380574623;0.38;82.33333333333334
235;-428.76734458931355;0.18666666666666668;88.33333333333333
240;-406.0091835341173;0.34;84.33333333333334
245;-396.06955760163197;0.26;86.66666666666667
250;-403.91619095905907;0.4;84.66666666666667
255;-410.7434303957139;0.35333333333333333;84.0
260;-357.9172742550371;0.5666666666666667;78.33333333333333
265;-413.79223857273485;0.12666666666666668;90.0
270;-431.7098320983488;0.12;92.33333333333333
275;-427.41961507928767;0.2;90.33333333333333
280;-408.05006017470316;0.2;89.33333333333333
285;-426.8692645687664;0.41333333333333333;85.33333333333334
290;-387.8289215371006;0.46;82.0
295;-421.8587980523888;0.7466666666666667;70.0
300;-408.6910913707907;0.18666666666666668;90.0
