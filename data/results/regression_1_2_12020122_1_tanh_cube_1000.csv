Train dataset: data/regression/data.cube.train.1000.csv
Test dataset: data/regression/data.cube.test.1000.csv
Layers: [1, 2, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.04087681599728105;inf
10;0.03208380213436482;inf
15;0.022511223406754544;inf
20;0.017510555941282528;inf
25;0.013872126915323905;inf
30;0.014585830880114867;inf
35;0.014565963654581788;inf
40;0.019419842004777674;inf
45;0.022024008420088646;inf
50;0.0258345110798885;0.4492759567112958
55;0.03215745491112741;0.28838012546927255
60;0.03618385583516319;0.2271969750589521
65;0.043061036272268836;0.19371486655858677
70;0.049399349447701704;0.17143948716408858
75;0.05283753857113354;0.15779747163186209
80;0.06116568553062617;0.14724946780560585
85;0.06536198590840935;0.1400074579470516
90;0.07360882175369919;0.1334859062424045
95;0.07726675815450733;0.12855555892778578
100;0.08113343650184593;0.12368375530258831
105;0.08879078134906365;0.12072620024611251
110;0.0928824680711429;0.11680313131026675
115;0.10121302208235963;0.11474220051452402
120;0.10584208153139289;0.11189826703586786
125;0.10732361203041882;0.10815360706590371
130;0.1112065028336734;0.10576434121067053
135;0.11586408067421887;0.10343283911843298
140;0.1216995076794275;0.1022346867898004
145;0.1272916461516962;0.10081619793728436
150;0.1307619865566447;0.09865598530101943
155;0.13701800985063234;0.0975377469420107
160;0.1413080669450574;0.09589893812427316
165;0.14185029770573387;0.09291898695511872
170;0.14784748310077392;0.09193811794636741
175;0.15434338992685875;0.0913610139581987
180;0.15541707112928263;0.08872330255612737
185;0.15977017639291824;0.08743471956843163
190;0.1633475184688207;0.08580785488632241
195;0.1667384505603586;0.08422030599432581
200;0.16808567887148831;0.08158134561342263
205;0.17306215345007828;0.08068531132733607
210;0.18029972037050196;0.0805341982002728
215;0.18126455277579043;0.07833776988689305
220;0.18383832253048885;0.07677747529491036
225;0.18874946588274416;0.07588433163295383
230;0.19153002290477905;0.07434738946566898
235;0.1963870123037951;0.07383961738554319
240;0.19747857591668352;0.0719756754779313
245;0.20540853529217398;0.07221625788221317
250;0.20564206747304103;0.0703386247960979
255;0.20533474544008795;0.06836416980899618
260;0.21235768452599965;0.06850219737976045
265;0.21450856989421077;0.06717761171160172
270;0.2203185883388319;0.0669186595420527
275;0.2199714371155843;0.06505565270025741
280;0.22559764306904445;0.06481540504828141
285;0.22443920260038905;0.06277785077128895
290;0.2292714667066301;0.06236072806078982
295;0.23217168796635182;0.061504735524392944
300;0.2331548285460102;0.06014606853911699
