Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-421.50753769446067;0.2866666666666667;88.66666666666667
10;-413.0063219575675;0.29333333333333333;88.0
15;-417.3486549111009;0.26;88.66666666666667
20;-414.05281824509655;0.26;88.33333333333333
25;-418.91839934239454;0.20666666666666667;89.66666666666666
30;-422.3841349951943;0.23333333333333334;89.0
35;-416.1458108201548;0.18666666666666668;90.0
40;-422.3841349951943;0.23333333333333334;89.0
45;-408.8474391742078;0.26666666666666666;88.0
50;-408.4034093316723;0.18;89.33333333333333
55;-414.9294155458303;0.2;89.66666666666666
60;-419.5073146040098;0.13333333333333333;91.33333333333333
65;-408.8474391742078;0.26666666666666666;88.0
70;-428.8715764582583;0.16;90.66666666666666
75;-412.05259515464576;0.12;91.0
80;-432.78134195359354;0.30666666666666664;88.0
85;-412.51017618055965;0.15333333333333332;90.66666666666666
90;-428.62245917023387;0.2733333333333333;89.0
95;-417.7020040680701;0.22;89.33333333333333
100;-418.5786013688038;0.16;90.66666666666666
105;-419.6115464729545;0.21333333333333335;89.33333333333333
110;-409.7240364749415;0.22;89.33333333333333
115;-422.1756712573049;0.09333333333333334;92.0
120;-409.7240364749415;0.22;89.33333333333333
125;-423.6661973873695;0.16666666666666666;90.33333333333333
130;-436.2470776063933;0.3333333333333333;87.33333333333333
135;-417.7812223692991;0.09333333333333334;92.0
140;-433.1346911105627;0.26666666666666666;88.66666666666667
145;-429.8795079946934;0.14666666666666667;90.0
150;-417.71555525144845;0.14666666666666667;91.0
155;-422.1756712573049;0.09333333333333334;92.0
160;-421.1677397208698;0.24666666666666667;88.66666666666667
165;-421.8223221003358;0.12;91.33333333333333
170;-430.4934368240243;0.14;91.0
175;-416.6304942128253;0.05333333333333334;92.66666666666666
180;-417.7020040680701;0.22;89.33333333333333
185;-408.40340933167226;0.16;90.0
190;-417.71555525144845;0.14666666666666667;91.0
195;-418.5786013688038;0.16;90.66666666666666
200;-412.84997415415046;0.2;89.66666666666666
205;-413.7130202715058;0.21333333333333335;89.33333333333333
210;-419.9513444465453;0.26;88.33333333333333
215;-412.92919245537945;0.06;92.33333333333333
220;-420.55381089153894;0.11333333333333333;91.66666666666666
225;-426.79213506657845;0.14666666666666667;90.66666666666666
230;-383.6700387537409;0.43333333333333335;83.33333333333334
235;-418.9976176436236;0.08;92.33333333333333
240;-422.5675851653681;0.16666666666666666;90.66666666666666
245;-406.24474963876344;0.2866666666666667;87.33333333333333
250;-421.1677397208698;0.24666666666666667;88.66666666666667
255;-421.1677397208698;0.24666666666666667;88.66666666666667
260;-420.99784073407443;0.22;89.66666666666666
265;-417.7020040680701;0.22;89.33333333333333
270;-421.1677397208698;0.24666666666666667;88.66666666666667
275;-417.8854542382438;0.15333333333333332;91.0
280;-413.7922385727348;0.08666666666666667;92.0
285;-419.7949966431283;0.14666666666666667;91.0
290;-416.48560879374554;0.23333333333333334;89.0
295;-417.00885693751013;0.21333333333333335;89.66666666666666
300;-416.51271116050225;0.13333333333333333;90.33333333333333
