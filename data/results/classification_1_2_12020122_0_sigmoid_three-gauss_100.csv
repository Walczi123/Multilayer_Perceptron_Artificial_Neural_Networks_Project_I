Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-416.72117489839167;0.24666666666666667;89.0
10;-419.95134444654536;0.25333333333333335;89.33333333333333
15;-420.6444915771053;0.26;89.0
20;-425.4965214910249;0.29333333333333333;88.66666666666667
25;-425.4965214910249;0.29333333333333333;88.66666666666667
30;-423.41708009934507;0.28;88.66666666666667
35;-422.7239329687851;0.2733333333333333;89.0
40;-422.0307858382252;0.26666666666666666;89.33333333333333
45;-422.7239329687851;0.2733333333333333;89.0
50;-428.80590934040754;0.20666666666666667;90.66666666666666
55;-427.5895140660831;0.22;90.33333333333333
60;-424.11022722990504;0.2866666666666667;88.33333333333333
65;-422.7239329687851;0.2733333333333333;89.0
70;-429.83885444455836;0.26;89.33333333333333
75;-423.94032824310966;0.26;89.33333333333333
80;-426.37311879175866;0.23333333333333334;90.0
85;-426.37311879175866;0.23333333333333334;90.0
90;-426.1896686215849;0.3;88.33333333333333
95;-423.94032824310966;0.26;89.33333333333333
100;-422.7239329687851;0.2733333333333333;89.0
105;-423.41708009934507;0.28;88.66666666666667
110;-429.83885444455836;0.26;89.33333333333333
115;-426.1896686215849;0.3;88.33333333333333
120;-424.63347537366957;0.26666666666666666;89.0
125;-426.37311879175866;0.23333333333333334;90.0
130;-426.1896686215849;0.3;88.33333333333333
135;-425.32662250422953;0.2733333333333333;88.66666666666667
140;-423.94032824310966;0.26;89.33333333333333
145;-429.83885444455836;0.26;89.33333333333333
150;-424.11022722990504;0.2866666666666667;88.33333333333333
155;-426.37311879175866;0.23333333333333334;90.0
160;-426.7129167653494;0.28;89.0
165;-427.5895140660831;0.22;90.33333333333333
170;-427.40606389590937;0.2866666666666667;88.66666666666667
175;-427.06626592231856;0.24;89.66666666666666
180;-427.40606389590937;0.2866666666666667;88.66666666666667
185;-423.94032824310966;0.26;89.33333333333333
190;-427.5895140660831;0.22;90.33333333333333
195;-426.37311879175866;0.23333333333333334;90.0
200;-429.4855052875892;0.3;88.66666666666667
205;-427.40606389590937;0.2866666666666667;88.66666666666667
210;-426.7129167653494;0.28;89.0
215;-423.6005302695188;0.21333333333333335;90.33333333333333
220;-426.01976963478944;0.2733333333333333;89.33333333333333
225;-428.97580832720297;0.23333333333333334;89.66666666666666
230;-429.83885444455836;0.26;89.33333333333333
235;-426.37311879175866;0.23333333333333334;90.0
240;-426.01976963478944;0.2733333333333333;89.33333333333333
245;-426.01976963478944;0.2733333333333333;89.33333333333333
250;-427.40606389590937;0.2866666666666667;88.66666666666667
255;-427.40606389590937;0.2866666666666667;88.66666666666667
260;-426.01976963478944;0.2733333333333333;89.33333333333333
265;-429.4855052875892;0.3;88.66666666666667
270;-429.4855052875892;0.3;88.66666666666667
275;-429.1457073139984;0.25333333333333335;89.66666666666666
280;-420.1347946167191;0.20666666666666667;90.0
285;-427.5895140660831;0.22;90.33333333333333
290;-428.45256018343844;0.24666666666666667;90.0
295;-425.4965214910249;0.29333333333333333;88.66666666666667
300;-426.7129167653494;0.28;89.0
