Train dataset: data/regression/data.activation.train.100.csv
Test dataset: data/regression/data.activation.test.100.csv
Layers: [1, 16, 8, 4, 2, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.022527234287243306;0.12437438721233587
10;0.037618456611571496;0.03450231497309167
15;0.023171388545047276;0.04637983549748151
20;0.03364565728224281;0.03307556164716122
25;0.020342822043328913;0.05553760540251334
30;0.02982925668312671;0.03214157434433294
35;0.019867427089111853;0.07106181939363207
40;0.031054515665738712;0.032208860760492154
45;0.030268331990822062;0.03225824774576667
50;0.05345126723791265;0.03765340667529861
55;0.030719844381652216;0.032128723935571264
60;0.019825849286394224;0.03420027651266
65;0.014540382783817345;0.04117950357630949
70;0.03207043792591028;0.03262338318465815
75;0.03760446646779028;0.03400190686431025
80;0.016425186038322118;0.029824436902197243
85;0.015673922034136277;0.06797624068406402
90;0.015265814265145403;0.0380281795089638
95;0.03829714943088326;0.03469902091016086
100;0.01821028594328083;0.03445180858049993
105;0.02783775476319963;0.032292164467704
110;0.021378163385059875;0.030585879409619408
115;0.025665624059199876;0.03312143193719717
120;0.019522095654521312;0.0305894682826291
125;0.01887182400257899;0.030293241487397298
130;0.027091899764771256;0.031842326675663495
135;0.056418401931204246;0.0383587895409852
140;0.0318730977845777;0.032546161369474684
145;0.019181422863527944;0.04082407128508905
150;0.027977057604353962;0.03147948666387719
155;0.01937530321934495;0.03076428154457762
160;0.02292171560158377;0.031169388273502175
165;0.023683037445549105;0.031354107788470954
170;0.017331899638260116;0.031278044438798884
175;0.018508881525829864;0.0355948541566732
180;0.01598322762875856;0.030626153871836353
185;0.015599084254883055;0.030855705441741016
190;0.018288604600872935;0.03253799171023709
195;0.03068948911831581;0.032134934202782774
200;0.017189919595453084;0.043177247186445576
205;0.01991930836743453;0.06782917487733056
210;0.03228794884603798;0.03311337301495959
215;0.014645522386880378;0.06075557763176981
220;0.018805518049105584;0.03403622451454479
225;0.023838370920011915;0.030683962987412827
230;0.018352638422920894;0.03228241042048665
235;0.018812356505586787;0.034623705407189176
240;0.018569366303463033;0.04733537817995146
245;0.03659658303993313;0.033933163979194846
250;0.020564264901751287;0.04073345240202028
255;0.02486259172308456;0.030881977702815665
260;0.020548445684829945;0.029715432947536577
265;0.03807015563256609;0.03415860320454979
270;0.03950644285699581;0.035311311817581056
275;0.01524359328299169;0.09146982199646475
280;0.0235380395679211;0.03133049803913837
285;0.020356604790471175;0.03014111894187086
290;0.017763767402901694;0.029422194337877218
295;0.03421516744718212;0.03359811603364338
300;0.03146349760260247;0.03300563570100442
