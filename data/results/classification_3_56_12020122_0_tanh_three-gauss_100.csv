Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 32, 16, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-412.6800751673551;0.16;90.66666666666666
10;-414.75951655903486;0.17333333333333334;90.66666666666666
15;-413.373222297915;0.16666666666666666;90.33333333333333
20;-410.9539829326443;0.12;91.33333333333333
25;-416.91817625194375;0.06666666666666667;92.33333333333333
30;-423.0908333091326;0.14666666666666667;91.33333333333333
35;-414.5510528211455;0.05333333333333334;92.66666666666666
40;-424.3072285834571;0.13333333333333333;91.66666666666666
45;-413.373222297915;0.16666666666666666;90.33333333333333
50;-397.5079677972242;0.34;85.0
55;-411.25521615514117;0.05333333333333334;92.33333333333333
60;-409.09655646223223;0.2;89.0
65;-396.5271386275458;0.3;87.33333333333333
70;-433.01690805823966;0.30666666666666664;86.33333333333333
75;-398.26678204563484;0.2733333333333333;87.33333333333333
80;-414.28838434974267;0.25333333333333335;87.66666666666667
85;-420.4881437736882;0.16;90.33333333333333
90;-406.8993320182293;0.17333333333333334;88.33333333333333
95;-428.8059093404076;0.21333333333333335;89.66666666666666
100;-424.3072285834571;0.13333333333333333;91.66666666666666
105;-416.1458108201548;0.2;90.0
110;-396.6313704964905;0.4;83.66666666666667
115;-397.16816982363343;0.2866666666666667;86.33333333333333
120;-412.1568270235905;0.19333333333333333;90.0
125;-400.9872546334023;0.25333333333333335;87.33333333333333
130;-430.3485514049446;0.35333333333333333;84.33333333333334
135;-427.6030652494614;0.16;90.0
140;-442.838750938402;0.3466666666666667;86.0
145;-433.2003582284134;0.24;87.66666666666667
150;-424.4771275702525;0.16;90.66666666666666
155;-417.2308718587779;0.30666666666666664;85.0
160;-409.73758765831985;0.14;89.0
165;-414.89085079473625;0.09333333333333334;89.66666666666666
170;-408.9131062920585;0.24;89.0
175;-432.44154398000273;0.30666666666666664;86.33333333333333
180;-412.7457422852057;0.13333333333333333;90.0
185;-411.00609886711675;0.18;89.33333333333333
190;-431.81406396729346;0.2;90.33333333333333
195;-406.89933201822936;0.16;90.0
200;-418.2388033952129;0.11333333333333333;91.66666666666666
205;-410.6006337756752;0.17333333333333334;89.0
210;-392.22337042510634;0.44666666666666666;83.33333333333334
215;-411.5950141287319;0.1;91.33333333333333
220;-418.2388033952129;0.13333333333333333;91.33333333333333
225;-421.6524231135403;0.11333333333333333;89.0
230;-406.59809879573254;0.24666666666666667;87.0
235;-421.18129090424816;0.16666666666666666;90.33333333333333
240;-417.3757572778576;0.08;91.66666666666666
245;-422.9209343223372;0.12;92.33333333333333
250;-412.0911599057398;0.26666666666666666;87.33333333333333
255;-415.28276470279945;0.16;89.0
260;-409.1872371477986;0.32;88.0
265;-415.96236064998106;0.26666666666666666;88.33333333333333
270;-425.0003757140171;0.14;91.33333333333333
275;-419.7428807086559;0.13333333333333333;91.33333333333333
280;-416.91817625194375;0.06666666666666667;92.33333333333333
285;-412.44450906270896;0.22;88.66666666666667
290;-409.436354435823;0.2;88.66666666666667
295;-435.2797996200932;0.2733333333333333;86.66666666666667
300;-417.6363369502194;0.3;85.0
