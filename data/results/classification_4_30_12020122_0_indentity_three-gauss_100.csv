Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 16, 8, 4, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-404.8313530108868;0.43333333333333335;84.66666666666667
10;-422.5404827986114;0.34;87.33333333333333
15;-421.3240875242869;0.35333333333333333;87.0
20;-415.4391125062165;0.26666666666666666;88.66666666666667
25;-419.4280963027808;0.2733333333333333;88.66666666666667
30;-413.8693680749228;0.32;87.66666666666667
35;-416.3021586235718;0.29333333333333333;88.33333333333333
40;-416.9953057541318;0.3;88.0
45;-424.45002520349584;0.3333333333333333;87.33333333333333
50;-410.9268805658877;0.28;88.0
55;-416.3021586235718;0.29333333333333333;88.33333333333333
60;-416.13225963677644;0.2733333333333333;88.33333333333333
65;-419.4280963027808;0.2733333333333333;88.66666666666667
70;-420.80083938052235;0.37333333333333335;86.33333333333333
75;-406.59809879573254;0.24;89.0
80;-427.91576085629555;0.36;86.66666666666667
85;-409.7240364749415;0.22;89.33333333333333
90;-419.24464613260704;0.34;87.0
95;-414.22271723189203;0.28;88.33333333333333
100;-420.1212434333407;0.28;88.33333333333333
105;-411.26667853947845;0.32666666666666666;87.0
110;-409.03088934438154;0.21333333333333335;89.66666666666666
115;-394.2371446989355;0.5133333333333333;82.33333333333334
120;-409.03088934438154;0.21333333333333335;89.66666666666666
125;-414.915864362452;0.2866666666666667;88.0
130;-417.84480068810876;0.42;85.0
135;-410.77053276247057;0.18;90.66666666666666
140;-431.56494667926904;0.32;87.66666666666667
145;-413.8693680749228;0.32666666666666666;86.66666666666667
150;-410.7569815790922;0.25333333333333335;89.0
155;-417.3486549111009;0.26;88.66666666666667
160;-414.57606638886114;0.24;89.0
165;-413.69946908812744;0.3;87.66666666666667
170;-421.6638854978777;0.4;86.0
175;-407.2912459262925;0.24666666666666667;88.66666666666667
180;-413.69946908812744;0.3;87.66666666666667
185;-407.80094288667874;0.3;87.66666666666667
190;-413.0063219575675;0.29333333333333333;88.0
195;-421.67743668125604;0.31333333333333335;87.66666666666667
200;-410.58708259229684;0.23333333333333334;89.0
205;-401.0393705678746;0.2866666666666667;88.0
210;-414.37906503530905;0.3933333333333333;85.66666666666667
215;-406.24474963876344;0.26666666666666666;88.33333333333333
220;-415.09931453262567;0.22;89.66666666666666
225;-418.21170102845633;0.2866666666666667;88.33333333333333
230;-416.47205761036724;0.32;87.33333333333333
235;-420.6444915771052;0.26;89.0
240;-421.86088685142977;0.24666666666666667;89.33333333333333
245;-407.81449407005704;0.22666666666666666;89.33333333333333
250;-421.8473356680514;0.34;86.66666666666667
255;-424.6199241902912;0.36;86.33333333333333
260;-412.14327584021214;0.26666666666666666;88.33333333333333
265;-410.7569815790922;0.25333333333333335;89.0
270;-413.69946908812744;0.3;87.66666666666667
275;-419.4280963027808;0.2733333333333333;88.66666666666667
280;-411.80347786662134;0.22;89.33333333333333
285;-414.57606638886114;0.24;89.0
290;-424.45002520349584;0.3333333333333333;87.33333333333333
295;-414.22271723189203;0.28;88.33333333333333
300;-405.184702167856;0.3933333333333333;85.33333333333334
