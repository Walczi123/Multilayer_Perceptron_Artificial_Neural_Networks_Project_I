Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 64, 32, 16, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4340.474588466097;0.09866666666666667;92.93333333333334
10;-4153.300868036328;0.15466666666666667;91.0
15;-4258.051569449232;0.14466666666666667;91.23333333333333
20;-4376.556804006309;0.09533333333333334;93.33333333333333
25;-4532.075056137844;0.12066666666666667;91.8
30;-4469.637609653935;0.10666666666666667;92.93333333333334
35;-4437.4672484081;0.07266666666666667;93.66666666666667
40;-4256.234796528955;0.07333333333333333;93.10000000000001
45;-4332.822867663182;0.08333333333333333;93.36666666666666
50;-4460.458886768901;0.07266666666666667;93.5
55;-4345.009745175101;0.112;93.06666666666666
60;-4520.255078966272;0.074;92.9
65;-4389.321134395506;0.1;93.13333333333334
70;-4310.039693040269;0.08133333333333333;93.33333333333333
75;-4402.3616844394855;0.09266666666666666;93.4
80;-4418.91071248544;0.09066666666666667;93.0
85;-4439.988630843274;0.09866666666666667;92.76666666666667
90;-4493.419342227986;0.08733333333333333;92.93333333333334
95;-4416.2131646663465;0.07333333333333333;93.60000000000001
100;-4386.695520091387;0.07133333333333333;93.60000000000001
105;-4403.029818002329;0.07066666666666667;93.76666666666667
110;-4308.130150635385;0.07733333333333334;93.30000000000001
115;-4453.119861572819;0.09533333333333334;93.13333333333334
120;-4327.028573330676;0.086;93.33333333333333
125;-4299.889514570853;0.09466666666666666;93.06666666666666
130;-4384.24917835936;0.06933333333333333;93.56666666666666
135;-4424.50591666535;0.06933333333333333;93.26666666666667
140;-4564.186016662951;0.072;93.03333333333333
145;-4605.502802439849;0.084;92.86666666666666
150;-4366.632818056242;0.07066666666666667;93.5
155;-4613.193087993859;0.07066666666666667;92.83333333333333
160;-4365.180856677272;0.06933333333333333;93.33333333333333
165;-4327.918721814789;0.07333333333333333;93.56666666666666
170;-4456.077989064273;0.07333333333333333;93.06666666666666
175;-4439.336137262849;0.08;93.0
180;-4441.205026117599;0.09333333333333334;93.0
185;-4469.222770977198;0.08066666666666666;93.13333333333334
190;-4476.688952810899;0.07733333333333334;93.36666666666666
195;-4499.773360656307;0.07933333333333334;93.16666666666666
200;-4353.1617893531065;0.06933333333333333;93.5
205;-4503.828011570722;0.072;93.30000000000001
210;-4453.500313096545;0.08266666666666667;93.30000000000001
215;-4478.548468080351;0.07;93.26666666666667
220;-4291.927186960144;0.06733333333333333;93.26666666666667
225;-4399.890329139742;0.082;93.60000000000001
230;-4398.060005036086;0.06866666666666667;93.60000000000001
235;-4540.095766080148;0.07466666666666667;93.33333333333333
240;-4436.667780609554;0.08;93.23333333333333
245;-4410.980683228701;0.086;92.73333333333333
250;-4359.463691846956;0.088;93.06666666666666
255;-4495.550899554138;0.07933333333333334;92.83333333333333
260;-4511.531848308111;0.07066666666666667;93.16666666666666
265;-4384.718221769612;0.094;92.96666666666667
270;-4440.409735917135;0.078;93.10000000000001
275;-4374.033332772093;0.08866666666666667;93.36666666666666
280;-4462.040093584533;0.082;93.33333333333333
285;-4535.22809618381;0.094;92.66666666666666
290;-4371.378527302177;0.08533333333333333;93.33333333333333
295;-4352.690657143815;0.06866666666666667;93.43333333333334
300;-4500.871972878309;0.07066666666666667;93.56666666666666
