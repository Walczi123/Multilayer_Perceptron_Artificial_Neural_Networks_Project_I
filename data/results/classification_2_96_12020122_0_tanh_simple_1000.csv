Train dataset: data/classification/data.simple.train.1000.csv
Test dataset: data/classification/data.simple.test.1000.csv
Layers: [2, 64, 32, 2]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-675.8186014959429;0.018;99.1
10;-677.8980428876228;0.018;99.1
15;-677.8980428876228;0.018;99.1
20;-673.7391601042632;0.012;99.4
25;-677.2048957570628;0.016;99.2
30;-670.9665715820233;0.052;97.39999999999999
35;-676.5117486265029;0.014;99.3
40;-674.432307234823;0.02;99.0
45;-677.2048957570628;0.022;98.9
50;-673.0460129737032;0.022;98.9
55;-677.2048957570628;0.034;98.3
60;-677.2048957570628;0.016;99.2
65;-673.7391601042632;0.03;98.5
70;-675.8186014959429;0.018;99.1
75;-677.2048957570628;0.016;99.2
80;-672.3528658431433;0.038;98.1
85;-677.2048957570628;0.016;99.2
90;-675.818601495943;0.024;98.8
95;-677.2048957570628;0.016;99.2
100;-677.8980428876228;0.006;99.7
105;-675.125454365383;0.01;99.5
110;-674.432307234823;0.02;99.0
115;-673.0460129737032;0.022;98.9
120;-677.2048957570628;0.016;99.2
125;-677.8980428876228;0.006;99.7
130;-677.8980428876228;0.018;99.1
135;-677.8980428876228;0.018;99.1
140;-676.5117486265028;0.008;99.6
145;-676.5117486265028;0.008;99.6
150;-677.2048957570628;0.016;99.2
155;-677.2048957570628;0.016;99.2
160;-677.8980428876228;0.006;99.7
165;-676.5117486265028;0.008;99.6
170;-677.2048957570628;0.016;99.2
175;-677.8980428876228;0.018;99.1
180;-676.5117486265028;0.008;99.6
185;-675.125454365383;0.01;99.5
190;-677.2048957570628;0.022;98.9
195;-674.432307234823;0.02;99.0
200;-676.5117486265029;0.014;99.3
205;-677.2048957570628;0.016;99.2
210;-677.8980428876228;0.012;99.4
215;-676.5117486265028;0.008;99.6
220;-676.5117486265029;0.014;99.3
225;-676.5117486265028;0.008;99.6
230;-675.818601495943;0.012;99.4
235;-677.2048957570628;0.016;99.2
240;-675.125454365383;0.01;99.5
245;-677.8980428876228;0.012;99.4
250;-678.5911900181827;0.014;99.3
255;-675.818601495943;0.012;99.4
260;-677.8980428876228;0.006;99.7
265;-676.5117486265028;0.008;99.6
270;-677.2048957570628;0.016;99.2
275;-677.2048957570628;0.016;99.2
280;-677.2048957570628;0.016;99.2
285;-677.2048957570628;0.01;99.5
290;-676.5117486265028;0.008;99.6
295;-677.8980428876228;0.006;99.7
300;-677.8980428876228;0.006;99.7
