Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 8, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-433.802824673407;0.06;92.66666666666666
10;-432.7042124514055;0.06;93.0
15;-435.2412348689992;0.10666666666666667;92.66666666666666
20;-438.6548545873266;0.09333333333333334;92.33333333333333
25;-433.802824673407;0.06;92.66666666666666
30;-436.4576301433237;0.09333333333333334;93.0
35;-432.7042124514055;0.06;93.0
40;-430.2193059682842;0.04666666666666667;94.0
45;-428.13986457660434;0.03333333333333333;94.0
50;-437.7396925354989;0.05333333333333334;93.0
55;-432.53431346461014;0.03333333333333333;94.0
60;-431.6056002294041;0.06;93.33333333333333
65;-428.7152286548412;0.05333333333333334;94.33333333333334
70;-439.93691697950175;0.05333333333333334;93.66666666666667
75;-432.0110653208456;0.05333333333333334;93.33333333333333
80;-439.93691697950175;0.05333333333333334;93.66666666666667
85;-437.4520104963804;0.06666666666666667;93.0
90;-443.4026526323015;0.05333333333333334;93.33333333333333
95;-439.1259867966188;0.04;94.0
100;-430.2193059682842;0.04666666666666667;94.0
105;-441.0355292015032;0.05333333333333334;93.33333333333333
110;-449.8244269775148;0.05333333333333334;93.33333333333333
115;-445.42997808950895;0.05333333333333334;93.33333333333333
120;-437.9095915222943;0.05333333333333334;93.66666666666667
125;-431.31791819028564;0.04666666666666667;93.66666666666667
130;-441.89857531885855;0.06;93.66666666666667
135;-449.8244269775148;0.05333333333333334;93.33333333333333
140;-436.4055142088514;0.06;94.0
145;-455.31748808752207;0.05333333333333334;93.0
150;-444.33136586750754;0.05333333333333334;93.66666666666667
155;-449.8244269775148;0.05333333333333334;93.33333333333333
160;-449.8244269775148;0.05333333333333334;93.33333333333333
165;-455.31748808752207;0.05333333333333334;93.0
170;-449.8244269775148;0.05333333333333334;93.33333333333333
175;-454.2188758655206;0.05333333333333334;93.33333333333333
180;-449.8244269775148;0.05333333333333334;93.33333333333333
185;-449.8244269775148;0.05333333333333334;93.33333333333333
190;-449.8244269775148;0.05333333333333334;93.33333333333333
195;-455.31748808752207;0.05333333333333334;93.0
200;-454.2188758655206;0.05333333333333334;93.33333333333333
205;-454.2188758655206;0.05333333333333334;93.33333333333333
210;-449.8244269775148;0.05333333333333334;93.33333333333333
215;-448.72581475551334;0.05333333333333334;93.66666666666667
220;-443.925900776066;0.06;93.66666666666667
225;-459.7119369755278;0.05333333333333334;93.0
230;-455.31748808752207;0.05333333333333334;93.0
235;-448.32034966407184;0.06;93.66666666666667
240;-448.72581475551334;0.05333333333333334;93.66666666666667
245;-441.89857531885855;0.06;93.66666666666667
250;-455.31748808752207;0.05333333333333334;93.0
255;-453.8134107740791;0.06;93.33333333333333
260;-449.8244269775148;0.05333333333333334;93.33333333333333
265;-452.71479855207764;0.06;93.66666666666667
270;-454.9120229960805;0.06;93.0
275;-454.2188758655206;0.05333333333333334;93.33333333333333
280;-448.72581475551334;0.05333333333333334;93.66666666666667
285;-454.2188758655206;0.05333333333333334;93.33333333333333
290;-454.2188758655206;0.05333333333333334;93.33333333333333
295;-448.32034966407184;0.06;93.66666666666667
300;-449.8244269775148;0.05333333333333334;93.33333333333333
