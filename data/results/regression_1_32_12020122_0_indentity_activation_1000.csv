Train dataset: data/regression/data.activation.train.1000.csv
Test dataset: data/regression/data.activation.test.1000.csv
Layers: [1, 32, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.37141546307951834;0.07098106843072101
10;0.32548818913051925;0.07187369807129185
15;0.4334424935003141;0.07054820394289749
20;0.22856876352691133;0.08260281970386849
25;0.39749020457993794;0.070726010993651
30;0.40304819126460517;0.07068720464962455
35;0.26161535522946544;0.07555944547584849
40;0.25554971437488794;0.07629138463784355
45;0.4991811811390313;0.07053395032424352
50;0.2855786514105453;0.07357364239661807
55;0.436918504330614;0.07053897767328374
60;0.2732693744831783;0.07445066570442781
65;0.350691065165085;0.07129526434354788
70;0.5907483431554238;0.07085311873031379
75;0.4462212115886201;0.0705199092840704
80;0.40438893257189773;0.07067854336764073
85;0.37367858518301356;0.07095345292718815
90;0.40960477263185113;0.07064730063458016
95;0.3149609275522158;0.07220472259026788
100;0.40392776036079964;0.07068149275478576
105;0.32195009136660196;0.07197792431653716
110;0.33276402850744996;0.07167919674211322
115;0.2645202156023415;0.07525084650615536
120;0.46479927745179833;0.07050354138139049
125;0.3558913268740204;0.07120501922611315
130;0.32929070644021285;0.07176887651904887
135;0.277198272312214;0.07414351125557817
140;0.4597451514510372;0.07050537299587689
145;0.711675257728859;0.07152235035867119
150;0.3365174998052337;0.07158835224758321
155;0.26931461382465816;0.07479060127831479
160;0.815604183821547;0.07217607801091593
165;0.39841295414272193;0.07071923584669548
170;0.2625904764299045;0.07545312136552428
175;0.28020317446882037;0.07392678563282087
180;0.6309930910103405;0.07105662422573478
185;0.28348078419662853;0.07370651872349712
190;0.23390515013049842;0.08062984501444356
195;0.37056131740005954;0.07099179901911788
200;0.5087051712788195;0.07055346782123338
205;0.5247514177528106;0.07059514687902524
210;0.4085880848589299;0.07065309186088907
215;0.4271267332329454;0.07056812529169931
220;0.3295678838075707;0.0717615128311163
225;0.3191828067687342;0.0720642566302416
230;0.3711514526862826;0.07098436692738054
235;0.5891922677945162;0.07084581003329184
240;0.41382736393158476;0.07062473351967753
245;0.5218909244794734;0.07058696942133127
250;0.24114544944904182;0.0787367451030306
255;0.2337144610336067;0.08068973607760653
260;0.22636341206127872;0.08366664283732199
265;0.35984350202466103;0.07114186195019029
270;0.3141904117408453;0.0722315636611786
275;0.4755895986637107;0.07050550040865618
280;0.6661417438839559;0.07125226044940884
285;0.6669045677205215;0.07125664933082847
290;0.4008087174412356;0.07070226945325304
295;0.25269279948925255;0.07668510004972609
300;0.3302923197351886;0.0717424392634071
