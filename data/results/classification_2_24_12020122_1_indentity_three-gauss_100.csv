Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 16, 8, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: indentity
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-446.9205042195736;0.11333333333333333;90.33333333333333
10;-428.63601035361216;0.18;91.66666666666666
15;-441.41389192618806;0.19333333333333333;90.66666666666666
20;-437.6604742342698;0.15333333333333332;91.66666666666666
25;-428.1398645766043;0.05333333333333334;93.0
30;-425.1317099497184;0.06;93.33333333333333
35;-427.8521825374859;0.04;93.33333333333333
40;-421.2605092054772;0.04;94.0
45;-434.41675350273783;0.19333333333333333;91.0
50;-446.88193946847963;0.08;92.0
55;-433.68504162108394;0.07333333333333333;92.0
60;-372.45043922812135;0.09333333333333334;88.66666666666667
65;-434.4824206205885;0.14;92.0
70;-449.11772866357654;0.12;91.66666666666666
75;-429.7617249423703;0.05333333333333334;92.66666666666666
80;-431.59204904602575;0.15333333333333332;92.0
85;-420.0441139311527;0.05333333333333334;93.66666666666667
90;-405.3952547047864;0.17333333333333334;89.33333333333333
95;-426.51800421083834;0.05333333333333334;93.66666666666667
100;-398.23967967887813;0.43333333333333335;84.0
105;-434.6658707907623;0.08666666666666667;92.33333333333333
110;-438.5506227183819;0.06;92.0
115;-443.6382187369476;0.07333333333333333;92.33333333333333
120;-400.72667496104054;0.08666666666666667;91.33333333333333
125;-415.3619830040285;0.04666666666666667;93.0
130;-422.7510353355418;0.11333333333333333;92.33333333333333
135;-434.1561738303761;0.05333333333333334;92.66666666666666
140;-442.3426051613941;0.16666666666666666;91.33333333333333
145;-464.62963400729825;0.10666666666666667;91.0
150;-407.6716974500183;0.06;92.66666666666666
155;-430.45487207293024;0.06;92.33333333333333
160;-424.89614384507234;0.07333333333333333;93.33333333333333
165;-459.65982104105547;0.08666666666666667;90.66666666666666
170;-453.52572873496064;0.07333333333333333;89.33333333333333
175;-434.1561738303761;0.05333333333333334;92.66666666666666
180;-418.76205153897746;0.10666666666666667;92.33333333333333
185;-441.8464593843862;0.06666666666666667;91.66666666666666
190;-444.73683095894904;0.07333333333333333;92.0
195;-424.3728957013078;0.09333333333333334;92.66666666666666
200;-410.1566039331397;0.05333333333333334;92.66666666666666
205;-427.73439948516284;0.05333333333333334;92.66666666666666
210;-438.98110137753906;0.22;90.0
215;-380.79530716159735;0.04;90.0
220;-427.8521825374859;0.04;93.33333333333333
225;-407.5539143976953;0.06;92.0
230;-455.5916189432621;0.13333333333333333;89.0
235;-425.1317099497184;0.06;93.33333333333333
240;-436.2877311565283;0.06666666666666667;92.66666666666666
245;-430.7946700465211;0.06666666666666667;93.0
250;-428.2962123800214;0.15333333333333332;91.66666666666666
255;-439.85769867827275;0.16;91.33333333333333
260;-437.5041264308528;0.05333333333333334;93.0
265;-436.9808782870883;0.07333333333333333;92.33333333333333
270;-437.0329942215606;0.11333333333333333;92.0
275;-485.50326622532566;0.10666666666666667;87.33333333333333
280;-412.52372736393795;0.08;92.33333333333333
285;-405.76215504513385;0.05333333333333334;92.66666666666666
290;-407.2912459262925;0.23333333333333334;88.66666666666667
295;-383.214546526868;0.06666666666666667;90.0
300;-408.60041068522435;0.05333333333333334;92.33333333333333
