Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 64, 32, 16, 8, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4184.747872596673;0.084;92.2
10;-4186.129989259711;0.128;91.66666666666666
15;-4157.1960639591525;0.10333333333333333;90.43333333333334
20;-4306.843910645128;0.14066666666666666;92.30000000000001
25;-4628.990586577658;0.098;91.36666666666666
30;-4543.924224475214;0.11866666666666667;92.30000000000001
35;-4407.831820780817;0.086;93.13333333333334
40;-4419.692451502524;0.07533333333333334;93.33333333333333
45;-4182.809139025991;0.094;92.13333333333334
50;-4439.048455223731;0.07733333333333334;93.36666666666666
55;-4324.253896009396;0.11066666666666666;92.96666666666667
60;-4763.807194277002;0.07466666666666667;92.13333333333334
65;-4356.686925726634;0.14;92.26666666666667
70;-4317.965544698925;0.078;93.43333333333334
75;-4477.511345378119;0.11333333333333333;92.76666666666667
80;-4559.469498582815;0.128;91.9
85;-4450.229489998256;0.09266666666666666;92.9
90;-4490.071389627509;0.09533333333333334;92.86666666666666
95;-4465.6642658397905;0.07533333333333334;93.46666666666667
100;-4418.555274529429;0.07133333333333333;93.46666666666667
105;-4392.410596122661;0.068;93.60000000000001
110;-4334.052814120883;0.074;93.5
115;-4468.5796509820675;0.084;93.33333333333333
120;-4310.576492367412;0.06933333333333333;93.56666666666666
125;-4303.133235302386;0.09266666666666666;93.16666666666666
130;-4373.328723257196;0.06933333333333333;93.53333333333333
135;-4456.130104998746;0.07266666666666667;93.2
140;-4611.335661523446;0.076;92.73333333333333
145;-4726.025988868836;0.122;91.73333333333333
150;-4429.305830644797;0.07333333333333333;93.33333333333333
155;-4633.622690369351;0.08333333333333333;92.60000000000001
160;-4394.01890530505;0.07333333333333333;93.56666666666666
165;-4414.983218208643;0.08066666666666666;93.43333333333334
170;-4498.296385709621;0.084;93.2
175;-4407.7255001128315;0.08133333333333333;93.2
180;-4441.284244418828;0.086;93.33333333333333
185;-4428.626234697616;0.08533333333333333;93.06666666666666
190;-4438.119741988525;0.074;93.5
195;-4674.23068903327;0.096;91.93333333333334
200;-4311.49165441924;0.07266666666666667;93.60000000000001
205;-4458.431561311693;0.07066666666666667;93.43333333333334
210;-4444.763531255006;0.09666666666666666;92.9
215;-4584.604156654106;0.086;92.7
220;-4290.160441175299;0.076;93.16666666666666
225;-4392.252159520204;0.08533333333333333;93.23333333333333
230;-4445.182547529826;0.076;93.36666666666666
235;-4649.29094351649;0.098;92.26666666666667
240;-4419.02431793968;0.086;93.10000000000001
245;-4438.262538608564;0.08866666666666667;92.83333333333333
250;-4288.837725232988;0.10666666666666667;92.73333333333333
255;-4726.96616448838;0.094;91.76666666666667
260;-4477.57910129501;0.07466666666666667;93.23333333333333
265;-4364.080155656229;0.09133333333333334;93.06666666666666
270;-4398.569701996473;0.07466666666666667;93.56666666666666
275;-4347.967872666555;0.08933333333333333;92.93333333333334
280;-4457.018164683817;0.08133333333333333;93.16666666666666
285;-4444.31741261343;0.098;92.93333333333334
290;-4330.990454760485;0.096;93.33333333333333
295;-4385.415546498253;0.09266666666666666;92.96666666666667
300;-4561.648994245357;0.07666666666666666;93.4
