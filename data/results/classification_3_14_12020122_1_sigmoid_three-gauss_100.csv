Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 8, 4, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-659.1673932008655;1.3333333333333333;33.33333333333333
10;-214.18252334302122;0.5266666666666666;60.333333333333336
15;-341.3745126062056;0.24666666666666667;75.66666666666667
20;-447.6136513501336;0.16;89.0
25;-464.6296340072982;0.08;92.66666666666666
30;-461.2681302234432;0.08666666666666667;92.33333333333333
35;-443.1149705931831;0.06666666666666667;93.33333333333333
40;-451.09293818631164;0.05333333333333334;93.66666666666667
45;-429.748173758992;0.11333333333333333;92.33333333333333
50;-461.3337973412938;0.08;92.33333333333333
55;-457.0571315056111;0.06666666666666667;93.0
60;-447.1696215075981;0.06666666666666667;93.33333333333333
65;-441.0355292015032;0.05333333333333334;93.33333333333333
70;-461.67359531488466;0.06;93.0
75;-441.0355292015032;0.05333333333333334;93.33333333333333
80;-467.0488733725689;0.07333333333333333;92.0
85;-463.1255566938553;0.04;94.0
90;-459.5941539232048;0.06666666666666667;92.33333333333333
95;-455.31748808752207;0.05333333333333334;93.0
100;-443.9259007760661;0.06;93.66666666666667
105;-453.69562772175607;0.07333333333333333;92.66666666666666
110;-448.89571374230877;0.05333333333333334;93.0
115;-452.88469753887307;0.06;93.0
120;-457.85451050511574;0.08;93.33333333333333
125;-449.30117883375027;0.07333333333333333;92.66666666666666
130;-444.0957997628615;0.06;93.0
135;-454.1010928131975;0.06666666666666667;92.66666666666666
140;-439.41366883573727;0.07333333333333333;93.0
145;-462.7722075368861;0.06;92.66666666666666
150;-442.81373737068634;0.10666666666666667;92.33333333333333
155;-459.7640529100002;0.04666666666666667;93.66666666666667
160;-446.12312522006897;0.06;93.0
165;-463.9886028112106;0.06666666666666667;92.33333333333333
170;-446.5285903115104;0.05333333333333334;93.0
175;-448.72581475551334;0.05333333333333334;93.66666666666667
180;-457.39692947920184;0.06666666666666667;93.0
185;-460.6927661452063;0.06666666666666667;93.33333333333333
190;-458.4955417012033;0.06666666666666667;92.66666666666666
195;-465.72824622929966;0.08;92.33333333333333
200;-457.39692947920184;0.06666666666666667;93.0
205;-458.32564271440793;0.06666666666666667;93.33333333333333
210;-464.91731604641666;0.06666666666666667;92.66666666666666
215;-453.93119382640214;0.06666666666666667;93.33333333333333
220;-444.2135828151845;0.06666666666666667;93.0
225;-455.0298060484036;0.06666666666666667;93.0
230;-465.72824622929966;0.08;92.33333333333333
235;-450.92303919951627;0.05333333333333334;93.0
240;-457.39692947920184;0.06666666666666667;93.0
245;-455.0298060484036;0.06666666666666667;93.0
250;-469.024082895304;0.08;91.33333333333333
255;-474.51714400531125;0.08;91.0
260;-460.5228671584108;0.06666666666666667;92.66666666666666
265;-464.91731604641666;0.06666666666666667;92.66666666666666
270;-465.2049980855351;0.05333333333333334;92.66666666666666
275;-463.8187038244152;0.06666666666666667;93.0
280;-442.3040404103001;0.05333333333333334;93.66666666666667
285;-463.0077736415322;0.05333333333333334;93.33333333333333
290;-460.6927661452063;0.06666666666666667;93.33333333333333
295;-447.6793184679843;0.06666666666666667;92.66666666666666
300;-463.0077736415322;0.05333333333333334;93.33333333333333
