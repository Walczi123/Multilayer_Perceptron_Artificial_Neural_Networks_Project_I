Train dataset: data/regression/data.activation.train.100.csv
Test dataset: data/regression/data.activation.test.100.csv
Layers: [1, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.43543815999196556;0.07054276108416382
10;0.21888242717437087;0.10432653962881926
15;0.5522533133835088;0.07068808690754665
20;0.22023090749381857;0.088455819044171
25;0.6933834640948782;0.07141204280289459
30;0.6181414452675268;0.07098887988278105
35;0.518252291813782;0.07057702091977958
40;0.2762457105379516;0.07421539814440714
45;0.3801800491569439;0.07088040176820348
50;0.7069297526065372;0.0714935320949214
55;0.6890617618183512;0.07138630673891194
60;0.6178841936547503;0.07098754796975754
65;0.219040829891679;0.10481607986532109
70;0.2502849448079004;0.07704612273908426
75;0.4895557701923576;0.07051868494302999
80;0.21935718691963765;0.10574200438625994
85;0.35631697027395887;0.0711979989547327
90;0.7235580639365788;0.07159506375832178
95;0.24019264878873114;0.07895078383110829
100;0.42817936577907745;0.07056451200033638
105;0.5261450810523806;0.070599241719069
110;0.2270162130129121;0.08333105529463139
115;0.5050053542100718;0.07054539203543594
120;0.304508939531165;0.0726041624369021
125;0.24579351197329374;0.15483882913709252
130;0.8574759947515337;0.07244549022809306
135;0.35939095464552395;0.07114886729312912
140;0.5091809290688506;0.07055455024828289
145;0.3627004244027698;0.07109894099577561
150;0.5473498669719349;0.07066977126025321
155;0.5223778590975743;0.0705883395953355
160;0.21752122676058813;0.09567352001038423
165;0.3832301485427875;0.07084916015346714
170;0.2175851883134434;0.09836978824945415
175;0.44771778314935307;0.0705175641673891
180;0.2237952076946995;0.08521399613803605
185;0.4637805230670895;0.07050376319125559
190;0.33355665697385434;0.0716595019506494
195;0.5159015711768851;0.07057087193713163
200;0.43648088293260207;1.6125401149380907
205;0.6825170678135364;0.07134759517359418
210;0.22116515325668581;0.08740394264810593
215;0.25556921533716975;0.0762888152956264
220;0.5167301287893225;0.07057301390714017
225;0.3999095507913444;0.9084485423951527
230;0.23574617538517606;0.13722653794287432
235;0.2309045921319125;0.08165482981921349
240;0.4349278868045839;0.07054411506003368
245;0.2665771691311318;0.0750463759124267
250;0.5560601975382585;0.07070277673634237
255;0.2615144004683642;0.07557061759111536
260;0.25872011858695854;0.17899648882836303
265;0.5643356333651455;0.07073605072580615
270;0.48725984925862076;0.07051575745948226
275;0.40189382231873;0.07069487560642992
280;0.5339862981778135;0.0706235789785872
285;0.4409227015353223;0.0705297959865628
290;0.6756468967531537;0.0713073204467589
295;0.2736437824055106;0.07442014703768038
300;0.22866245417699013;0.12484536790407977
