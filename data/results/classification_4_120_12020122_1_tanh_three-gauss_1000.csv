Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 64, 32, 16, 8, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-3948.061561473691;0.06933333333333333;90.63333333333333
10;-4180.754711202027;0.11466666666666667;91.83333333333333
15;-4756.784023896704;0.3486666666666667;86.26666666666667
20;-4186.102886892954;0.116;91.66666666666666
25;-5005.019288523691;0.10733333333333334;87.13333333333333
30;-4573.446046648255;0.08733333333333333;92.23333333333333
35;-4264.137723418937;0.084;92.43333333333334
40;-4158.630296556663;0.07;92.26666666666667
45;-4362.958618665553;0.09;92.96666666666667
50;-4250.521809296721;0.06933333333333333;92.33333333333333
55;-4410.339652032613;0.08466666666666667;93.46666666666667
60;-4885.542598382232;0.08733333333333333;89.46666666666667
65;-4439.59462813617;0.12733333333333333;92.7
70;-4337.935477249463;0.09933333333333333;92.93333333333334
75;-4364.422042428861;0.06666666666666667;93.5
80;-4731.783807249288;0.17066666666666666;90.33333333333333
85;-4440.525430170417;0.09533333333333334;93.13333333333334
90;-4495.143345663655;0.10733333333333334;92.46666666666667
95;-4213.873603263569;0.088;92.46666666666667
100;-4310.834983240733;0.116;92.76666666666667
105;-4333.164754435813;0.072;92.76666666666667
110;-4254.021932102532;0.102;92.63333333333334
115;-4285.35843839681;0.1;92.86666666666666
120;-4144.058566832485;0.09066666666666667;91.9
125;-4265.898202806659;0.09866666666666667;92.63333333333334
130;-4384.969427856676;0.088;93.10000000000001
135;-4373.963488056161;0.15466666666666667;92.0
140;-4786.943718056882;0.084;90.9
145;-4844.085104784336;0.084;90.96666666666667
150;-4230.991728990637;0.074;93.03333333333333
155;-4751.500444913719;0.07866666666666666;91.73333333333333
160;-4113.764379227654;0.12733333333333333;91.26666666666667
165;-4372.921169366714;0.09666666666666666;93.0
170;-4429.421524898079;0.09533333333333334;93.06666666666666
175;-4479.880557607958;0.09;92.73333333333333
180;-4125.932509568981;0.064;92.33333333333333
185;-4523.695801051355;0.08666666666666667;92.7
190;-4127.343817397817;0.06266666666666666;92.5
195;-4918.512427426613;0.14266666666666666;86.5
200;-4008.505051264272;0.10066666666666667;89.73333333333333
205;-4446.136274332747;0.09333333333333334;92.96666666666667
210;-4669.475606202039;0.15;91.23333333333333
215;-4853.13458223271;0.096;90.23333333333333
220;-4231.686964920239;0.06666666666666667;92.53333333333333
225;-4621.667201363995;0.08933333333333333;92.73333333333333
230;-4385.818922790653;0.074;93.43333333333334
235;-4325.787164488637;0.08466666666666667;92.93333333333334
240;-4324.097548205979;0.10266666666666667;92.86666666666666
245;-4520.565685774064;0.11466666666666667;91.86666666666666
250;-4366.186699414666;0.088;93.23333333333333
255;-4072.8749649217402;0.08333333333333333;91.2
260;-4458.0782121547245;0.09666666666666666;92.56666666666666
265;-4300.503443400185;0.11733333333333333;92.5
270;-4505.057958028425;0.09333333333333334;92.9
275;-4297.06063251606;0.15266666666666667;92.13333333333334
280;-4285.688862785104;0.072;92.83333333333333
285;-4435.01464027895;0.164;92.03333333333333
290;-4083.8527319455907;0.16;90.4
295;-4458.89540873473;0.164;91.0
300;-4674.321369718837;0.07933333333333334;92.2
