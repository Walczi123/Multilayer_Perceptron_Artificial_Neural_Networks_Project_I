Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 256, 128, 64, 32, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-442.186257357977;0.04666666666666667;93.66666666666667
10;-433.27957652964244;0.06;94.33333333333334
15;-435.42468503917297;0.06666666666666667;93.0
20;-461.62147938041227;0.06666666666666667;92.33333333333333
25;-452.0216514215177;0.05333333333333334;94.0
30;-432.87411143820094;0.06666666666666667;93.0
35;-451.10648936969;0.08;92.66666666666666
40;-435.54246809149595;0.05333333333333334;93.66666666666667
45;-424.1373295966617;0.12;92.66666666666666
50;-426.17820623724754;0.05333333333333334;92.33333333333333
55;-466.0159282684181;0.06666666666666667;92.33333333333333
60;-424.4385628191585;0.05333333333333334;93.66666666666667
65;-423.9809817932446;0.05333333333333334;93.0
70;-450.2298920689563;0.09333333333333334;92.33333333333333
75;-448.6080317031903;0.04666666666666667;93.66666666666667
80;-474.75271010995743;0.05333333333333334;92.33333333333333
85;-456.93934845328806;0.08;92.33333333333333
90;-472.4377026136315;0.06666666666666667;92.33333333333333
95;-434.1426226469978;0.09333333333333334;93.0
100;-437.6740254176482;0.06666666666666667;93.33333333333333
105;-454.40232603569433;0.08;93.0
110;-446.4629231936598;0.08666666666666667;92.66666666666666
115;-452.6626826176053;0.06666666666666667;93.0
120;-458.4955417012033;0.06666666666666667;92.66666666666666
125;-455.31748808752207;0.05333333333333334;93.0
130;-450.0464418987825;0.09333333333333334;92.33333333333333
135;-441.37532717509407;0.10666666666666667;92.66666666666666
140;-439.5700166391543;0.14666666666666667;91.66666666666666
145;-443.2848695799785;0.09333333333333334;92.33333333333333
150;-455.70940199558527;0.1;93.0
155;-468.3830516992165;0.06666666666666667;92.33333333333333
160;-458.4955417012033;0.06666666666666667;92.66666666666666
165;-472.55548566595456;0.05333333333333334;93.0
170;-481.61851429770604;0.09333333333333334;77.33333333333333
175;-478.51967898525396;0.13333333333333333;90.66666666666666
180;-456.87368133543737;0.08666666666666667;92.33333333333333
185;-462.88999058920916;0.06666666666666667;92.66666666666666
190;-457.39692947920184;0.06666666666666667;93.0
195;-451.21072123863473;0.06666666666666667;92.66666666666666
200;-414.38115383435;0.04666666666666667;92.66666666666666
205;-425.1317099497184;0.06;93.33333333333333
210;-459.5941539232048;0.06666666666666667;92.33333333333333
215;-429.30414391645644;0.05333333333333334;92.0
220;-429.8138408768427;0.07333333333333333;93.33333333333333
225;-454.5586738391114;0.08;93.0
230;-437.7261413521205;0.1;92.66666666666666
235;-435.42468503917297;0.04;93.0
240;-425.65495809348295;0.04;94.0
245;-445.6519930107768;0.09333333333333334;92.33333333333333
250;-461.4380292102386;0.06666666666666667;92.33333333333333
255;-455.9970840347037;0.10666666666666667;92.33333333333333
260;-466.23794318968584;0.08666666666666667;90.66666666666666
265;-428.1398645766043;0.05333333333333334;93.0
270;-448.51526221858296;0.26;89.0
275;-489.84559917885923;0.06666666666666667;89.0
280;-433.68504162108394;0.06;93.33333333333333
285;-418.1481227096466;0.04666666666666667;91.33333333333333
290;-452.1123321070841;0.18666666666666668;90.66666666666666
295;-448.0191164415751;0.12;92.0
300;-468.9719669608317;0.06666666666666667;92.66666666666666
