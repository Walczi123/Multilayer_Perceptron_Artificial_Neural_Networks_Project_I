Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 8, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-434.6658707907623;0.08666666666666667;92.33333333333333
10;-442.9315204230093;0.11333333333333333;92.33333333333333
15;-445.2986438538076;0.14;92.0
20;-458.49554170120336;0.09333333333333334;92.33333333333333
25;-448.6080317031903;0.09333333333333334;92.66666666666666
30;-440.0932647829188;0.12666666666666668;92.33333333333333
35;-440.8520790313295;0.1;92.33333333333333
40;-431.55348429493165;0.06666666666666667;92.66666666666666
45;-437.3206762606791;0.10666666666666667;92.66666666666666
50;-458.6133247535264;0.1;92.33333333333333
55;-459.71193697552786;0.1;92.0
60;-425.9290889492231;0.12666666666666668;92.0
65;-437.3206762606791;0.10666666666666667;92.66666666666666
70;-467.3501065950657;0.08666666666666667;92.33333333333333
75;-428.42754661572275;0.06;93.66666666666667
80;-445.7697760630998;0.08;93.0
85;-447.74498558583497;0.08666666666666667;92.33333333333333
90;-454.96413893055296;0.07333333333333333;93.0
95;-449.0134967946318;0.08666666666666667;92.66666666666666
100;-438.4714044171528;0.14666666666666667;92.0
105;-462.19684345864925;0.08666666666666667;92.66666666666666
110;-471.74455548307157;0.08666666666666667;92.33333333333333
115;-467.46788964738874;0.09333333333333334;92.33333333333333
120;-448.2025666117488;0.07333333333333333;93.0
125;-446.93405540295197;0.07333333333333333;92.66666666666666
130;-435.7509318293854;0.16666666666666666;92.0
135;-464.51185095497516;0.07333333333333333;92.66666666666666
140;-440.0932647829188;0.12666666666666668;92.33333333333333
145;-475.275958253722;0.08;92.0
150;-445.2465279193353;0.1;92.33333333333333
155;-463.4132387329737;0.07333333333333333;93.0
160;-462.19684345864925;0.08666666666666667;92.66666666666666
165;-472.15002057451306;0.08;92.33333333333333
170;-468.8541839085087;0.08;92.0
175;-467.7555716865072;0.08;92.33333333333333
180;-453.69562772175607;0.07333333333333333;92.66666666666666
185;-469.6651140913917;0.09333333333333334;91.66666666666666
190;-453.69562772175607;0.07333333333333333;92.66666666666666
195;-459.01878984496784;0.07333333333333333;93.0
200;-440.9041949658018;0.14;92.0
205;-456.58599929631896;0.08;93.0
210;-464.51185095497516;0.07333333333333333;92.66666666666666
215;-442.2519244758277;0.08666666666666667;92.66666666666666
220;-440.6300641100617;0.06;93.33333333333333
225;-442.5396065149461;0.07333333333333333;92.66666666666666
230;-457.04358032223286;0.08666666666666667;93.0
235;-443.808117723743;0.07333333333333333;93.0
240;-437.0329942215606;0.12;92.66666666666666
245;-456.9914643877604;0.07333333333333333;93.0
250;-465.32278113785816;0.08666666666666667;92.33333333333333
255;-454.61078977358375;0.12;92.66666666666666
260;-465.32278113785816;0.08666666666666667;92.33333333333333
265;-451.3806202254301;0.08666666666666667;92.66666666666666
270;-447.6136513501335;0.12666666666666668;92.0
275;-467.7555716865072;0.08;92.33333333333333
280;-445.8354431809505;0.07333333333333333;93.0
285;-457.0571315056111;0.06666666666666667;93.0
290;-453.34227856478697;0.09333333333333334;92.66666666666666
295;-393.6253046686456;0.06666666666666667;90.66666666666666
300;-465.5583472425043;0.08;93.0
