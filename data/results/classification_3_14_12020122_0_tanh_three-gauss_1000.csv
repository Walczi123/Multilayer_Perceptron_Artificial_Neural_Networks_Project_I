Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 8, 4, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-3924.1516018521124;0.31533333333333335;86.4
10;-4056.099744356436;0.14933333333333335;90.4
15;-4011.89778299219;0.32466666666666666;86.1
20;-4182.775770262111;0.20533333333333334;90.10000000000001
25;-4091.6524453557604;0.276;87.23333333333333
30;-4117.946186779688;0.182;90.26666666666667
35;-4126.281681127868;0.116;91.56666666666666
40;-4052.545416817111;0.104;91.16666666666666
45;-4060.1022793363786;0.13866666666666666;90.56666666666666
50;-4053.3271558341958;0.146;90.3
55;-4227.506175757336;0.18266666666666667;91.0
60;-4038.6991325774634;0.23;87.76666666666667
65;-3980.3569905581053;0.22266666666666668;88.53333333333333
70;-4100.372568825747;0.11866666666666667;91.36666666666666
75;-4087.855266925533;0.13733333333333334;90.83333333333333
80;-4159.083699984494;0.11066666666666666;91.66666666666666
85;-4054.632142995046;0.182;89.76666666666667
90;-4130.42701272785;0.12;91.5
95;-4129.158501519052;0.122;91.56666666666666
100;-4088.378515069298;0.12866666666666668;91.03333333333333
105;-4077.4716111505127;0.124;91.03333333333333
110;-3434.116294085178;0.8246666666666667;73.5
115;-4152.177242246611;0.11866666666666667;91.36666666666666
120;-4073.4961785373266;0.11666666666666667;91.10000000000001
125;-3957.082866145399;0.33066666666666666;86.36666666666667
130;-4072.136986642963;0.10466666666666667;91.33333333333333
135;-4235.982377926513;0.16666666666666666;91.13333333333333
140;-4037.4619013335055;0.15733333333333333;89.8
145;-4190.3097080127045;0.19333333333333333;90.10000000000001
150;-4109.265698470704;0.116;91.36666666666666
155;-4122.1999278466965;0.12733333333333333;91.13333333333333
160;-4095.1807409382372;0.10466666666666667;91.26666666666667
165;-4102.608358020844;0.12266666666666666;91.2
170;-4050.0063056004765;0.13466666666666666;90.5
175;-4112.561535136708;0.116;91.2
180;-4150.344829343914;0.13333333333333333;91.26666666666667
185;-4084.7564316130815;0.12333333333333334;91.06666666666666
190;-4094.9566372179283;0.14066666666666666;90.83333333333333
195;-3871.601665366217;0.296;84.53333333333333
200;-4086.251135341228;0.10666666666666667;90.96666666666667
205;-4072.4496822497977;0.11733333333333333;91.06666666666666
210;-4203.099051969618;0.22333333333333333;89.26666666666667
215;-4073.3919466683815;0.114;91.10000000000001
220;-4044.254753617148;0.09466666666666666;91.13333333333333
225;-4116.14296504279;0.15466666666666667;90.76666666666667
230;-4089.1644316844654;0.11466666666666667;91.23333333333333
235;-4012.2667721315784;0.284;84.89999999999999
240;-4093.923692113777;0.13133333333333333;90.96666666666667
245;-4185.421202146732;0.14333333333333334;91.26666666666667
250;-4079.0142532150494;0.13;90.9
255;-4075.367156191117;0.10066666666666667;91.3
260;-4112.665767005653;0.12666666666666668;91.2
265;-3522.411807346644;0.624;77.53333333333333
270;-4117.714798273124;0.12533333333333332;91.3
275;-4193.856750765774;0.152;91.43333333333334
280;-4080.427649842926;0.12;91.06666666666666
285;-4103.19727328246;0.11733333333333333;91.26666666666667
290;-4021.2182841081303;0.168;89.83333333333333
295;-4072.56746530212;0.12333333333333334;90.9
300;-4069.362309321682;0.11866666666666667;90.5
