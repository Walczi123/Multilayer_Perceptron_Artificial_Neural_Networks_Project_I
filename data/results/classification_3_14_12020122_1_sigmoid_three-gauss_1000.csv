Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 8, 4, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4328.505548277363;0.13;92.2
10;-4287.684908277474;0.13733333333333334;91.96666666666667
15;-4656.36938904021;0.13133333333333333;91.36666666666666
20;-4354.4031981951475;0.09466666666666666;92.83333333333333
25;-4931.58425743543;0.11733333333333333;89.13333333333333
30;-4631.452568292105;0.11;91.83333333333333
35;-4483.742384766903;0.10466666666666667;92.83333333333333
40;-4439.4018043807;0.096;93.0
45;-4294.697686683343;0.09333333333333334;93.03333333333333
50;-4509.687973021077;0.08;92.86666666666666
55;-4370.38414694912;0.09266666666666666;93.23333333333333
60;-4790.148874037321;0.08066666666666666;92.13333333333334
65;-4356.115739246479;0.08533333333333333;93.2
70;-4357.907498599041;0.08133333333333333;93.36666666666666
75;-4440.067849144503;0.09266666666666666;93.26666666666667
80;-4533.481167979465;0.11466666666666667;92.2
85;-4411.150582215497;0.086;93.46666666666667
90;-4493.863372070521;0.07733333333333334;93.06666666666666
95;-4508.890594021572;0.08933333333333333;93.13333333333334
100;-4281.081772561127;0.11;92.56666666666666
105;-4392.369942572527;0.09266666666666666;93.10000000000001
110;-4225.575797382819;0.09866666666666667;92.46666666666667
115;-4361.189784081667;0.096;93.26666666666667
120;-4277.067775196848;0.08933333333333333;93.03333333333333
125;-4277.917270130824;0.09666666666666666;92.83333333333333
130;-4325.119030925793;0.08533333333333333;93.30000000000001
135;-4354.831588055263;0.118;92.63333333333334
140;-4905.74081225116;0.12733333333333333;89.13333333333333
145;-4752.365579830114;0.10466666666666667;91.60000000000001
150;-4286.248586880922;0.094;93.03333333333333
155;-4765.7459278476845;0.11666666666666667;91.3
160;-4334.863744303768;0.08266666666666667;93.23333333333333
165;-4398.279931158313;0.11133333333333334;93.03333333333333
170;-4382.353187137854;0.09333333333333334;93.03333333333333
175;-4424.936395324508;0.10533333333333333;93.10000000000001
180;-4434.377786680944;0.102;93.03333333333333
185;-4282.207487149885;0.09266666666666666;93.0
190;-4223.874718715823;0.114;92.30000000000001
195;-4709.726078110906;0.098;91.9
200;-4238.224433518734;0.08333333333333333;92.83333333333333
205;-4525.931590246453;0.08533333333333333;93.26666666666667
210;-4524.805875657694;0.094;92.80000000000001
215;-4725.5162919084505;0.12;91.76666666666667
220;-4128.261068248685;0.07066666666666667;92.10000000000001
225;-4579.267443347515;0.09666666666666666;92.56666666666666
230;-4431.7250700100685;0.08066666666666666;93.46666666666667
235;-4593.44517036459;0.096;92.86666666666666
240;-4331.015468328201;0.11133333333333334;93.0
245;-4627.812756054428;0.10066666666666667;92.43333333333334
250;-4242.444805821862;0.138;91.8
255;-4638.503911449068;0.12266666666666666;91.9
260;-4421.339325436006;0.09266666666666666;93.33333333333333
265;-4346.760850977527;0.13333333333333333;92.5
270;-4222.882427161808;0.09333333333333334;92.56666666666666
275;-4294.904061622191;0.12733333333333333;92.53333333333333
280;-4309.131815774697;0.15866666666666668;91.96666666666667
285;-4417.950719285394;0.10733333333333334;92.86666666666666
290;-4301.5864156397665;0.14266666666666666;92.23333333333333
295;-4296.59367790485;0.094;93.06666666666666
300;-4741.694242015975;0.11666666666666667;91.56666666666666
