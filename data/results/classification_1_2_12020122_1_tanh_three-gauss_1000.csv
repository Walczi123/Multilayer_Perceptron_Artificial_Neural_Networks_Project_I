Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 2, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4160.954677638285;0.11;91.7
10;-4210.990516475262;0.14266666666666666;91.63333333333334
15;-4262.104131564605;0.11266666666666666;92.23333333333333
20;-4220.54760208498;0.196;90.8
25;-4301.649993958576;0.17066666666666666;91.4
30;-4224.527212296248;0.13533333333333333;91.8
35;-4198.083389466025;0.12266666666666666;91.9
40;-4172.647498172239;0.10333333333333333;91.9
45;-4161.448734616252;0.144;91.26666666666667
50;-4209.946108986774;0.12066666666666667;91.93333333333334
55;-4183.276093637201;0.154;91.23333333333333
60;-4298.3155925414785;0.15933333333333333;91.7
65;-4223.768398047838;0.14;91.73333333333333
70;-4172.933091412315;0.12733333333333333;91.56666666666666
75;-4188.456459140375;0.13333333333333333;91.63333333333334
80;-4226.400278749079;0.10333333333333333;92.30000000000001
85;-4223.310817021923;0.13666666666666666;91.76666666666667
90;-4247.6616472770875;0.16266666666666665;91.53333333333333
95;-4223.034597367143;0.164;91.4
100;-4220.499663748589;0.12533333333333332;91.9
105;-4194.918887035722;0.11866666666666667;91.86666666666666
110;-4200.239960359893;0.14133333333333334;91.56666666666666
115;-4197.5465901388825;0.12866666666666668;91.76666666666667
120;-4209.447874410725;0.132;91.73333333333333
125;-4213.319075154966;0.13266666666666665;91.8
130;-4178.271893517946;0.09733333333333333;91.93333333333334
135;-4211.187517828814;0.12866666666666668;91.83333333333333
140;-4265.411430614948;0.13266666666666665;91.9
145;-4271.269303266261;0.15266666666666667;91.76666666666667
150;-4189.738521532549;0.13;91.66666666666666
155;-4202.661288524205;0.11933333333333333;91.83333333333333
160;-4230.072389340728;0.13933333333333334;91.73333333333333
165;-4207.943797097281;0.13266666666666665;91.76666666666667
170;-4203.628566510505;0.12466666666666666;91.8
175;-4232.505179889377;0.13666666666666666;91.8
180;-4200.853889189225;0.15133333333333332;91.36666666666666
185;-4207.95734828066;0.12666666666666668;91.8
190;-4212.589452072352;0.106;92.03333333333333
195;-4289.64447781779;0.15733333333333333;91.73333333333333
200;-4165.165676356117;0.11333333333333333;91.76666666666667
205;-4223.310817021923;0.13666666666666666;91.76666666666667
210;-4277.374204406558;0.202;90.86666666666666
215;-4205.302542810744;0.12533333333333332;91.8
220;-4172.0064669761505;0.10733333333333334;91.83333333333333
225;-4219.491732212155;0.13866666666666666;91.8
230;-4235.395551463939;0.13666666666666666;91.8
235;-4239.803551535323;0.128;91.96666666666667
240;-4210.009687305584;0.14133333333333334;91.60000000000001
245;-4253.390274491741;0.16066666666666668;91.53333333333333
250;-4223.310817021923;0.13666666666666666;91.76666666666667
255;-4207.096390962346;0.106;92.06666666666666
260;-4241.76312107564;0.16333333333333333;91.56666666666666
265;-4188.705576428399;0.12933333333333333;91.7
270;-4222.436308520231;0.11866666666666667;91.96666666666667
275;-4215.933227074747;0.15733333333333333;91.43333333333334
280;-4206.335487914894;0.12866666666666668;91.76666666666667
285;-4243.76334416609;0.17866666666666667;91.16666666666666
290;-4182.766396676815;0.14866666666666667;91.33333333333333
295;-4205.041963138381;0.118;91.9
300;-4232.83351547863;0.118;92.06666666666666
