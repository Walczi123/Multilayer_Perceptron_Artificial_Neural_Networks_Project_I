Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 64, 32, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-428.5974456025182;0.06666666666666667;93.66666666666667
10;-426.46588827636594;0.06;93.0
15;-438.942536626445;0.10666666666666667;92.33333333333333
20;-445.2465279193353;0.1;92.33333333333333
25;-447.051838455275;0.08;92.66666666666666
30;-452.8190304210224;0.11333333333333333;92.0
35;-437.4520104963804;0.06666666666666667;93.0
40;-428.0220815242813;0.04666666666666667;93.33333333333333
45;-426.5701201453107;0.09333333333333334;93.33333333333333
50;-467.7555716865072;0.08;92.33333333333333
55;-451.4462873432808;0.08;92.66666666666666
60;-441.0355292015032;0.05333333333333334;93.33333333333333
65;-428.47966255019514;0.08;93.0
70;-468.213152712421;0.06666666666666667;91.66666666666666
75;-437.5041264308528;0.06;93.66666666666667
80;-459.4242549364094;0.06666666666666667;93.0
85;-458.2735267799356;0.05333333333333334;93.33333333333333
90;-462.7722075368861;0.06;92.66666666666666
95;-452.30933346063614;0.04;94.0
100;-436.2877311565283;0.07333333333333333;93.33333333333333
105;-449.70664392519177;0.06666666666666667;92.66666666666666
110;-454.2188758655206;0.05333333333333334;93.33333333333333
115;-456.12841827040506;0.06666666666666667;92.66666666666666
120;-450.4519069902241;0.08666666666666667;92.33333333333333
125;-438.60273865285427;0.06;93.33333333333333
130;-443.45476856677385;0.09333333333333334;93.0
135;-458.6133247535264;0.05333333333333334;93.33333333333333
140;-444.4355977364523;0.08666666666666667;92.66666666666666
145;-466.0159282684181;0.06666666666666667;92.33333333333333
150;-443.7424506058923;0.08;93.0
155;-459.7119369755278;0.05333333333333334;93.0
160;-453.8134107740791;0.06;93.33333333333333
165;-465.2049980855351;0.05333333333333334;92.66666666666666
170;-452.02165142151773;0.05333333333333334;92.66666666666666
175;-460.5228671584108;0.06666666666666667;92.66666666666666
180;-458.0900766097618;0.07333333333333333;92.66666666666666
185;-460.81054919752927;0.05333333333333334;92.66666666666666
190;-459.7119369755278;0.05333333333333334;93.0
195;-470.2404781696285;0.06666666666666667;91.66666666666666
200;-459.3064718840863;0.06;93.0
205;-459.3064718840863;0.06;93.0
210;-455.31748808752207;0.05333333333333334;93.0
215;-450.6353571603978;0.06666666666666667;93.0
220;-445.88755911542285;0.06666666666666667;93.66666666666667
225;-460.81054919752927;0.05333333333333334;92.66666666666666
230;-460.5228671584108;0.06666666666666667;92.66666666666666
235;-449.58886087286874;0.06;92.66666666666666
240;-454.2188758655206;0.05333333333333334;93.33333333333333
245;-446.0574581022183;0.06666666666666667;93.0
250;-460.81054919752927;0.05333333333333334;92.66666666666666
255;-457.56682846599733;0.04666666666666667;93.0
260;-451.73396938239927;0.06666666666666667;92.66666666666666
265;-451.7860853168716;0.06;93.33333333333333
270;-457.8545105051158;0.08;92.0
275;-462.43240956329527;0.08;92.0
280;-450.92303919951627;0.05333333333333334;93.0
285;-463.64880483761976;0.06666666666666667;92.33333333333333
290;-450.92303919951627;0.05333333333333334;93.0
295;-450.68747309487014;0.06;93.66666666666667
300;-457.2791464268788;0.06;93.0
