Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4085.1337239278573;0.37866666666666665;86.1
10;-4083.2106303395944;0.38666666666666666;85.93333333333332
15;-4028.2279033050495;0.38333333333333336;85.6
20;-4110.270470798189;0.38533333333333336;86.06666666666666
25;-4125.50615648713;0.4053333333333333;85.66666666666667
30;-4120.314328599619;0.3973333333333333;85.8
35;-4077.325655321524;0.38;86.0
40;-4052.148254901057;0.3953333333333333;85.53333333333333
45;-4036.899018028738;0.38466666666666666;85.66666666666667
50;-4099.87326383979;0.378;86.16666666666667
55;-4062.769565579765;0.37;86.1
60;-4096.903673963998;0.392;85.76666666666667
65;-4117.045594300372;0.37933333333333336;86.2
70;-4092.9417925341904;0.376;86.2
75;-4088.939257554248;0.38133333333333336;86.03333333333333
80;-4076.3198125841304;0.358;86.36666666666667
85;-4084.7261700373747;0.41333333333333333;85.36666666666667
90;-4101.612907257879;0.37466666666666665;86.26666666666667
95;-4110.270470798189;0.38533333333333336;86.06666666666666
100;-4118.431888561492;0.38066666666666665;86.13333333333333
105;-4092.432095573804;0.37066666666666664;86.3
110;-3995.8949278586747;0.426;84.6
115;-4026.6446076903776;0.3973333333333333;85.33333333333334
120;-4055.144947143606;0.36466666666666664;86.16666666666667
125;-4028.5812524620187;0.38;85.76666666666667
130;-4073.4794681449985;0.3973333333333333;85.66666666666667
135;-4158.647973317347;0.3993333333333333;85.66666666666667
140;-4099.268708595755;0.432;84.89999999999999
145;-4042.5598893265005;0.42533333333333334;84.93333333333334
150;-4097.297676671102;0.36533333333333334;86.43333333333332
155;-4116.141894632881;0.4033333333333333;85.63333333333333
160;-4125.703157840682;0.39066666666666666;85.9
165;-4062.2056638858658;0.398;85.53333333333333
170;-4058.7263770496875;0.404;85.43333333333332
175;-4173.72731120287;0.408;85.53333333333333
180;-4156.724879729084;0.4086666666666667;85.5
185;-4095.476726152743;0.41733333333333333;85.23333333333333
190;-4022.3429282869793;0.376;85.76666666666667
195;-4080.907085227606;0.41533333333333333;85.26666666666667
200;-4027.5347561744893;0.38266666666666665;85.63333333333333
205;-4075.5453583533;0.4046666666666667;85.5
210;-4082.191236418822;0.37333333333333335;86.13333333333333
215;-4063.2386089900165;0.4026666666666667;85.5
220;-4019.7402387515344;0.376;85.8
225;-4146.511122940859;0.39466666666666667;85.96666666666667
230;-4127.2457999052185;0.402;85.76666666666667
235;-4075.701706156717;0.416;85.23333333333333
240;-4058.386579076097;0.3993333333333333;85.53333333333333
245;-4106.057383281316;0.4166666666666667;85.3
250;-4125.179909696917;0.392;85.93333333333332
255;-4034.452676296711;0.39666666666666667;85.33333333333334
260;-4031.00049182729;0.38533333333333336;85.56666666666666
265;-4012.6388684591398;0.37133333333333335;85.93333333333332
270;-4093.268039324403;0.38666666666666666;85.93333333333332
275;-4028.737600265436;0.39;85.5
280;-4065.8819520755956;0.37666666666666665;85.96666666666667
285;-4146.484020574102;0.4126666666666667;85.33333333333334
290;-4115.136051895487;0.38;86.2
295;-4068.2605378907315;0.404;85.46666666666667
300;-4021.4256774361106;0.4073333333333333;85.03333333333333
