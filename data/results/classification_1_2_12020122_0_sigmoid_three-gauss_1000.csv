Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4200.387952967147;0.294;88.83333333333333
10;-4149.088798908588;0.37466666666666665;86.83333333333333
15;-4213.401400644369;0.2926666666666667;88.86666666666667
20;-4158.28316177604;0.37466666666666665;86.86666666666667
25;-4241.121019469643;0.42533333333333334;85.86666666666667
30;-4184.636303920697;0.38466666666666666;86.76666666666667
35;-4178.877467151113;0.23066666666666666;89.86666666666666
40;-4232.429068776321;0.32866666666666666;88.13333333333333
45;-4176.175741733939;0.3586666666666667;87.3
50;-4180.814111922755;0.214;90.2
55;-4152.278314906605;0.4066666666666667;86.16666666666667
60;-4304.848883541891;0.276;89.56666666666668
65;-4179.14533160973;0.346;87.5
70;-4128.008791751711;0.328;87.7
75;-4185.043857811179;0.3453333333333333;87.6
80;-4239.181267509829;0.262;89.56666666666668
85;-4186.022598181817;0.386;86.7
90;-4244.77647168974;0.30866666666666664;88.63333333333333
95;-4210.024256878094;0.3453333333333333;87.73333333333333
100;-4225.028554060471;0.2906666666666667;88.86666666666667
105;-4180.787009555997;0.23;89.86666666666666
110;-4175.285593249827;0.37333333333333335;87.0
115;-4253.209931509742;0.3506666666666667;87.76666666666667
120;-4150.216602296387;0.328;87.76666666666667
125;-4151.99689926461;0.298;88.46666666666667
130;-4201.495938774444;0.3626666666666667;87.23333333333333
135;-4189.895887725099;0.3486666666666667;87.56666666666668
140;-4295.988052250907;0.394;86.76666666666667
145;-4249.703542306806;0.37;87.33333333333333
150;-4171.520713173571;0.34;87.66666666666667
155;-4285.828500196194;0.3446666666666667;88.0
160;-4241.507737390492;0.29133333333333333;88.93333333333334
165;-4228.752780586591;0.35;87.7
170;-4229.1676192633295;0.41333333333333333;86.23333333333333
175;-4202.107778804734;0.41133333333333333;86.4
180;-4213.931933574388;0.3973333333333333;86.63333333333333
185;-4237.172689223214;0.398;86.66666666666667
190;-4239.3511664966245;0.26466666666666666;89.46666666666667
195;-4276.709178031888;0.4086666666666667;86.4
200;-4154.64024235019;0.2733333333333333;88.93333333333334
205;-4244.368917799257;0.3466666666666667;87.8
210;-4248.425657512713;0.30466666666666664;88.73333333333333
215;-4208.923555857052;0.384;86.93333333333332
220;-4187.673649713381;0.328;87.9
225;-4197.092116301143;0.29733333333333334;88.7
230;-4219.450008252112;0.416;86.23333333333333
235;-4300.96204281523;0.31666666666666665;88.63333333333333
240;-4205.967517164639;0.38666666666666666;86.9
245;-4273.834446439744;0.3586666666666667;87.66666666666667
250;-4175.8046637955085;0.448;85.43333333333332
255;-4333.702572152089;0.288;89.06666666666668
260;-4247.080016801729;0.2773333333333333;89.3
265;-4145.221775762428;0.304;88.33333333333333
270;-4197.234912921182;0.31466666666666665;88.26666666666667
275;-4134.636941035773;0.37333333333333335;86.83333333333333
280;-4238.626739401226;0.358;87.53333333333333
285;-4247.046648037849;0.406;86.5
290;-4123.979154405011;0.35333333333333333;87.2
295;-4205.1107374444055;0.2753333333333333;89.0
300;-4267.847328351771;0.31;88.66666666666667
