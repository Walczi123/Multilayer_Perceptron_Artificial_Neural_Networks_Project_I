Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 16, 8, 4, 2, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-4073.4555249871914;0.13066666666666665;90.8
10;-4022.473244133548;0.17866666666666667;89.63333333333333
15;-3961.7306099195116;0.23333333333333334;87.03333333333333
20;-4106.645280153799;0.19133333333333333;89.7
25;-4059.586315978869;0.22133333333333333;88.63333333333333
30;-4051.6646419182953;0.16666666666666666;90.0
35;-4129.803710313223;0.10133333333333333;91.26666666666667
40;-4037.832979271935;0.09733333333333333;91.0
45;-4037.199232862103;0.17133333333333334;89.83333333333333
50;-3982.9732312769274;0.214;88.66666666666667
55;-3918.0602518951937;0.256;85.2
60;-3952.982365693635;0.226;86.46666666666667
65;-3712.128816591129;0.432;82.53333333333333
70;-4113.961380581206;0.12066666666666667;91.3
75;-3988.0222625443985;0.19933333333333333;88.96666666666667
80;-4227.099692276763;0.178;89.06666666666668
85;-4060.270089524133;0.16866666666666666;90.0
90;-4284.529779432467;0.18466666666666667;91.03333333333333
95;-4213.448320591627;0.16866666666666666;91.06666666666666
100;-4049.145348282162;0.09733333333333333;91.13333333333333
105;-4063.660784473786;0.10933333333333334;90.96666666666667
110;-3991.920565655397;0.17466666666666666;89.26666666666667
115;-4095.9916711211195;0.108;90.7
120;-4023.7302929580073;0.14333333333333334;90.16666666666666
125;-4015.232184409288;0.30533333333333335;87.26666666666667
130;-4066.6168231661986;0.11266666666666666;91.06666666666666
135;-4126.254578761112;0.12266666666666666;91.26666666666667
140;-4100.082797987588;0.146;90.63333333333333
145;-3808.0989234034096;0.64;79.5
150;-4078.046975228749;0.11866666666666667;91.03333333333333
155;-3613.847827859829;0.5313333333333333;79.73333333333333
160;-4129.486837108306;0.10266666666666667;91.10000000000001
165;-4077.6415101373077;0.11666666666666667;91.03333333333333
170;-3895.6888087608468;0.208;87.8
175;-4112.051838176321;0.108;91.5
180;-4143.793809562041;0.11466666666666667;91.46666666666667
185;-4041.2445101912213;0.12066666666666667;90.7
190;-4071.80865105371;0.112;91.03333333333333
195;-3991.016865987907;0.18466666666666667;87.86666666666667
200;-4093.051272411126;0.098;91.03333333333333
205;-4048.502228287033;0.11666666666666667;90.73333333333333
210;-3984.2062849228037;0.3626666666666667;85.83333333333333
215;-4073.9287459955244;0.098;91.33333333333333
220;-4086.1969306077144;0.088;91.46666666666667
225;-4135.066401305798;0.17933333333333334;90.26666666666667
230;-4096.173032492252;0.132;90.96666666666667
235;-4259.732830535726;0.18066666666666667;90.96666666666667
240;-4042.4358918978296;0.09866666666666667;91.0
245;-4177.024218278782;0.148;91.2
250;-4001.1211949199733;0.11;90.4
255;-4012.2115490089327;0.106;90.66666666666666
260;-4028.9836103652865;0.206;88.96666666666667
265;-3448.6932197965707;0.9286666666666666;71.76666666666667
270;-4107.892955392962;0.132;90.93333333333334
275;-4288.847098818284;0.196;90.53333333333333
280;-3980.5873606755367;0.12533333333333332;89.93333333333334
285;-4155.210410441213;0.12933333333333333;91.4
290;-4151.744674788413;0.12666666666666668;91.46666666666667
295;-3973.3004514139266;0.13733333333333334;89.36666666666667
300;-4160.821254603542;0.13066666666666665;91.26666666666667
