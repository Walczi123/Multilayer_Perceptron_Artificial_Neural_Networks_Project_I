Train dataset: data/regression/data.activation.train.100.csv
Test dataset: data/regression/data.activation.test.100.csv
Layers: [1, 8, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.0003295610862681463;0.012702364586854916
10;0.0003099033744518811;0.0142632065370205
15;0.0002574695959961549;0.015161125196418409
20;0.0004036982704916186;0.016290231217772115
25;0.00030858750920510287;0.017365430386088898
30;0.00036443541522692124;0.017800332427680032
35;0.00034654217387080255;0.017802682098036773
40;0.0003081429099319034;0.017405546720773307
45;0.0004452854460199279;0.017042280731147375
50;0.0003573181704733953;0.019352874185284363
55;0.00033818386934342796;0.018598355534337255
60;0.0003439733031992903;0.017827671321959306
65;0.0003299443275761699;0.01954372275141287
70;0.00038585852805747263;0.01950284290025792
75;0.00028531927424828106;0.018011045782474176
80;0.00033779584718348726;0.019268636219435673
85;0.0003426050059305298;0.02054095235887597
90;0.0002778979394829196;0.017724610571837367
95;0.0004022434905003802;0.019402517629276046
100;0.00032355718011746975;0.02000934706569389
105;0.00037416752072157725;0.019718094105833642
110;0.0003476847228947367;0.02031697489152712
115;0.0003081742267836851;0.02026003256939917
120;0.0003299844462994242;0.021157714981089277
125;0.00033098515854446044;0.02088124506218226
130;0.0003917481928052028;0.021308232004035227
135;0.00036316462608884035;0.02118334160103343
140;0.00038622000918470486;0.02003289797952755
145;0.00032931577195085524;0.021542568687832903
150;0.00034063023208366253;0.021224221347144953
155;0.00033067311090663877;0.020722165851088586
160;0.0003174330346698502;0.020671616347792694
165;0.00033093159188919257;0.020389265195006525
170;0.0003345894063805455;0.022069312947885306
175;0.00034785459996686203;0.021832743106834973
180;0.0003167624966190338;0.021713964243943992
185;0.0003332412966812451;0.02221395906386989
190;0.000350051392688659;0.02232351007804896
195;0.00034491871543436203;0.02076419528283571
200;0.00033623244722857606;0.022622577918502623
205;0.00032375784047346116;0.02226492062856921
210;0.0003505946556453518;0.022653396972033304
215;0.00034042541270103935;0.022917691429045428
220;0.0003442138117916875;0.021994053561611156
225;0.0003708791915496013;0.023605261253998828
230;0.000343160326021819;0.022888055824429286
235;0.0003336126648209058;0.022618901256029056
240;0.00033242614812182343;0.022366908761370055
245;0.00037060158819241315;0.023348046134961626
250;0.000374290730468915;0.023593083339265013
255;0.00039292402937170934;0.02435710365494431
260;0.00032555668766495646;0.022967188759126723
265;0.00035746475386553694;0.022944919498960336
270;0.00035210349083349097;0.02337276180432169
275;0.0003718219919156063;0.024108920071130142
280;0.00037370483625693196;0.02387497601641056
285;0.0003552109508504934;0.02333753936580384
290;0.0003881838543301218;0.02441509747972572
295;0.00035989010427773936;0.02385011539381477
300;0.000371921036407372;0.023696247982327907
