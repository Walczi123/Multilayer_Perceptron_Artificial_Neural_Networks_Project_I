Train dataset: data/classification/data.three_gauss.train.100.csv
Test dataset: data/classification/data.three_gauss.test.100.csv
Layers: [2, 32, 3]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-419.4280963027808;0.2733333333333333;88.66666666666667
10;-411.78992668324304;0.30666666666666664;87.66666666666667
15;-419.5979952895762;0.3;87.66666666666667
20;-414.05281824509655;0.26;88.33333333333333
25;-418.22525221183463;0.2;90.0
30;-422.3841349951943;0.23333333333333334;89.0
35;-416.1458108201548;0.18666666666666668;90.0
40;-422.3841349951943;0.23333333333333334;89.0
45;-412.8364229707721;0.2733333333333333;88.0
50;-417.7812223692991;0.11333333333333333;91.33333333333333
55;-417.00885693751013;0.21333333333333335;89.66666666666666
60;-418.12102034288995;0.14;91.0
65;-410.0638344485323;0.25333333333333335;88.33333333333333
70;-426.79213506657845;0.14666666666666667;90.66666666666666
75;-413.26899042897026;0.10666666666666667;91.33333333333333
80;-430.7019005619137;0.29333333333333333;88.0
85;-414.9429667292086;0.12666666666666668;91.33333333333333
90;-424.46357638687414;0.24666666666666667;89.0
95;-416.48560879374554;0.23333333333333334;89.0
100;-419.7949966431283;0.14666666666666667;91.0
105;-418.91839934239454;0.20666666666666667;89.66666666666666
110;-414.995082663681;0.16;90.66666666666666
115;-422.1756712573049;0.09333333333333334;92.0
120;-414.9294155458303;0.2;89.66666666666666
125;-426.79213506657845;0.14666666666666667;90.66666666666666
130;-436.2470776063933;0.3333333333333333;87.33333333333333
135;-418.3044705130636;0.07333333333333333;92.66666666666666
140;-433.1346911105627;0.26666666666666666;88.66666666666667
145;-433.93415890910836;0.21333333333333335;88.33333333333333
150;-419.33741561721445;0.12666666666666668;91.33333333333333
155;-422.9866014401879;0.10666666666666667;91.66666666666666
160;-421.1677397208698;0.24666666666666667;88.66666666666667
165;-421.1291749697758;0.11333333333333333;91.66666666666666
170;-429.8002896934643;0.13333333333333333;91.33333333333333
175;-415.36198300402845;0.05333333333333334;92.33333333333333
180;-417.7020040680701;0.22;89.33333333333333
185;-408.9266574754368;0.14;90.66666666666666
190;-418.93195052577295;0.13333333333333333;91.33333333333333
195;-418.9840664602453;0.15333333333333332;90.66666666666666
200;-416.49915997712395;0.16;90.66666666666666
205;-412.4966249971813;0.22666666666666666;89.0
210;-419.9513444465453;0.26;88.33333333333333
215;-413.33465754682095;0.05333333333333334;92.33333333333333
220;-419.860663760979;0.10666666666666667;92.0
225;-426.0989879360185;0.14;91.0
230;-392.18480567401235;0.34;85.66666666666667
235;-419.4030827350651;0.07333333333333333;92.33333333333333
240;-422.5675851653681;0.16666666666666666;90.66666666666666
245;-407.6310438998833;0.28;87.66666666666667
250;-424.46357638687414;0.24666666666666667;89.0
255;-426.89636693552313;0.22;89.66666666666666
260;-423.4306312827234;0.19333333333333333;90.33333333333333
265;-420.1347946167191;0.19333333333333333;90.0
270;-421.1677397208698;0.24666666666666667;88.66666666666667
275;-417.71555525144845;0.14666666666666667;91.0
280;-412.11826227249645;0.06666666666666667;92.0
285;-417.7812223692991;0.09333333333333334;92.0
290;-415.2692135194211;0.24666666666666667;88.66666666666667
295;-418.5786013688038;0.16;90.66666666666666
300;-420.85504411403565;0.12;90.33333333333333
