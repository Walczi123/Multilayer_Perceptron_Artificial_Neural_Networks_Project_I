Train dataset: data/regression/data.activation.train.1000.csv
Test dataset: data/regression/data.activation.test.1000.csv
Layers: [1, 32, 16, 8, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: sigmoid
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.00013804059722082772;0.024769649754964995
10;0.0001489655164744052;0.0175633880835725
15;0.00013952072437262616;0.014293031939936564
20;0.00010724053684176815;0.013694337347886677
25;0.00011802025111834985;0.012919518740406194
30;0.00017676760339369954;0.012972863806945928
35;0.00012657094757047012;0.018931486327138564
40;0.000138911401356144;0.014830588541269748
45;0.00011000997888967538;0.0163385687420882
50;0.00010502491756662068;0.016317398580902125
55;0.00011407775669874716;0.018171466395807738
60;0.0001314947869849951;0.016859037594366143
65;0.00014050087215616613;0.01677728954519851
70;0.00016441375541725224;0.01718060374796424
75;0.00013230998564329173;0.02038094266086047
80;0.0001465804297343942;0.017116400417797748
85;0.0001237070397813456;0.019655117257566232
90;0.00013625309529022623;0.018250644609291766
95;0.00012214189501979646;0.022020979740234415
100;0.00011935827970255717;0.01948850621613189
105;0.00011932785294256123;0.022203121525821858
110;0.00012449325031462614;0.022398624995777727
115;0.00011664258131435905;0.02207780903552093
120;0.00013956518389369476;0.019053062543346308
125;0.00012981902615384183;0.020029800238225832
130;0.00012076580868459936;0.022739323641894633
135;0.0001194574192555989;0.023106306410475425
140;0.00011563715252297414;0.02222071069908216
145;0.00010694289265628914;0.02192756556207355
150;0.00011379950530991957;0.021356568234792473
155;0.00011694164622822217;0.023540518398828404
160;0.00011172072440402108;0.021859106144204127
165;0.0001147823934693739;0.021578461164806828
170;0.0001076547008469561;0.02129130783791699
175;0.00012007160936733145;0.023769629147117784
180;0.00011228284668191911;0.021283951703896627
185;0.000117172619820336;0.023675969806612955
190;0.00010649290500184424;0.023042146620731705
195;0.00010902956787719469;0.022307035542607635
200;0.00010794810951101043;0.023120834071295563
205;0.0001142049690350179;0.02140846966336691
210;0.00010270329506025048;0.023279912502462394
215;0.00011066166298472158;0.02329016317524039
220;0.00010837849311857679;0.024040720880685658
225;0.00011060638464440674;0.023893386323534656
230;0.00011083633108074273;0.023820835526621852
235;0.00011324925528543533;0.022136396253644445
240;0.00010357179918347823;0.02300272106732658
245;0.00010693005411004325;0.023966341923958998
250;0.0001059445798552551;0.024038291833541267
255;0.00010842240610316725;0.024235817382821583
260;0.00011246708368285315;0.025280419017613163
265;0.0001050023163327887;0.02332226905681772
270;0.00010298355671840847;0.024043674276700285
275;0.00010885991039156976;0.024584835288765084
280;0.0001041953080525604;0.023383624550965175
285;0.00010017687400397641;0.023304062740746458
290;0.00010163888959901508;0.024017675893803294
295;0.00011145051804056346;0.02584671850966395
300;0.00010103889332125114;0.023880097823708337
