Train dataset: data/regression/data.cube.train.1000.csv
Test dataset: data/regression/data.cube.test.1000.csv
Layers: [1, 16, 8, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.4505933087922417;0.1936969867987093
10;0.4673928870313111;0.20208243116116217
15;0.45933030920272805;0.21552699669882722
20;0.5019238038648828;0.17981666481731565
25;0.5028488689175665;0.18727306342496336
30;0.38835284020533944;0.2425941561983808
35;0.3871184791079846;0.25956641615403964
40;0.43014874520764895;0.2074525803614062
45;0.484024495571278;0.2296307795475622
50;0.4976097061142337;0.237963488264114
55;0.4430878054781872;0.15304888972710995
60;0.454070354189752;0.20932356868676133
65;0.4225211283479787;0.21325637942502454
70;0.4614314566382958;0.204735367004188
75;0.4523002104311674;0.20608234052670707
80;0.5097174503609039;0.19829315411627538
85;0.45030271864379967;0.18483479347250265
90;0.4412864378491076;0.17397894847272155
95;0.447357464491595;0.18854745803600245
100;0.4160474018888127;0.24568190931736408
105;0.4164496938286798;0.21930904324152584
110;0.3892107706950812;0.2998941116359113
115;0.39491068837797433;0.20763009953040984
120;0.44249727338985834;0.21789886674381692
125;0.4378768709119772;0.18864356858679196
130;0.4688136998405371;0.2361647186745459
135;0.4375187051109528;0.19850623656183866
140;0.5366032456063812;0.23259578702977715
145;0.43785341508784537;0.18840035830698415
150;0.5682098998417692;0.16793722412167336
155;0.4223713790927434;0.17824702491011368
160;0.42093795329034694;0.20977453515133188
165;0.41308795742317256;0.1923970979006378
170;0.3618274502522345;0.29597770036577215
175;0.42455226408219165;0.263262126033529
180;0.4047492932397548;0.15748500290797637
185;0.47545963846884953;0.22749494717741064
190;0.4463864470449731;0.21661646866709613
195;0.5454987039946875;0.18777125408387535
200;0.4901935346030408;0.18504953742634886
205;0.4881098330058943;0.1910932978373477
210;0.41544112826491963;0.19457186762463213
215;0.4677685851152431;0.20611540793615277
220;0.45984053647631057;0.20569064539951656
225;0.5609795024310442;0.2420087145201495
230;0.37776806925585105;0.5428679473932456
235;0.46691193926369107;0.14472190452104886
240;0.5584694676788784;0.22194772311069794
245;0.42483449966926146;0.19472944564814643
250;0.5051680000608654;0.21146968422097503
255;0.41423591044276975;0.20015003982462454
260;0.42842806707280867;0.19292913844378926
265;0.5639270387208166;0.1755467162984619
270;0.4752637774167544;0.14561943076917494
275;0.4710148267876825;0.20215533662433274
280;0.38754569194097754;0.25617595683218763
285;0.39493290874049986;0.2300491093447059
290;0.4677067097479266;0.20351036739220738
295;0.377019924393511;0.26722721563903057
300;0.5636749428522784;0.19258052096409364
