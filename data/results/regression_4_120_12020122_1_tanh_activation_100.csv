Train dataset: data/regression/data.activation.train.100.csv
Test dataset: data/regression/data.activation.test.100.csv
Layers: [1, 64, 32, 16, 8, 1]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.00033848964893873703;inf
10;0.0002007900733175917;inf
15;5.52625630184141e-05;0.01469143443653835
20;5.827213109856204e-05;0.01703554585525384
25;6.738279859465548e-05;0.020309281316833787
30;9.106486520196976e-05;0.021369278458968435
35;9.948785861783391e-05;0.02353072767800306
40;0.00014142756375616508;0.025988609344386647
45;0.0001670421323219128;0.027229300868116438
50;0.0001619536459728539;0.027155104246593148
55;0.00017556868754123398;0.027754951145227746
60;0.00018942593475810115;0.028387223352427743
65;0.00019821139693396275;0.028748682076336598
70;0.00021186643439224695;0.029035245268317772
75;0.00018315936063332167;0.02817618168999938
80;0.00018921429295187057;0.02846160231959901
85;0.00022658385867646712;0.029553282376501733
90;0.00014167985136535698;0.02586738585199556
95;0.00016427352068624482;0.0272911831558615
100;0.00022207085419662011;0.029605331698821954
105;0.00018621351848695887;0.02832147775742148
110;0.00013984482466767445;0.026331399741531637
115;0.0001432674398537133;0.026174318182826332
120;0.0001670239774662906;0.02719597050805957
125;0.00019029813838609242;0.028919287452287636
130;0.00012756074540519515;0.02580628318632107
135;0.00014094359150212962;0.026467447786073753
140;0.00013101299331209025;0.025744140192987257
145;0.0001799709218790229;0.0285749921110351
150;0.00011142424310052174;0.024901940874289836
155;0.00015035609237542085;0.02713116662939564
160;0.00014454669175460776;0.026711889177273494
165;0.00013462800254011474;0.02650666168724427
170;0.00012949098018258178;0.026253232819350214
175;0.00011856123303105983;0.0252283426002818
180;0.00011373274061732302;0.02531015092568356
185;0.00011228825858722778;0.02524213663148396
190;0.00010640408548269438;0.024875824815794055
195;0.00014068945323400235;0.02678890532139522
200;0.00011424318237586637;0.025541991786862492
205;0.00012718683303883697;0.025817725097035237
210;0.0001096523345696318;0.025259712540298827
215;0.00010370153289536563;0.02492183900982122
220;0.00011930457769760589;0.02556619188768262
225;9.98747289305648e-05;0.024630382891571354
230;9.282872711925669e-05;0.02402032646549167
235;9.63702353182857e-05;0.024464758121612255
240;0.00010957736744004075;0.02520917790750193
245;0.00010177010746425796;0.024493699036828662
250;0.00010466666288743524;0.024770607161391678
255;7.761010604861074e-05;0.023006256454285744
260;9.517392122477952e-05;0.024422107223371358
265;8.156156093939537e-05;0.023357961328399342
270;9.16908346505872e-05;0.023873172195489612
275;8.464192581358438e-05;0.02366603380385219
280;9.167459368414091e-05;0.023956427645595725
285;0.00010573730208536945;0.02510764448577453
290;8.623104767721532e-05;0.023610856824789417
295;8.814185577121121e-05;0.02372397613826218
300;9.224560909290558e-05;0.02429761197735544
