Train dataset: data/regression/data.activation.train.100.csv
Test dataset: data/regression/data.activation.test.100.csv
Layers: [1, 64, 32, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.36161834976314744;0.12009228241610732
10;0.24749591675968888;0.170037841102353
15;0.3677485957829277;0.11849108090267836
20;0.23002223370706093;0.13225090297235895
25;0.386607390216117;0.12258810401232835
30;0.3692941297492022;0.10307720588798476
35;0.39075518410326815;0.12866178549206703
40;0.24861390746079107;0.11468328138259176
45;0.3934916741409857;0.08074047629174615
50;0.26712566010692984;0.13466575258635266
55;0.30893367703895863;0.1236628042635865
60;0.36357961335662925;0.10472896258712402
65;0.32018982634508325;0.11831835629322639
70;0.23773643902956068;0.13965949797184118
75;0.25198359235523526;0.12085127788705939
80;0.29507151248816;0.09480358475925386
85;0.3177337147837974;0.13030766944090055
90;0.31334296787126176;0.10593451918702915
95;0.29698255027705817;0.09228068089115583
100;0.3129325089628202;0.12481605165487404
105;0.35251472940456025;0.08866116489045905
110;0.2572347858269773;0.126140071208947
115;0.4273052678357747;0.12728805280612368
120;0.24210977901400133;0.16377082584071959
125;0.30199166862355703;0.12298625890177589
130;0.34909189075109454;0.1182241122975125
135;0.26237618076398633;0.1334236310330941
140;0.3459943215958609;0.11477950041973917
145;0.3474709214447146;0.14825201228335108
150;0.33972821041458723;0.12891362577317264
155;0.3133853120241898;0.10839165505115685
160;0.24496034678192868;0.15776694580802922
165;0.42998615294373155;0.1104071761305819
170;0.2888338495737006;0.11833629017299771
175;0.3170667688806547;0.1206162331935016
180;0.3126421522816316;0.12222951608864183
185;0.34760111379590464;0.10889978974138116
190;0.30981983127066826;0.11822245725593654
195;0.38443502791482925;0.11297741543906994
200;0.313388243946953;0.12900203671365823
205;0.3557571676285521;0.15096884606394081
210;0.3203631706971739;0.11666325117485327
215;0.3232794647323358;0.127249698062841
220;0.32632719235170554;0.12667280528542046
225;0.2940785360464038;0.11254462925561602
230;0.3378411611805244;0.1348638333454204
235;0.3676432905290788;0.12650749016361787
240;0.35479258749159304;0.14634031520050012
245;0.32321004343609194;0.11590049327556712
250;0.3432477050065371;0.14455345495738847
255;0.2603227580785235;0.1339894091539271
260;0.30343557156133083;0.11985749200462094
265;0.33495279491122437;0.12482461477108042
270;0.261577835767277;0.1336073714246973
275;0.33343903758942406;0.13297236367499407
280;0.30938157755183987;0.132019570755731
285;0.3086379689275213;0.12700228423285698
290;0.3048976498263768;0.1156671570444224
295;0.29244896495540895;0.13087386726578754
300;0.3168424628161055;0.1276426385416717
