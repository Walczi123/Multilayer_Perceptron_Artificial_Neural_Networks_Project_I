Train dataset: data/regression/data.activation.train.100.csv
Test dataset: data/regression/data.activation.test.100.csv
Layers: [1, 8, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.348385339752348;0.10438341413982752
10;0.280248125726693;0.17335584932974543
15;0.4393914903157239;0.0996532500709989
20;0.23180471121360707;0.11378909689728076
25;0.47333753396986883;0.10891918957500982
30;0.4077847693778953;0.0978666466120196
35;0.4665624825277464;0.10491621147915663
40;0.242819010778277;0.09782627482718416
45;0.27845103957501816;0.08664743032709621
50;0.43119673001223047;0.1078778780007505
55;0.43051684859010886;0.1007617660916921
60;0.277623213551848;0.09571971273349261
65;0.29483463957729555;0.09180745488566021
70;0.2387730282792273;0.09720988776220801
75;0.27500941606187745;0.09067716167578554
80;0.28840058826562665;0.09722857618422255
85;0.3982223842354026;0.0968667282833057
90;0.2905306146159823;0.0951610771142512
95;0.23235324273471455;0.10396941725972178
100;0.4184383196151836;0.10096966170192775
105;0.2575968112732625;0.09814093931751433
110;0.2857696482122952;0.10371623821474628
115;0.5346309157355478;0.10671646799653343
120;0.3141768026427947;0.1002419869254893
125;0.3357004701051755;0.10524054428015671
130;0.4345447893526776;0.1087770402748801
135;0.316263576262495;0.09824079697992659
140;0.3708180429249518;0.0950482665112603
145;0.48422729174021245;0.10416876173257095
150;0.42694896380699354;0.09690123532100343
155;0.3164772106682072;0.09307351518795234
160;0.23047358048748964;0.10804343812914416
165;0.3095980128456576;0.09498765587712392
170;0.25473060913258033;0.09033800721329699
175;0.31437131884277225;0.0888764790820884
180;0.24092690976370706;0.09505424437242271
185;0.23490922397608804;0.09254995600540752
190;0.2683788220266583;0.0942619132420129
195;0.339714051866258;0.09646878216342918
200;0.36431122020250084;0.09399419945012197
205;0.4428071447415972;0.10270178907018837
210;0.23275022424319786;0.10194740796718607
215;0.2909332563002203;0.10161832927675114
220;0.3423104607213718;0.09764965467462842
225;0.23093201336995167;0.10521946665041892
230;0.3267363068648693;0.09488688768222113
235;0.4072634519889661;0.09593581604519194
240;0.3621595685055905;0.1012526086040609
245;0.2493172416538171;0.09461385612635002
250;0.38410827139088977;0.09647599307113205
255;0.2638230242599739;0.09699967045275061
260;0.24013154387539298;0.09888762219971126
265;0.3348995734641834;0.09200273974066564
270;0.23347079618466018;0.10386326195280556
275;0.30269194480001754;0.09785458029342661
280;0.3153364120853906;0.09700010180811668
285;0.325322978462124;0.09373779404982374
290;0.2837228383977463;0.09074056269730894
295;0.2382125209844191;0.09815283746411108
300;0.22957537694094332;0.10393936934907258
