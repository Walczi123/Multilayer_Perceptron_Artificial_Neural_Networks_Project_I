Train dataset: data/classification/data.three_gauss.train.1000.csv
Test dataset: data/classification/data.three_gauss.test.1000.csv
Layers: [2, 64, 32, 3]
Test dataset: 1
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: softmax
Problem type: classification
Epochs: 300
Epochs;Loss (cross_entropy);Loss (hinge);Accuracy
5;-3977.04658431959;0.08;90.43333333333334
10;-4237.386400969094;0.10266666666666667;92.43333333333334
15;-4758.084833459471;0.17133333333333334;89.8
20;-4362.780364482594;0.16666666666666666;92.03333333333333
25;-4790.919150670068;0.09933333333333333;91.03333333333333
30;-4485.106772648481;0.14666666666666667;91.76666666666667
35;-4368.0326635007405;0.07533333333333334;93.26666666666667
40;-4195.958098536996;0.07066666666666667;92.2
45;-4284.456827528361;0.108;92.66666666666666
50;-4530.495938121254;0.08133333333333333;92.4
55;-4110.300732373896;0.09;91.83333333333333
60;-4830.729770334482;0.094;90.53333333333333
65;-4354.030031457677;0.17666666666666667;91.86666666666666
70;-4286.040123143033;0.08466666666666667;93.13333333333334
75;-4125.52704447754;0.06266666666666666;92.43333333333334
80;-4492.329085202148;0.236;89.16666666666667
85;-4470.867556111637;0.10133333333333333;92.60000000000001
90;-4464.486435316559;0.09;92.93333333333334
95;-4248.544510974945;0.07333333333333333;93.10000000000001
100;-4202.101564428388;0.08333333333333333;92.46666666666667
105;-4314.6311432818275;0.078;93.23333333333333
110;-4290.067671690691;0.094;93.06666666666666
115;-4345.413121467502;0.14466666666666667;92.43333333333334
120;-4204.584382112468;0.1;92.4
125;-4183.4887349731725;0.10333333333333333;92.2
130;-4362.136226098333;0.092;92.76666666666667
135;-4469.771032688677;0.08266666666666667;93.0
140;-4843.781782762799;0.092;89.93333333333334
145;-4894.820357148996;0.124;90.0
150;-4138.6832887748005;0.07266666666666667;92.33333333333333
155;-4769.15536996793;0.09466666666666666;91.26666666666667
160;-4177.943557928693;0.09666666666666666;92.26666666666667
165;-4339.978442689089;0.096;92.83333333333333
170;-4280.340687094177;0.07866666666666666;92.7
175;-4406.83535162872;0.08466666666666667;93.36666666666666
180;-4346.276167584857;0.146;92.36666666666666
185;-4534.054443258661;0.08266666666666667;92.83333333333333
190;-4021.133869819687;0.06133333333333333;91.4
195;-4908.810456397814;0.09333333333333334;89.3
200;-4175.684843964921;0.088;91.8
205;-4426.245560083438;0.096;92.86666666666666
210;-4381.823672596966;0.16133333333333333;91.60000000000001
215;-4845.181628207297;0.096;90.36666666666666
220;-4078.2095894292893;0.06;91.93333333333334
225;-4467.129778402139;0.086;93.36666666666666
230;-4346.776490959946;0.098;92.96666666666667
235;-4454.637490069641;0.09266666666666666;93.10000000000001
240;-4341.3490969677905;0.094;93.33333333333333
245;-4798.93359421525;0.104;90.60000000000001
250;-4345.8613289081195;0.09266666666666666;93.26666666666667
255;-4144.491134290683;0.058666666666666666;92.7
260;-4526.8582146826175;0.08933333333333333;92.9
265;-4414.317173444841;0.09333333333333334;92.86666666666666
270;-4601.021850464359;0.14466666666666667;91.46666666666667
275;-4237.656354226752;0.17133333333333334;91.33333333333333
280;-4233.854998198444;0.08933333333333333;92.73333333333333
285;-4329.735494735067;0.09266666666666666;93.03333333333333
290;-4046.2570655066397;0.056666666666666664;91.8
295;-4311.308204249066;0.086;93.26666666666667
300;-4857.361220932961;0.09466666666666666;90.8
