Train dataset: data/regression/data.cube.train.1000.csv
Test dataset: data/regression/data.cube.test.1000.csv
Layers: [1, 8, 1]
Test dataset: 0
Seed: 12020122
Learning rate: 0.1
Activation function: tanh
Output function: indentity
Problem type: regression
Epochs: 300
Epochs;Loss (mse);Loss (msle)
5;0.6255770738028629;0.17092009262772612
10;0.5747665262271333;0.15553627151743488
15;0.5967685885378256;0.14966019203144396
20;0.42659850193824406;0.1928587772040923
25;0.5326701131486463;0.1589621040900762
30;0.3628444520801133;0.3251164197940955
35;0.4027131558041228;0.20024197512798853
40;0.39267451181536134;0.1979347559498713
45;0.4681051527149557;0.18097640406103577
50;0.5098809262422169;0.19907255430660142
55;0.36875246752874685;0.20313288483526531
60;0.6622929958782282;0.1707415021830173
65;0.38117355750388143;0.22489428391345667
70;0.5188960062603762;0.16925073593685727
75;0.4755525316866512;0.18569719241139115
80;0.552521668007844;0.18116761579943205
85;0.47983526777263685;0.17309678630332911
90;0.5410650380604438;0.16279276820791547
95;0.48254662555464495;0.17597709735123096
100;0.3897647528645377;0.2256975752028604
105;0.388099243001183;0.20640620834496215
110;0.377957192045056;0.2501668841584464
115;0.37123052212065805;0.20236272059475627
120;0.8335699437547406;0.16770340938418335
125;0.48774827038493573;0.16169136772872963
130;0.49218239814678727;0.19747931705101757
135;0.41340470461859735;0.19218868023756233
140;0.5743088013689228;0.2097699441519965
145;0.4468231870845053;0.18294832730559638
150;0.5689476052174944;0.16666728921112656
155;0.37125044825366205;0.2123587504458842
160;0.4506740597214524;0.17871357514597602
165;0.44832189987947896;0.17471604001784297
170;0.36828753991726493;0.3826243607092484
175;0.4034050044753837;0.22783238326516986
180;0.364331072426753;0.20251945308788538
185;0.4310579771666715;0.22130730260350515
190;0.5313429210154541;0.1858141013853917
195;0.5531577580184389;0.17532332697713665
200;0.534316478432726;0.16848018180518437
205;0.505728560616388;0.18637850819525462
210;0.3706285467198651;0.21254169982238316
215;0.4873546128729598;0.1760256363021854
220;0.4922819674229736;0.18202029193184197
225;0.6165667248336245;0.20948309476284777
230;0.36536482091299544;0.38926857860298486
235;0.36613193502261293;0.22478943958509107
240;0.7352795209414502;0.18217086223586115
245;0.4389651988134729;0.1759376034743133
250;0.6230140818926235;0.18141074647375674
255;0.4102876633714163;0.18506972244649447
260;0.367959388060742;0.24931162405559606
265;0.581808432750772;0.1719023504226521
270;0.37023216318284297;0.17903901509205905
275;0.5007095829913156;0.18241588737900336
280;0.36084490679397285;0.32174782339178815
285;0.40406088627338876;0.18577487123602127
290;0.544638681403754;0.18364624525673176
295;0.3695464947405849;0.39674294306467367
300;0.6456884218528605;0.17628102670083126
